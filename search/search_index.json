{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":"<p>A BBOT scan in real-time - visualization with VivaGraphJS</p>"},{"location":"#installation","title":"Installation","text":"<p>Supported Platforms</p> <p>Only Linux is supported at this time. Windows and macOS are not supported. If you use one of these platforms, consider using Docker.</p> <p>BBOT offers multiple methods of installation, including pipx and Docker. If you plan to dev on BBOT, see Installation (Poetry).</p>"},{"location":"#python-pip-pipx","title":"Python (pip / pipx)","text":"Note <p><code>pipx</code> installs BBOT inside its own virtual environment.</p> <pre><code># stable version\npipx install bbot\n\n# bleeding edge (dev branch)\npipx install --pip-args '\\--pre' bbot\n\n# execute bbot command\nbbot --help\n</code></pre>"},{"location":"#docker","title":"Docker","text":"<p>Docker images are provided, along with helper script <code>bbot-docker.sh</code> to persist your scan data.</p> <pre><code># bleeding edge (dev)\ndocker run -it blacklanternsecurity/bbot --help\n\n# stable\ndocker run -it blacklanternsecurity/bbot:stable --help\n\n# helper script\ngit clone https://github.com/blacklanternsecurity/bbot &amp;&amp; cd bbot\n./bbot-docker.sh --help\n</code></pre>"},{"location":"#example-commands","title":"Example Commands","text":"<p>Below are some examples of common scans.</p> <p>Subdomains:</p> <pre><code># Perform a full subdomain enumeration on evilcorp.com\nbbot -t evilcorp.com -f subdomain-enum\n</code></pre> <p>Subdomains (passive only):</p> <pre><code># Perform a passive-only subdomain enumeration on evilcorp.com\nbbot -t evilcorp.com -f subdomain-enum -rf passive\n</code></pre> <p>Subdomains + port scan + web screenshots:</p> <pre><code># Port-scan every subdomain, screenshot every webpage, output to current directory\nbbot -t evilcorp.com -f subdomain-enum -m nmap gowitness -n my_scan -o .\n</code></pre> <p>Subdomains + basic web scan:</p> <pre><code># A basic web scan includes wappalyzer, robots.txt, and other non-intrusive web modules\nbbot -t evilcorp.com -f subdomain-enum web-basic\n</code></pre> <p>Web spider:</p> <pre><code># Crawl www.evilcorp.com up to a max depth of 2, automatically extracting emails, secrets, etc.\nbbot -t www.evilcorp.com -m httpx robots badsecrets secretsdb -c web_spider_distance=2 web_spider_depth=2\n</code></pre> <p>Everything everywhere all at once:</p> <pre><code># Subdomains, emails, cloud buckets, port scan, basic web, web screenshots, nuclei\nbbot -t evilcorp.com -f subdomain-enum email-enum cloud-enum web-basic -m nmap gowitness nuclei --allow-deadly\n</code></pre>"},{"location":"#api-keys","title":"API Keys","text":"<p>No API keys are required to run BBOT. However, some modules need them to function. If you have API keys and want to make use of these modules, you can place them either in BBOT's YAML config (<code>~/.config/bbot/secrets.yml</code>):</p> ~/.config/bbot/secrets.yml<pre><code>modules:\nshodan_dns:\napi_key: deadbeef\nvirustotal:\napi_key: cafebabe\n</code></pre> <p>Or on the command-line:</p> <pre><code># specify API key with -c\nbbot -t evilcorp.com -f subdomain-enum -c modules.shodan_dns.api_key=deadbeef modules.virustotal.api_key=cafebabe\n</code></pre> <p>For more information, see Configuration. For a full list of modules, including which ones require API keys, see List of Modules.</p> <p>Next Up: Scanning --&gt;</p>"},{"location":"comparison/","title":"Comparison to Other Tools","text":"<p>BBOT does a lot more than just subdomain enumeration. However, subdomain enumeration is arguably the most important part of OSINT, and since there's so many subdomain enumeration tools out there, they're the easiest class of tool to compare it to.</p> <p>Thanks to BBOT's recursive nature (and its <code>massdns</code> module with its NLP-powered subdomain mutations), it typically finds about 20-25% more than other tools such as <code>Amass</code> or <code>theHarvester</code>. This holds true even for larger targets like <code>delta.com</code> (1000+ subdomains):</p>"},{"location":"comparison/#subdomains-found","title":"Subdomains Found","text":""},{"location":"comparison/#runtimes-lower-is-better","title":"Runtimes (Lower is Better)","text":"<p>For a detailed analysis of this data, please see Subdomain Enumeration Tool Face-Off</p>"},{"location":"contribution/","title":"Contribution","text":"<p>We welcome contributions! If you have an idea for a new module, or are a Python developer who wants to get involved, please fork us or come talk to us on Discord.</p>"},{"location":"contribution/#setting-up-a-dev-environment","title":"Setting Up a Dev Environment","text":""},{"location":"contribution/#installation-poetry","title":"Installation (Poetry)","text":"<p>Poetry is the recommended method of installation if you want to dev on BBOT. To set up a dev environment with Poetry, you can follow these steps:</p> <ul> <li>Fork BBOT on GitHub</li> <li>Clone your fork and set up a development environment with Poetry:</li> </ul> <pre><code># clone your forked repo and cd into it\ngit clone git@github.com/&lt;username&gt;/bbot.git\ncd bbot\n\n# install poetry\ncurl -sSL https://install.python-poetry.org | python3 -\n\n# install pip dependencies\npoetry install\n# install pre-commit hooks, etc.\npoetry run pre-commit install\n\n# enter virtual environment\npoetry shell\n\nbbot --help\n</code></pre> <ul> <li>Now, any changes you make in the code will be reflected in the <code>bbot</code> command.</li> <li>After making your changes, run the tests locally to ensure they pass.</li> </ul> <pre><code># auto-format code indentation, etc.\nblack .\n\n# run tests\n./bbot/test/run_tests.sh\n</code></pre> <ul> <li>Finally, commit and push your changes, and create a pull request to the <code>dev</code> branch of the main BBOT repo.</li> </ul>"},{"location":"contribution/#creating-a-module","title":"Creating a Module","text":"<p>Writing a module is easy and requires only a basic understanding of Python. It consists of a few steps:</p> <ol> <li>Create a new <code>.py</code> file in <code>bbot/modules</code></li> <li>At the top of the file, import <code>BaseModule</code></li> <li>Declare a class that inherits from <code>BaseModule</code></li> <li>the class must have the same name as your file (case-insensitive)</li> <li>Define in <code>watched_events</code> what type of data your module will consume</li> <li>Define in <code>produced_events</code> what type of data your module will produce</li> <li>Define (via <code>flags</code>) whether your module is <code>active</code> or <code>passive</code>, and whether it's <code>safe</code> or <code>aggressive</code></li> <li>Override <code>.handle_event()</code> (see <code>handle_event()</code> and <code>emit_event()</code>)</li> </ol> <p>Here is a simple example of a working module (<code>bbot/modules/mymodule.py</code>):</p> <pre><code>from bbot.modules.base import BaseModule\n\nclass MyModule(BaseModule):\n\"\"\"\n    Resolve DNS_NAMEs to IPs\n    \"\"\"\n    watched_events = [\"DNS_NAME\"]\n    produced_events = [\"IP_ADDRESS\"]\n    flags = [\"passive\", \"safe\"]\n\n    async def handle_event(self, event):\n        self.hugeinfo(f\"GOT EVENT: {event}\")\n        for ip in await self.helpers.resolve(event.data):\n            self.hugesuccess(f\"EMITTING IP_ADDRESS: {ip}\")\n            self.emit_event(ip, \"IP_ADDRESS\", source=event)\n</code></pre> <p>After saving the module, you can run it simply by specifying it with <code>-m</code>:</p> <pre><code># run a scan enabling the module in bbot/modules/mymodule.py\nbbot -t evilcorp.com -m mymodule\n</code></pre> <p>This will produce the output:</p> <pre><code>[SUCC] Starting scan satanic_linda\n[SCAN]                  satanic_linda (SCAN:2e9ec8b6f06875bcf7980eea4c150754b53a6049)  TARGET  (distance-0)\n[INFO] mymodule: GOT EVENT: DNS_NAME(\"dns.google\", module=TARGET, tags={'aaaa-record', 'ns-record', 'target', 'domain', 'a-record', 'resolved', 'txt-record', 'soa-record', 'distance-0', 'in-scope'})\n[DNS_NAME]              dns.google  TARGET  (a-record, aaaa-record, distance-0, domain, in-scope, ns-record, resolved, soa-record, target, txt-record)\n[INFO] Finishing scan\n</code></pre> <p>But something's wrong! We're emitting <code>IP_ADDRESS</code> events, but they're not showing up in the output. This is because by default, BBOT only shows in-scope events. To see them, we need to increase the report distance:</p> <pre><code># run the module again but with a higher report distance\n# this lets us see out-of-scope events (up to distance 1)\nbbot -t evilcorp.com -m mymodule -c scope_report_distance=1\n</code></pre> <p>Now, with the <code>report_distance=1</code>:</p> <pre><code>[SUCC] Starting scan suspicious_dobby\n[SCAN]                  suspicious_dobby (SCAN:e9d28f64527da53eaffc16f46f5deb20103bc78b)    TARGET  (distance-0)\n[INFO] mymodule: GOT EVENT: DNS_NAME(\"dns.google\", module=TARGET, tags={'soa-record', 'aaaa-record', 'ns-record', 'txt-record', 'distance-0', 'in-scope', 'resolved', 'domain', 'a-record', 'target'})\n[DNS_NAME]              dns.google  TARGET  (a-record, aaaa-record, distance-0, domain, in-scope, ns-record, resolved, soa-record, target, txt-record)\n[IP_ADDRESS]            8.8.4.4 mymodule   (distance-1, ipv4, ptr-record, resolved)\n[IP_ADDRESS]            2001:4860:4860::8888    mymodule    (distance-1, ipv6, ptr-record, resolved)\n[IP_ADDRESS]            8.8.8.8 mymodule   (distance-1, ipv4, ptr-record, resolved)\n[IP_ADDRESS]            2001:4860:4860::8844    mymodule    (distance-1, ipv6, ptr-record, resolved)\n[DNS_NAME]              ns3.zdns.google NS  (a-record, aaaa-record, distance-1, resolved, subdomain)\n[DNS_NAME]              ns1.zdns.google NS  (a-record, aaaa-record, distance-1, resolved, subdomain)\n[DNS_NAME]              ns4.zdns.google NS  (a-record, aaaa-record, distance-1, resolved, subdomain)\n[DNS_NAME]              ns2.zdns.google NS  (a-record, aaaa-record, distance-1, resolved, subdomain)\n[DNS_NAME]              xkcd.com    TXT (a-record, aaaa-record, distance-1, domain, mx-record, ns-record, resolved, soa-record, txt-record)\n[INFO] Finishing scan\n</code></pre>"},{"location":"contribution/#handle_event-and-emit_event","title":"<code>handle_event()</code> and <code>emit_event()</code>","text":"<p>The <code>handle_event()</code> method is the most important part of the module. By overriding this method, you control what the module does. During a scan, when an event from your <code>watched_events</code> is encountered (a <code>DNS_NAME</code> in this example), <code>handle_event()</code> is automatically called with that event.</p> <p>The <code>emit_event()</code> method is how modules return data. When you call <code>emit_event()</code>, it creates an event and prints it to the console. It also distributes it any modules that are interested in that data type.</p>"},{"location":"contribution/#module-dependencies","title":"Module Dependencies","text":"<p>BBOT automates module dependencies with Ansible. If your module relies on a third-party binary, OS package, or python library, you can specify them in the <code>deps_*</code> attributes of your module.</p> <pre><code>class MyModule(BaseModule):\n    ...\n    deps_pip = [\"beautifulsoup4\"]\n    deps_apt = [\"chromium-browser\"]\n    deps_ansible = [\n        {\n            \"name\": \"install dev tools\",\n            \"package\": {\"name\": [\"gcc\", \"git\", \"make\"], \"state\": \"present\"},\n            \"become\": True,\n            \"ignore_errors\": True,\n        },\n        {\n            \"name\": \"Download massdns source code\",\n            \"git\": {\n                \"repo\": \"https://github.com/blechschmidt/massdns.git\",\n                \"dest\": \"#{BBOT_TEMP}/massdns\",\n                \"single_branch\": True,\n                \"version\": \"master\",\n            },\n        },\n        {\n            \"name\": \"Build massdns\",\n            \"command\": {\"chdir\": \"#{BBOT_TEMP}/massdns\", \"cmd\": \"make\", \"creates\": \"#{BBOT_TEMP}/massdns/bin/massdns\"},\n        },\n        {\n            \"name\": \"Install massdns\",\n            \"copy\": {\"src\": \"#{BBOT_TEMP}/massdns/bin/massdns\", \"dest\": \"#{BBOT_TOOLS}/\", \"mode\": \"u+x,g+x,o+x\"},\n        },\n    ]\n</code></pre>"},{"location":"how_it_works/","title":"What is it?","text":"<p>BBOT is a system of modules that interchange data recursively. Okay, but like, what is it?</p>"},{"location":"how_it_works/#what-it-isnt","title":"What It Isn't","text":"<p>BBOT's discovery process does not have \"phases\", or \"stages\"; i.e. it does not work like this:</p> <p></p> <p>This is a traditional OSINT process, where you start with a target and you work in stages. Each stage gets you a little more data and requires more cleaning/deduplication, until finally you reach the end. The problem with this approach is that it misses things. </p> <p>Imagine if on the last step of this process, you discovered a new subdomain. Awesome! But wait, shouldn't you go back and check that one the same way you did the others? Shouldn't you port-scan it and SSL-mine it and so on? Maybe you're a thorough, hard-working human, and you take the time to do that. Maybe by doing that, you find another subdomain! Sigh. What about this time? Should you start over again for that one? You see the dilemma.</p> <p></p>"},{"location":"how_it_works/#what-it-is","title":"What It Is","text":"<p>Instead, BBOT works recursively, treating each new individual piece of data as an opportunity to find even more. When it finds something, it feeds it back into the machine and uses it to fuel the discovery process. It continues to churn like this until there is no new data to discover.</p> <p></p>"},{"location":"how_it_works/#module-example","title":"Module Example","text":"<p>In a simple example, we run a BBOT scan with three modules: <code>nmap</code>, <code>sslcert</code>, and <code>httpx</code>. Each of these modules \"consume\" a certain type of data:</p> <ul> <li><code>nmap</code> consumes <code>DNS_NAME</code>s, port-scans them, and outputs <code>OPEN_TCP_PORT</code>s</li> <li><code>sslcert</code> consumes <code>OPEN_TCP_PORT</code>s, grabs certs, and extracts <code>DNS_NAME</code>s</li> <li><code>httpx</code> consumes <code>OPEN_TCP_PORT</code>s and visits any web services, ultimately producing new <code>DNS_NAME</code>s</li> </ul> <pre><code>graph TD\n  nmap --&gt;|OPEN_TCP_PORT| sslcert;\n  nmap --&gt;|OPEN_TCP_PORT| httpx;\n  sslcert --&gt; |DNS_NAME| nmap;\n  httpx --&gt; |DNS_NAME| nmap;</code></pre> <p>This allows for some interesting chains of events. Given a single target such as <code>evilcorp.com</code>, <code>nmap</code> may start by discovering an <code>OPEN_TCP_PORT</code> <code>evilcorp.com:443</code>. <code>sslcert</code> and <code>httpx</code> will then visit that port and extract more hostnames, which are in turn scanned by <code>nmap</code> to produce more open ports which are visited by <code>sslcert</code> and <code>httpx</code>, which discover more hostnames, which are again passed to <code>nmap</code>, and so on...</p> <p>This is a simple example with only a few modules, but you can being to see how if 30 or 40 modules were enabled, they could feed each other exponentially to produce an immense amount of data. This recursion is exactly how BBOT is able to outperform other tools.</p> <p>For a full list of event types and which modules consume/produce them, see List of Event Types.</p>"},{"location":"release_history/","title":"Release History","text":""},{"location":"release_history/#v112","title":"v1.1.2","text":"<p>October 24, 2023</p>"},{"location":"release_history/#improvements","title":"Improvements","text":"<ul> <li>https://github.com/blacklanternsecurity/bbot/pull/776</li> <li>https://github.com/blacklanternsecurity/bbot/pull/783</li> <li>https://github.com/blacklanternsecurity/bbot/pull/790</li> <li>https://github.com/blacklanternsecurity/bbot/pull/797</li> <li>https://github.com/blacklanternsecurity/bbot/pull/798</li> <li>https://github.com/blacklanternsecurity/bbot/pull/799</li> <li>https://github.com/blacklanternsecurity/bbot/pull/801</li> </ul>"},{"location":"release_history/#bugfixes","title":"Bugfixes","text":"<ul> <li>https://github.com/blacklanternsecurity/bbot/pull/780</li> <li>https://github.com/blacklanternsecurity/bbot/pull/787</li> <li>https://github.com/blacklanternsecurity/bbot/pull/788</li> <li>https://github.com/blacklanternsecurity/bbot/pull/791</li> </ul>"},{"location":"release_history/#new-modules","title":"New Modules","text":"<ul> <li>https://github.com/blacklanternsecurity/bbot/pull/774</li> </ul>"},{"location":"release_history/#v111","title":"v1.1.1","text":"<p>October 11, 2023</p> <p>Includes webhook output modules - Discord, Slack, and Teams!</p> <p></p>"},{"location":"release_history/#improvements_1","title":"Improvements","text":"<ul> <li>https://github.com/blacklanternsecurity/bbot/pull/677</li> <li>https://github.com/blacklanternsecurity/bbot/pull/674</li> <li>https://github.com/blacklanternsecurity/bbot/pull/683</li> <li>https://github.com/blacklanternsecurity/bbot/pull/740</li> <li>https://github.com/blacklanternsecurity/bbot/pull/743</li> <li>https://github.com/blacklanternsecurity/bbot/pull/748</li> <li>https://github.com/blacklanternsecurity/bbot/pull/749</li> <li>https://github.com/blacklanternsecurity/bbot/pull/751</li> <li>https://github.com/blacklanternsecurity/bbot/pull/692</li> </ul>"},{"location":"release_history/#bugfixes_1","title":"Bugfixes","text":"<ul> <li>https://github.com/blacklanternsecurity/bbot/pull/691</li> <li>https://github.com/blacklanternsecurity/bbot/pull/684</li> <li>https://github.com/blacklanternsecurity/bbot/pull/669</li> <li>https://github.com/blacklanternsecurity/bbot/pull/664</li> <li>https://github.com/blacklanternsecurity/bbot/pull/737</li> <li>https://github.com/blacklanternsecurity/bbot/pull/741</li> <li>https://github.com/blacklanternsecurity/bbot/pull/744</li> <li>https://github.com/blacklanternsecurity/bbot/issues/760</li> <li>https://github.com/blacklanternsecurity/bbot/issues/759</li> <li>https://github.com/blacklanternsecurity/bbot/issues/758</li> <li>https://github.com/blacklanternsecurity/bbot/pull/764</li> <li>https://github.com/blacklanternsecurity/bbot/pull/773</li> </ul>"},{"location":"release_history/#new-modules_1","title":"New Modules","text":"<ul> <li>https://github.com/blacklanternsecurity/bbot/pull/689</li> <li>https://github.com/blacklanternsecurity/bbot/pull/665</li> <li>https://github.com/blacklanternsecurity/bbot/pull/663</li> </ul>"},{"location":"release_history/#v110","title":"v1.1.0","text":"<p>August 4, 2023</p> <p>New Features:</p> <ul> <li>Complete Asyncification</li> <li>Documentation + auto-updating pipelines</li> <li>Ability to list flags and their descriptions with <code>-lf</code></li> <li>Fine-grained rate-limiting for HTTP and DNS</li> </ul> <p>Improvements / Fixes:</p> <ul> <li>Better tests (one for each individual module, 91% test coverage)</li> <li>New and improved paramminer modules</li> <li>Misc bugfixes</li> </ul> <p>New Modules:</p> <ul> <li>Git (detects exposed .git folder on websites)</li> <li>Subdomain Center (subdomain enumeration)</li> <li>Columbus API (subdomain enumeration)</li> <li>MySSL (subdomain enumeration)</li> <li>Sitedossier (subdomain enumeration)</li> <li>Digitorus (subdomain enumeration)</li> <li>Nmap (port scanner, more reliable than naabu)<ul> <li>Naabu has been removed due to reliability issues</li> </ul> </li> <li>NSEC (DNSSEC zone-walking for subdomain enumeration)</li> <li>OAUTH (Enumerates OAUTH / OpenID-Connect, detects sprayable endpoints)</li> <li>Azure Realm (Detects Managed/Federated Azure Tenants)</li> <li>Subdomains output module</li> </ul>"},{"location":"release_history/#v105","title":"v1.0.5","text":"<p>March 10, 2023</p> <p>New Modules:</p> <ul> <li>Badsecrets (blacklist3r but better!)</li> <li>Subdomain Hijacking (uses can-i-take-over-xyz)</li> <li>WafW00f</li> <li>Fingerprintx</li> <li>Masscan</li> <li>Robots.txt</li> <li>Web Report</li> <li>IIS shortnames (Pure Python rewrite)</li> </ul> <p>New Features:</p> <ul> <li>Automatic tagging of cloud resources (with cloudcheck)</li> <li>Significant performance increases</li> <li>Bug fixes</li> <li>Better tests + code coverage</li> <li>Support for punycode (non-ascii) domains</li> <li>Better support for non-64-bit systems</li> <li>Enter key now toggles verbosity during scan</li> </ul>"},{"location":"release_history/#v104","title":"v1.0.4","text":"<p>December 15, 2022</p> <p>New Modules:</p> <ul> <li>Storage buckets:<ul> <li>Azure</li> <li>GCP</li> <li>AWS</li> <li>DigitalOcean</li> </ul> </li> <li>ipstack (geolocation)</li> <li>BeVigil</li> <li>ASN (rewrite)</li> </ul> <p>New Features:</p> <ul> <li>Colored vulnerabilities on CLI</li> <li>Log full nuclei output</li> <li>Various bugfixes</li> <li>Better handling of:<ul> <li>DNS wildcards</li> <li>Infinite DNS-record chains</li> <li>Infinite HTTP redirects</li> </ul> </li> <li>Improved module tests</li> </ul>"},{"location":"release_history/#v103","title":"v1.0.3","text":"<p>October 12, 2022</p> <p>Changes:</p> <ul> <li>Tag URL events with their corresponding IP address</li> <li>Automatic docker hub publishing</li> <li>Added <code>retries</code> option for httpx module</li> <li>Added <code>asset_inventory</code> output module</li> <li>Improvements to nuclei module</li> <li>Avoid unnecessary failed sudo attempts during dependency install</li> <li>Improved Python API</li> <li>Added AnubisDB module</li> <li>Various bugfixes</li> <li>Add examples to <code>--help</code> output</li> <li>Reduce annoying warnings on free API modules</li> <li>Update iis_shortnames .jar dependency</li> <li>Updated documentation to explain targets, whitelists, blacklists</li> <li>Added help for module-specific options</li> <li>Added warning if unable to validate public DNS servers (for massdns)</li> <li>Various performance optimizations</li> <li>Various bugfixes</li> <li>Fix Pypi auto-publishing</li> <li>Added bug report template</li> <li>Added examples in README</li> <li>Improved wildcard detection</li> <li>Added DNS retry functionality</li> <li>Improved excavate hostname extraction</li> <li>Added command-line option for installing all dependencies</li> <li>Improved gowitness dependency install, improved tests</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#installation-troubleshooting","title":"Installation troubleshooting","text":"<ul> <li><code>Fatal error from pip prevented installation.</code></li> <li><code>ERROR: No matching distribution found for bbot</code></li> <li><code>bash: /home/user/.local/bin/bbot: /home/user/.local/pipx/venvs/bbot/bin/python: bad interpreter</code></li> </ul> <p>If you get errors resembling any of the above, it's probably because your Python version is too old. To install a newer version (3.9+ is required), you will need to do something like this: <pre><code># install a newer version of python\nsudo apt install python3.9 python3.9-venv\n# install pipx\npython3.9 -m pip install --user pipx\n# add pipx to your path\npython3.9 -m pipx ensurepath\n# reboot\nreboot\n# install bbot\npython3.9 -m pipx install bbot\n# run bbot\nbbot --help\n</code></pre></p>"},{"location":"troubleshooting/#modulenotfounderror","title":"<code>ModuleNotFoundError</code>","text":"<p>If you run into a <code>ModuleNotFoundError</code>, try running your <code>bbot</code> command again with <code>--force-deps</code>. This will repair your modules' Python dependencies.</p>"},{"location":"troubleshooting/#regenerate-config","title":"Regenerate Config","text":"<p>As a troubleshooting step it is sometimes useful to clear out your older configs and let BBOT generate new ones. This will ensure that new defaults are property restored, etc. <pre><code># make a backup of the old configs\nmv ~/.config/bbot ~/.config/bbot.bak\n\n# generate new configs\nbbot\n</code></pre></p>"},{"location":"dev/","title":"BBOT Developer Reference","text":"<p>BBOT exposes a convenient API that allows you to create, start, and stop scans using Python code.</p> <p>Documented in this section are commonly-used classes and functions within BBOT, along with usage examples.</p>"},{"location":"dev/#discord-bot-example","title":"Discord Bot Example","text":"<p>Below is a simple Discord bot designed to run BBOT scans.</p> <pre><code>import asyncio\nimport discord\nfrom discord.ext import commands\n\nfrom bbot.scanner import Scanner\nfrom bbot.modules import module_loader\nfrom bbot.modules.output.discord import Discord\n\n\n# make list of BBOT modules to enable for the scan\nbbot_modules = [\"excavate\", \"speculate\", \"aggregate\"]\nfor module_name, preloaded in module_loader.preloaded().items():\n    flags = preloaded[\"flags\"]\n    if \"subdomain-enum\" in flags and \"passive\" in flags and \"slow\" not in flags:\n        bbot_modules.append(module_name)\n\n\nclass BBOTDiscordBot(commands.Cog):\n\"\"\"\n    A simple Discord bot capable of running a BBOT scan.\n\n    To set up:\n        1. Go to Discord Developer Portal (https://discord.com/developers)\n        2. Create a new application\n        3. Create an invite link for the bot, visit the link to invite it to your server\n            - Your Application --&gt; OAuth2 --&gt; URL Generator\n                - For Scopes, select \"bot\"\"\n                - For Bot Permissions, select:\n                    - Read Messages/View Channels\n                    - Send Messages\n        4. Turn on \"Message Content Intent\"\n            - Your Application --&gt; Bot --&gt; Privileged Gateway Intents --&gt; Message Content Intent\n        5. Copy your Discord Bot Token and put it at the top this file\n            - Your Application --&gt; Bot --&gt; Reset Token\n        6. Run this script\n\n    To scan evilcorp.com, you would type:\n\n        /scan evilcorp.com\n\n    Results will be output to the same channel.\n    \"\"\"\n    def __init__(self):\n        self.current_scan = None\n\n    @commands.command(name=\"scan\", description=\"Scan a target with BBOT.\")\n    async def scan(self, ctx, target: str):\n        if self.current_scan is not None:\n            self.current_scan.stop()\n        await ctx.send(f\"Starting scan against {target}.\")\n\n        # creates scan instance\n        self.current_scan = Scanner(target, modules=bbot_modules)\n        discord_module = Discord(self.current_scan)\n\n        seen = set()\n        num_events = 0\n        # start scan and iterate through results\n        async for event in self.current_scan.async_start():\n            if hash(event) in seen:\n                continue\n            seen.add(hash(event))\n            await ctx.send(discord_module.format_message(event))\n            num_events += 1\n\n        await ctx.send(f\"Finished scan against {target}. {num_events:,} results.\")\n        self.current_scan = None\n\n\nif __name__ == \"__main__\":\n    intents = discord.Intents.default()\n    intents.message_content = True\n    bot = commands.Bot(command_prefix=\"/\", intents=intents)\n\n    @bot.event\n    async def on_ready():\n        print(f\"We have logged in as {bot.user}\")\n        await bot.add_cog(BBOTDiscordBot())\n\n    bot.run(\"DISCORD_BOT_TOKEN_HERE\")\n</code></pre> <p>Next Up: Scanner --&gt;</p>"},{"location":"dev/basemodule/","title":"BaseModule","text":""},{"location":"dev/basemodule/#bbot.modules.base.BaseModule","title":"BaseModule","text":"<p>The base class for all BBOT modules.</p> <p>Attributes:</p> <ul> <li> <code>watched_events</code>             (<code>List</code>)         \u2013          <p>Event types to watch.</p> </li> <li> <code>produced_events</code>             (<code>List</code>)         \u2013          <p>Event types to produce.</p> </li> <li> <code>meta</code>             (<code>Dict</code>)         \u2013          <p>Metadata about the module, such as whether authentication is required and a description.</p> </li> <li> <code>flags</code>             (<code>List</code>)         \u2013          <p>Flags indicating the type of module (must have at least \"safe\" or \"aggressive\" and \"passive\" or \"active\").</p> </li> <li> <code>deps_pip</code>             (<code>List</code>)         \u2013          <p>Python dependencies to install via pip. Empty list by default.</p> </li> <li> <code>deps_apt</code>             (<code>List</code>)         \u2013          <p>APT package dependencies to install. Empty list by default.</p> </li> <li> <code>deps_shell</code>             (<code>List</code>)         \u2013          <p>Other dependencies installed via shell commands. Uses ansible.builtin.shell. Empty list by default.</p> </li> <li> <code>deps_ansible</code>             (<code>List</code>)         \u2013          <p>Additional Ansible tasks for complex dependencies. Empty list by default.</p> </li> <li> <code>accept_dupes</code>             (<code>bool</code>)         \u2013          <p>Whether to accept incoming duplicate events. Default is False.</p> </li> <li> <code>suppress_dupes</code>             (<code>bool</code>)         \u2013          <p>Whether to suppress outgoing duplicate events. Default is True.</p> </li> <li> <code>per_host_only</code>             (<code>bool</code>)         \u2013          <p>Limit the module to only scanning once per host:port. Default is False.</p> </li> <li> <code>per_domain_only</code>             (<code>bool</code>)         \u2013          <p>Limit the module to only scanning once per domain. Default is False.</p> </li> <li> <code>scope_distance_modifier</code>             (<code>(int, None)</code>)         \u2013          <p>Modifies scope distance acceptance for events. Default is 0. <pre><code>None == accept all events\n2 == accept events up to and including the scan's configured search distance plus two\n1 == accept events up to and including the scan's configured search distance plus one\n0 == (DEFAULT) accept events up to and including the scan's configured search distance\n</code></pre></p> </li> <li> <code>target_only</code>             (<code>bool</code>)         \u2013          <p>Accept only the initial target event(s). Default is False.</p> </li> <li> <code>in_scope_only</code>             (<code>bool</code>)         \u2013          <p>Accept only explicitly in-scope events. Default is False.</p> </li> <li> <code>options</code>             (<code>Dict</code>)         \u2013          <p>Customizable options for the module, e.g., {\"api_key\": \"\"}. Empty dict by default.</p> </li> <li> <code>options_desc</code>             (<code>Dict</code>)         \u2013          <p>Descriptions for options, e.g., {\"api_key\": \"API Key\"}. Empty dict by default.</p> </li> <li> <code>max_event_handlers</code>             (<code>int</code>)         \u2013          <p>Maximum concurrent instances of handle_event() or handle_batch(). Default is 1.</p> </li> <li> <code>batch_size</code>             (<code>int</code>)         \u2013          <p>Size of batches processed by handle_batch(). Default is 1.</p> </li> <li> <code>batch_wait</code>             (<code>int</code>)         \u2013          <p>Seconds to wait before force-submitting a batch. Default is 10.</p> </li> <li> <code>failed_request_abort_threshold</code>             (<code>int</code>)         \u2013          <p>Threshold for setting error state after failed HTTP requests (only takes effect when <code>request_with_fail_count()</code> is used. Default is 5.</p> </li> <li> <code>_preserve_graph</code>             (<code>bool</code>)         \u2013          <p>When set to True, accept events that may be duplicates but are necessary for construction of complete graph. Typically only enabled for output modules that need to maintain full chains of events, e.g. <code>neo4j</code> and <code>json</code>. Default is False.</p> </li> <li> <code>_stats_exclude</code>             (<code>bool</code>)         \u2013          <p>Whether to exclude this module from scan statistics. Default is False.</p> </li> <li> <code>_qsize</code>             (<code>int</code>)         \u2013          <p>Outgoing queue size (0 for infinite). Default is 0.</p> </li> <li> <code>_priority</code>             (<code>int</code>)         \u2013          <p>Priority level of events raised by this module, 1-5. Default is 3.</p> </li> <li> <code>_name</code>             (<code>str</code>)         \u2013          <p>Module name, overridden automatically. Default is 'base'.</p> </li> <li> <code>_type</code>             (<code>str</code>)         \u2013          <p>Module type, for differentiating between normal and output modules. Default is 'scan'.</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>class BaseModule:\n\"\"\"The base class for all BBOT modules.\n\n    Attributes:\n        watched_events (List): Event types to watch.\n\n        produced_events (List): Event types to produce.\n\n        meta (Dict): Metadata about the module, such as whether authentication is required and a description.\n\n        flags (List): Flags indicating the type of module (must have at least \"safe\" or \"aggressive\" and \"passive\" or \"active\").\n\n        deps_pip (List): Python dependencies to install via pip. Empty list by default.\n\n        deps_apt (List): APT package dependencies to install. Empty list by default.\n\n        deps_shell (List): Other dependencies installed via shell commands. Uses [ansible.builtin.shell](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/shell_module.html). Empty list by default.\n\n        deps_ansible (List): Additional Ansible tasks for complex dependencies. Empty list by default.\n\n        accept_dupes (bool): Whether to accept incoming duplicate events. Default is False.\n\n        suppress_dupes (bool): Whether to suppress outgoing duplicate events. Default is True.\n\n        per_host_only (bool): Limit the module to only scanning once per host:port. Default is False.\n\n        per_domain_only (bool): Limit the module to only scanning once per domain. Default is False.\n\n        scope_distance_modifier (int, None): Modifies scope distance acceptance for events. Default is 0.\n            ```\n            None == accept all events\n            2 == accept events up to and including the scan's configured search distance plus two\n            1 == accept events up to and including the scan's configured search distance plus one\n            0 == (DEFAULT) accept events up to and including the scan's configured search distance\n            ```\n\n        target_only (bool): Accept only the initial target event(s). Default is False.\n\n        in_scope_only (bool): Accept only explicitly in-scope events. Default is False.\n\n        options (Dict): Customizable options for the module, e.g., {\"api_key\": \"\"}. Empty dict by default.\n\n        options_desc (Dict): Descriptions for options, e.g., {\"api_key\": \"API Key\"}. Empty dict by default.\n\n        max_event_handlers (int): Maximum concurrent instances of handle_event() or handle_batch(). Default is 1.\n\n        batch_size (int): Size of batches processed by handle_batch(). Default is 1.\n\n        batch_wait (int): Seconds to wait before force-submitting a batch. Default is 10.\n\n        failed_request_abort_threshold (int): Threshold for setting error state after failed HTTP requests (only takes effect when `request_with_fail_count()` is used. Default is 5.\n\n        _preserve_graph (bool): When set to True, accept events that may be duplicates but are necessary for construction of complete graph. Typically only enabled for output modules that need to maintain full chains of events, e.g. `neo4j` and `json`. Default is False.\n\n        _stats_exclude (bool): Whether to exclude this module from scan statistics. Default is False.\n\n        _qsize (int): Outgoing queue size (0 for infinite). Default is 0.\n\n        _priority (int): Priority level of events raised by this module, 1-5. Default is 3.\n\n        _name (str): Module name, overridden automatically. Default is 'base'.\n\n        _type (str): Module type, for differentiating between normal and output modules. Default is 'scan'.\n    \"\"\"\n\n    watched_events = []\n    produced_events = []\n    meta = {\"auth_required\": False, \"description\": \"Base module\"}\n    flags = []\n    options = {}\n    options_desc = {}\n\n    deps_pip = []\n    deps_apt = []\n    deps_shell = []\n    deps_ansible = []\n\n    accept_dupes = False\n    suppress_dupes = True\n    per_host_only = False\n    per_domain_only = False\n    scope_distance_modifier = 0\n    target_only = False\n    in_scope_only = False\n\n    _max_event_handlers = 1\n    _batch_size = 1\n    batch_wait = 10\n    failed_request_abort_threshold = 5\n\n    _preserve_graph = False\n    _stats_exclude = False\n    _qsize = 0\n    _priority = 3\n    _name = \"base\"\n    _type = \"scan\"\n\n    def __init__(self, scan):\n\"\"\"Initializes a module instance.\n\n        Args:\n            scan: The BBOT scan object associated with this module instance.\n\n        Attributes:\n            scan: The scan object associated with this module.\n\n            errored (bool): Whether the module has errored out. Default is False.\n        \"\"\"\n        self.scan = scan\n        self.errored = False\n        self._log = None\n        self._incoming_event_queue = None\n        self._outgoing_event_queue = None\n        # track incoming events to prevent unwanted duplicates\n        self._incoming_dup_tracker = set()\n        # seconds since we've submitted a batch\n        self._last_submitted_batch = None\n        # additional callbacks to be executed alongside self.cleanup()\n        self.cleanup_callbacks = []\n        self._cleanedup = False\n        self._watched_events = None\n\n        self._task_counter = TaskCounter()\n\n        # string constant\n        self._custom_filter_criteria_msg = \"it did not meet custom filter criteria\"\n\n        # track number of failures (for .request_with_fail_count())\n        self._request_failures = 0\n\n        self._tasks = []\n        self._event_received = asyncio.Condition()\n        self._event_queued = asyncio.Condition()\n\n        # used for optional \"per host\" tracking\n        self._per_host_tracker = set()\n\n    async def setup(self):\n\"\"\"Asynchronously sets up the module at the beginning of the scan.\n\n        This method can be overridden to perform any necessary setup logic.\n\n        Returns:\n            bool or None: True if setup was successful. None for a soft-fail, which will produce a warning but not abort the scan. False for a hard-fail, which will abort the scan.\n        \"\"\"\n        return True\n\n    async def handle_event(self, event):\n\"\"\"Asynchronously handles incoming events that the module is configured to watch.\n\n        This method is automatically invoked when an event that matches any in `watched_events` is encountered during a scan. Override this method to implement custom event-handling logic for your module.\n\n        Args:\n            event (Event): The event object containing details about the incoming event.\n\n        Note:\n            This method should be overridden if the `batch_size` attribute of the module is set to 1.\n\n        Returns:\n            None\n        \"\"\"\n        pass\n\n    def handle_batch(self, *events):\n\"\"\"Handles incoming events in batches for optimized processing.\n\n        This method is automatically called when multiple events that match any in `watched_events` are encountered and the `batch_size` attribute is set to a value greater than 1. Override this method to implement custom batch event-handling logic for your module.\n\n        Args:\n            *events (Event): A variable number of Event objects to be processed in a batch.\n\n        Note:\n            This method should be overridden if the `batch_size` attribute of the module is set to a value greater than 1.\n\n        Returns:\n            None\n        \"\"\"\n        pass\n\n    async def filter_event(self, event):\n\"\"\"Asynchronously filters incoming events based on custom criteria.\n\n        Override this method for more granular control over which events are accepted by your module. This method is called automatically before `handle_event()` for each incoming event that matches any in `watched_events`.\n\n        Args:\n            event (Event): The incoming Event object to be filtered.\n\n        Returns:\n            tuple: A 2-tuple where the first value is a bool indicating whether the event should be accepted, and the second value is a string explaining the reason for its acceptance or rejection. By default, returns `(True, None)` to indicate acceptance without reason.\n\n        Note:\n            This method should be overridden if the module requires custom logic for event filtering.\n        \"\"\"\n        return True\n\n    async def finish(self):\n\"\"\"Asynchronously performs final tasks as the scan nears completion.\n\n        This method can be overridden to execute any necessary finalization logic. For example, if the module relies on a word cloud, you might wait for the scan to finish to ensure the word cloud is most complete before running an operation.\n\n        Returns:\n            None\n\n        Warnings:\n            This method may be called multiple times since it can raise events, which may re-trigger the \"finish\" phase of the scan. Optional to override.\n        \"\"\"\n        return\n\n    async def report(self):\n\"\"\"Asynchronously executes a final task after the scan is complete but before cleanup.\n\n        This method can be overridden to aggregate data and raise summary events at the end of the scan.\n\n        Returns:\n            None\n\n        Note:\n            This method is called only once per scan.\n        \"\"\"\n        return\n\n    async def cleanup(self):\n\"\"\"Asynchronously performs final cleanup operations after the scan is complete.\n\n        This method can be overridden to implement custom cleanup logic. It is called only once per scan and may not raise events.\n\n        Returns:\n            None\n\n        Note:\n            This method is called only once per scan and may not raise events.\n        \"\"\"\n        return\n\n    async def require_api_key(self):\n\"\"\"\n        Asynchronously checks if an API key is required and valid.\n\n        Args:\n            None\n\n        Returns:\n            bool or tuple: Returns True if API key is valid and ready.\n                          Returns a tuple (None, \"error message\") otherwise.\n\n        Notes:\n            - Fetches the API key from the configuration.\n            - Calls the 'ping()' method to test API accessibility.\n            - Sets the API key readiness status accordingly.\n        \"\"\"\n        self.api_key = self.config.get(\"api_key\", \"\")\n        if self.auth_secret:\n            try:\n                await self.ping()\n                self.hugesuccess(f\"API is ready\")\n                return True\n            except Exception as e:\n                return None, f\"Error with API ({str(e).strip()})\"\n        else:\n            return None, \"No API key set\"\n\n    async def ping(self):\n\"\"\"Asynchronously checks the health of the configured API.\n\n        This method is used in conjunction with require_api_key() to verify that the API is not just configured, but also responsive. This method should include an assert statement to validate the API's health, typically by making a test request to a known endpoint.\n\n        Example Usage:\n            In your implementation, if the API has a \"/ping\" endpoint:\n            async def ping(self):\n                r = await self.request_with_fail_count(f\"{self.base_url}/ping\")\n                resp_content = getattr(r, \"text\", \"\")\n                assert getattr(r, \"status_code\", 0) == 200, resp_content\n\n        Returns:\n            None\n\n        Raises:\n            AssertionError: If the API does not respond as expected.\n        \"\"\"\n        return\n\n    @property\n    def batch_size(self):\n        batch_size = self.config.get(\"batch_size\", None)\n        # only allow overriding the batch size if its default value is greater than 1\n        # this prevents modules from being accidentally neutered by an incorect batch_size setting\n        if batch_size is None or self._batch_size == 1:\n            batch_size = self._batch_size\n        return batch_size\n\n    @property\n    def max_event_handlers(self):\n        max_event_handlers = self.config.get(\"max_event_handlers\", None)\n        if max_event_handlers is None:\n            max_event_handlers = self._max_event_handlers\n        return max_event_handlers\n\n    @property\n    def auth_secret(self):\n\"\"\"Indicates if the module is properly configured for authentication.\n\n        This read-only property should be used to check whether all necessary attributes (e.g., API keys, tokens, etc.) are configured to perform authenticated requests in the module. Commonly used in setup or initialization steps.\n\n        Returns:\n            bool: True if the module is properly configured for authentication, otherwise False.\n        \"\"\"\n        return getattr(self, \"api_key\", \"\")\n\n    def get_watched_events(self):\n\"\"\"Retrieve the set of events that the module is interested in observing.\n\n        Override this method if the set of events the module should watch needs to be determined dynamically, e.g., based on configuration options or other runtime conditions.\n\n        Returns:\n            set: The set of event types that this module will handle.\n        \"\"\"\n        if self._watched_events is None:\n            self._watched_events = set(self.watched_events)\n        return self._watched_events\n\n    async def _handle_batch(self):\n\"\"\"\n        Asynchronously handles a batch of events in the module.\n\n        Args:\n            None\n\n        Returns:\n            bool: True if events were submitted for processing, False otherwise.\n\n        Notes:\n            - The method is wrapped in a task counter to monitor asynchronous operations.\n            - Checks if there are any events in the incoming queue and module is not in an error state.\n            - Invokes '_events_waiting()' to fetch a batch of events.\n            - Calls the module's 'handle_batch()' method to process these events.\n            - If a \"FINISHED\" event is found, invokes 'finish()' method of the module.\n        \"\"\"\n        finish = False\n        async with self._task_counter.count(f\"{self.name}.handle_batch()\"):\n            submitted = False\n            if self.batch_size &lt;= 1:\n                return\n            if self.num_incoming_events &gt; 0:\n                events, finish = await self._events_waiting()\n                if events and not self.errored:\n                    self.debug(f\"Handling batch of {len(events):,} events\")\n                    submitted = True\n                    async with self.scan._acatch(f\"{self.name}.handle_batch()\"):\n                        await self.handle_batch(*events)\n                    self.debug(f\"Finished handling batch of {len(events):,} events\")\n        if finish:\n            context = f\"{self.name}.finish()\"\n            async with self.scan._acatch(context), self._task_counter.count(context):\n                await self.finish()\n        return submitted\n\n    def make_event(self, *args, **kwargs):\n\"\"\"Create an event for the scan.\n\n        Raises a validation error if the event could not be created, unless raise_error is set to False.\n\n        Args:\n            *args: Positional arguments to be passed to the scan's make_event method.\n            **kwargs: Keyword arguments to be passed to the scan's make_event method.\n            raise_error (bool, optional): Whether to raise a validation error if the event could not be created. Defaults to False.\n\n        Examples:\n            &gt;&gt;&gt; new_event = self.make_event(\"1.2.3.4\", source=event)\n            &gt;&gt;&gt; self.emit_event(new_event)\n\n        Returns:\n            Event or None: The created event, or None if a validation error occurred and raise_error was False.\n\n        Raises:\n            ValidationError: If the event could not be validated and raise_error is True.\n        \"\"\"\n        raise_error = kwargs.pop(\"raise_error\", False)\n        try:\n            event = self.scan.make_event(*args, **kwargs)\n        except ValidationError as e:\n            if raise_error:\n                raise\n            self.warning(f\"{e}\")\n            return\n        if not event.module:\n            event.module = self\n        return event\n\n    def emit_event(self, *args, **kwargs):\n\"\"\"Emit an event to the event queue and distribute it to interested modules.\n\n        This is how modules \"return\" data.\n\n        The method first creates an event object by calling `self.make_event()` with the provided arguments.\n        Then, the event is queued for outgoing distribution using `self.queue_outgoing_event()`.\n\n        Args:\n            *args: Positional arguments to be passed to `self.make_event()` for event creation.\n            **kwargs: Keyword arguments to be passed for event creation or configuration of the emit action.\n                ```markdown\n                - on_success_callback: Optional callback function to execute upon successful event emission.\n                - abort_if: Optional condition under which the event emission should be aborted.\n                - quick: Optional flag to indicate whether the event should be processed quickly.\n                ```\n\n        Examples:\n            &gt;&gt;&gt; self.emit_event(\"www.evilcorp.com\", source=event, tags=[\"affiliate\"])\n\n            &gt;&gt;&gt; new_event = self.make_event(\"1.2.3.4\", source=event)\n            &gt;&gt;&gt; self.emit_event(new_event)\n\n        Returns:\n            None\n\n        Raises:\n            ValidationError: If the event cannot be validated (handled in `self.make_event()`).\n        \"\"\"\n        event_kwargs = dict(kwargs)\n        emit_kwargs = {}\n        for o in (\"on_success_callback\", \"abort_if\", \"quick\"):\n            v = event_kwargs.pop(o, None)\n            if v is not None:\n                emit_kwargs[o] = v\n        event = self.make_event(*args, **event_kwargs)\n        if event:\n            self.queue_outgoing_event(event, **emit_kwargs)\n\n    async def emit_event_wait(self, *args, **kwargs):\n\"\"\"Emit an event to the event queue and await until there is space in the outgoing queue.\n\n        This method is similar to `emit_event`, but it waits until there's sufficient space in the outgoing\n        event queue before emitting the event. It utilizes the queue size threshold defined in `self._qsize`.\n\n        Args:\n            *args: Positional arguments to be passed to `emit_event()` for event creation.\n            **kwargs: Keyword arguments to be passed to `emit_event()` for event creation or configuration.\n\n        Returns:\n            None\n\n        See Also:\n            emit_event: For emitting an event without waiting on the queue size.\n        \"\"\"\n        while self.outgoing_event_queue.qsize() &gt; self._qsize:\n            await self.helpers.sleep(0.2)\n        return self.emit_event(*args, **kwargs)\n\n    async def _events_waiting(self):\n\"\"\"\n        Asynchronously fetches events from the incoming_event_queue, up to a specified batch size.\n\n        Args:\n            None\n\n        Returns:\n            tuple: A tuple containing two elements:\n                - events (list): A list of acceptable events from the queue.\n                - finish (bool): A flag indicating if a \"FINISHED\" event is encountered.\n\n        Notes:\n            - The method pulls events from incoming_event_queue using 'get_nowait()'.\n            - Events go through '_event_postcheck()' for validation.\n            - \"FINISHED\" events are handled differently and the finish flag is set to True.\n            - If the queue is empty or the batch size is reached, the loop breaks.\n        \"\"\"\n        events = []\n        finish = False\n        while self.incoming_event_queue:\n            if len(events) &gt; self.batch_size:\n                break\n            try:\n                event = self.incoming_event_queue.get_nowait()\n                self.debug(f\"Got {event} from {getattr(event, 'module', 'unknown_module')}\")\n                acceptable, reason = await self._event_postcheck(event)\n                if acceptable:\n                    if event.type == \"FINISHED\":\n                        finish = True\n                    else:\n                        events.append(event)\n                        self.scan.stats.event_consumed(event, self)\n                elif reason:\n                    self.debug(f\"Not accepting {event} because {reason}\")\n            except asyncio.queues.QueueEmpty:\n                break\n        return events, finish\n\n    @property\n    def num_incoming_events(self):\n        ret = 0\n        if self.incoming_event_queue is not False:\n            ret = self.incoming_event_queue.qsize()\n        return ret\n\n    def start(self):\n        self._tasks = [asyncio.create_task(self._worker()) for _ in range(self.max_event_handlers)]\n\n    async def _setup(self):\n\"\"\"\n        Asynchronously sets up the module by invoking its 'setup()' method.\n\n        This method catches exceptions during setup, sets the module's error state if necessary, and determines the\n        status code based on the result of the setup process.\n\n        Args:\n            None\n\n        Returns:\n            tuple: A tuple containing the module's name, status (True for success, False for hard-fail, None for soft-fail),\n            and an optional status message.\n\n        Raises:\n            Exception: Captured exceptions from the 'setup()' method are logged, but not propagated.\n\n        Notes:\n            - The 'setup()' method can return either a simple boolean status or a tuple of status and message.\n            - A WordlistError exception triggers a soft-fail status.\n            - The debug log will contain setup status information for the module.\n        \"\"\"\n        status_codes = {False: \"hard-fail\", None: \"soft-fail\", True: \"success\"}\n\n        status = False\n        self.debug(f\"Setting up module {self.name}\")\n        try:\n            result = await self.setup()\n            if type(result) == tuple and len(result) == 2:\n                status, msg = result\n            else:\n                status = result\n                msg = status_codes[status]\n            self.debug(f\"Finished setting up module {self.name}\")\n        except Exception as e:\n            self.set_error_state()\n            msg = f\"{e}\"\n            self.trace()\n        return self.name, status, str(msg)\n\n    async def _worker(self):\n\"\"\"\n        The core worker loop for the module, responsible for handling events from the incoming event queue.\n\n        This method is a coroutine and is run asynchronously. Multiple instances can run simultaneously based on\n        the 'max_event_handlers' configuration. The worker dequeues events from 'incoming_event_queue', performs\n        necessary prechecks, and passes the event to the appropriate handler function.\n\n        Args:\n            None\n\n        Returns:\n            None\n\n        Raises:\n            asyncio.CancelledError: If the worker is cancelled during its operation.\n\n        Notes:\n            - The worker is sensitive to the 'stopping' flag of the scan. It will terminate if this flag is set.\n            - The worker handles backpressure by pausing when the outgoing event queue is full.\n            - Batch processing is supported and is activated when 'batch_size' &gt; 1.\n            - Each event is subject to a post-check via '_event_postcheck()' to decide whether it should be handled.\n            - Special 'FINISHED' events trigger the 'finish()' method of the module.\n        \"\"\"\n        async with self.scan._acatch(context=self._worker):\n            try:\n                while not self.scan.stopping and not self.errored:\n                    # hold the reigns if our outgoing queue is full\n                    if self._qsize &gt; 0 and self.outgoing_event_queue.qsize() &gt;= self._qsize:\n                        await asyncio.sleep(0.1)\n                        continue\n\n                    if self.batch_size &gt; 1:\n                        submitted = await self._handle_batch()\n                        if not submitted:\n                            async with self._event_received:\n                                await self._event_received.wait()\n\n                    else:\n                        try:\n                            if self.incoming_event_queue is not False:\n                                event = await self.incoming_event_queue.get()\n                            else:\n                                self.debug(f\"Event queue is in bad state\")\n                                break\n                        except asyncio.queues.QueueEmpty:\n                            continue\n                        self.debug(f\"Got {event} from {getattr(event, 'module', 'unknown_module')}\")\n                        async with self._task_counter.count(f\"event_postcheck({event})\"):\n                            acceptable, reason = await self._event_postcheck(event)\n                        if acceptable:\n                            if event.type == \"FINISHED\":\n                                context = f\"{self.name}.finish()\"\n                                async with self.scan._acatch(context), self._task_counter.count(context):\n                                    await self.finish()\n                            else:\n                                context = f\"{self.name}.handle_event({event})\"\n                                self.scan.stats.event_consumed(event, self)\n                                self.debug(f\"Handling {event}\")\n                                async with self.scan._acatch(context), self._task_counter.count(context):\n                                    await self.handle_event(event)\n                                self.debug(f\"Finished handling {event}\")\n                        else:\n                            self.debug(f\"Not accepting {event} because {reason}\")\n            except asyncio.CancelledError:\n                self.log.trace(\"Worker cancelled\")\n                raise\n        self.log.trace(f\"Worker stopped\")\n\n    @property\n    def max_scope_distance(self):\n        if self.in_scope_only or self.target_only:\n            return 0\n        return max(0, self.scan.scope_search_distance + self.scope_distance_modifier)\n\n    def _event_precheck(self, event):\n\"\"\"\n        Pre-checks an event to determine if it should be accepted by the module for queuing.\n\n        This method is called when an event is about to be enqueued into the module's incoming event queue.\n        It applies various filters such as special signal event types, module error state, watched event types, and more\n        to decide whether or not the event should be enqueued.\n\n        Args:\n            event (Event): The event object to check.\n\n        Returns:\n            tuple: A tuple (bool, str) where the bool indicates if the event should be accepted, and the str gives the reason.\n\n        Examples:\n            &gt;&gt;&gt; result, reason = self._event_precheck(event)\n            &gt;&gt;&gt; if result:\n            ...     self.incoming_event_queue.put_nowait(event)\n            ... else:\n            ...     self.debug(f\"Not accepting {event} because {reason}\")\n\n        Notes:\n            - The method considers special signal event types like \"FINISHED\".\n            - Checks whether the module is in an error state.\n            - Checks if the event type matches the types this module is interested in (`watched_events`).\n            - Checks for events tagged as 'target' if the module has `target_only` flag set.\n            - Applies specific filtering based on event type and module name.\n        \"\"\"\n\n        # special signal event types\n        if event.type in (\"FINISHED\",):\n            return True, \"its type is FINISHED\"\n        if self.errored:\n            return False, f\"module is in error state\"\n        # exclude non-watched types\n        if not any(t in self.get_watched_events() for t in (\"*\", event.type)):\n            return False, \"its type is not in watched_events\"\n        if self.target_only:\n            if \"target\" not in event.tags:\n                return False, \"it did not meet target_only filter criteria\"\n        # exclude certain URLs (e.g. javascript):\n        if event.type.startswith(\"URL\") and self.name != \"httpx\" and \"httpx-only\" in event.tags:\n            return False, \"its extension was listed in url_extension_httpx_only\"\n        # if event is an IP address that was speculated from a CIDR\n        source_is_range = getattr(event.source, \"type\", \"\") == \"IP_RANGE\"\n        if (\n            source_is_range\n            and event.type == \"IP_ADDRESS\"\n            and str(event.module) == \"speculate\"\n            and self.name != \"speculate\"\n        ):\n            # and the current module listens for both ranges and CIDRs\n            if all([x in self.watched_events for x in (\"IP_RANGE\", \"IP_ADDRESS\")]):\n                # then skip the event.\n                # this helps avoid double-portscanning both an individual IP and its parent CIDR.\n                return False, \"module consumes IP ranges directly\"\n\n        return True, \"precheck succeeded\"\n\n    async def _event_postcheck(self, event):\n\"\"\"\n        A simple wrapper for dup tracking\n        \"\"\"\n        acceptable, reason = await self.__event_postcheck(event)\n        if acceptable:\n            # check duplicates\n            is_incoming_duplicate = self.is_incoming_duplicate(event, add=True)\n            if is_incoming_duplicate and not self.accept_dupes:\n                return False, f\"module has already seen {event}\"\n\n        return acceptable, reason\n\n    async def __event_postcheck(self, event):\n\"\"\"\n        Post-checks an event to determine if it should be accepted by the module for handling.\n\n        This method is called when an event is dequeued from the module's incoming event queue, right before it is actually processed.\n        It applies various filters such as scope, custom filtering logic, and per-host tracking to decide the event's fate.\n\n        Args:\n            event (Event): The event object to check.\n\n        Returns:\n            tuple: A tuple (bool, str) where the bool indicates if the event should be accepted, and the str gives the reason.\n\n        Notes:\n            - Override the `filter_event` method for custom filtering logic.\n            - This method also maintains host-based tracking when the `per_host_only` flag is set.\n            - The method will also update event production stats for output modules.\n        \"\"\"\n        # special exception for \"FINISHED\" event\n        if event.type in (\"FINISHED\",):\n            return True, \"\"\n\n        # force-output certain events to the graph\n        if self._is_graph_important(event):\n            return True, \"event is critical to the graph\"\n\n        # don't send out-of-scope targets to active modules\n        # this only takes effect if your target and whitelist are different\n        # TODO: the logic here seems incomplete, it could probably use some work.\n        if \"active\" in self.flags and \"target\" in event.tags and event not in self.scan.whitelist:\n            return False, \"it is not in whitelist and module has active flag\"\n\n        # check scope distance\n        filter_result, reason = self._scope_distance_check(event)\n        if not filter_result:\n            return filter_result, reason\n\n        # custom filtering\n        async with self.scan._acatch(context=self.filter_event):\n            filter_result = await self.filter_event(event)\n            msg = str(self._custom_filter_criteria_msg)\n            with suppress(ValueError, TypeError):\n                filter_result, reason = filter_result\n                msg += f\": {reason}\"\n            if not filter_result:\n                return False, msg\n\n        if self.per_host_only:\n            _hash = self.get_per_host_hash(event)\n            if _hash in self._per_host_tracker:\n                return False, \"per_host_only enabled and already seen host\"\n            else:\n                self._per_host_tracker.add(_hash)\n\n        if self.per_domain_only:\n            _hash = self.get_per_domain_hash(event)\n            if _hash in self._per_host_tracker:\n                return False, \"per_domain_only enabled and already seen domain\"\n            else:\n                self._per_host_tracker.add(_hash)\n\n        if self._type == \"output\" and not event._stats_recorded:\n            event._stats_recorded = True\n            self.scan.stats.event_produced(event)\n\n        self.debug(f\"{event} passed post-check\")\n        return True, \"\"\n\n    def _scope_distance_check(self, event):\n        if self.in_scope_only:\n            if event.scope_distance &gt; 0:\n                return False, \"it did not meet in_scope_only filter criteria\"\n        if self.scope_distance_modifier is not None:\n            if event.scope_distance &lt; 0:\n                return False, f\"its scope_distance ({event.scope_distance}) is invalid.\"\n            elif event.scope_distance &gt; self.max_scope_distance:\n                return (\n                    False,\n                    f\"its scope_distance ({event.scope_distance}) exceeds the maximum allowed by the scan ({self.scan.scope_search_distance}) + the module ({self.scope_distance_modifier}) == {self.max_scope_distance}\",\n                )\n        return True, \"\"\n\n    async def _cleanup(self):\n        if not self._cleanedup:\n            self._cleanedup = True\n            for callback in [self.cleanup] + self.cleanup_callbacks:\n                context = f\"{self.name}.cleanup()\"\n                if callable(callback):\n                    async with self.scan._acatch(context), self._task_counter.count(context):\n                        await self.helpers.execute_sync_or_async(callback)\n\n    async def queue_event(self, event, precheck=True):\n\"\"\"\n        Asynchronously queues an incoming event to the module's event queue for further processing.\n\n        The function performs an initial check to see if the event is acceptable for queuing.\n        If the event passes the check, it is put into the `incoming_event_queue`.\n\n        Args:\n            event: The event object to be queued.\n\n        Returns:\n            None: The function doesn't return anything but modifies the state of the `incoming_event_queue`.\n\n        Examples:\n            &gt;&gt;&gt; await self.queue_event(some_event)\n\n        Raises:\n            AttributeError: If the module is not in an acceptable state to queue incoming events.\n        \"\"\"\n        async with self._task_counter.count(\"queue_event()\", _log=False):\n            if self.incoming_event_queue is False:\n                self.debug(f\"Not in an acceptable state to queue incoming event\")\n                return\n            acceptable, reason = True, \"precheck was skipped\"\n            if precheck:\n                acceptable, reason = self._event_precheck(event)\n            if not acceptable:\n                if reason and reason != \"its type is not in watched_events\":\n                    self.debug(f\"Not accepting {event} because {reason}\")\n                return\n            else:\n                self.debug(f\"Accepting {event} because {reason}\")\n            try:\n                self.incoming_event_queue.put_nowait(event)\n                async with self._event_received:\n                    self._event_received.notify()\n                if event.type != \"FINISHED\":\n                    self.scan.manager._new_activity = True\n            except AttributeError:\n                self.debug(f\"Not in an acceptable state to queue incoming event\")\n\n    def queue_outgoing_event(self, event, **kwargs):\n\"\"\"\n        Queues an outgoing event to the module's outgoing event queue for further processing.\n\n        The function attempts to put the event into the `outgoing_event_queue` immediately.\n        If it's not possible due to the current state of the module, an AttributeError is raised, and a debug log is generated.\n\n        Args:\n            event: The event object to be queued.\n            **kwargs: Additional keyword arguments to be associated with the event.\n\n        Returns:\n            None: The function doesn't return anything but modifies the state of the `outgoing_event_queue`.\n\n        Examples:\n            &gt;&gt;&gt; self.queue_outgoing_event(some_outgoing_event, abort_if=lambda e: \"unresolved\" in e.tags)\n\n        Raises:\n            AttributeError: If the module is not in an acceptable state to queue outgoing events.\n        \"\"\"\n        try:\n            self.outgoing_event_queue.put_nowait((event, kwargs))\n        except AttributeError:\n            self.debug(f\"Not in an acceptable state to queue outgoing event\")\n\n    def set_error_state(self, message=None, clear_outgoing_queue=False):\n\"\"\"\n        Puts the module into an errored state where it cannot accept new events. Optionally logs a warning message.\n\n        The function sets the module's `errored` attribute to True and logs a warning with the optional message.\n        It also clears the incoming event queue to prevent further processing and updates its status to False.\n\n        Args:\n            message (str, optional): Additional message to be logged along with the warning.\n\n        Returns:\n            None: The function doesn't return anything but updates the `errored` state and clears the incoming event queue.\n\n        Examples:\n            &gt;&gt;&gt; self.set_error_state()\n            &gt;&gt;&gt; self.set_error_state(\"Failed to connect to the server\")\n\n        Notes:\n            - The function sets `self._incoming_event_queue` to False to prevent its further use.\n            - If the module was already in an errored state, the function will not reset the error state or the queue.\n        \"\"\"\n        if not self.errored:\n            log_msg = f\"Setting error state for module {self.name}\"\n            if message is not None:\n                log_msg += f\": {message}\"\n            self.warning(log_msg)\n            self.errored = True\n            # clear incoming queue\n            if self.incoming_event_queue is not False:\n                self.debug(f\"Emptying event_queue\")\n                with suppress(asyncio.queues.QueueEmpty):\n                    while 1:\n                        self.incoming_event_queue.get_nowait()\n                # set queue to None to prevent its use\n                # if there are leftover objects in the queue, the scan will hang.\n                self._incoming_event_queue = False\n\n            if clear_outgoing_queue:\n                with suppress(asyncio.queues.QueueEmpty):\n                    while 1:\n                        self.outgoing_event_queue.get_nowait()\n\n    def is_incoming_duplicate(self, event, add=False):\n        event_hash = self._incoming_dedup_hash(event)\n        is_dup = event_hash in self._incoming_dup_tracker\n        if add:\n            self._incoming_dup_tracker.add(event_hash)\n        return is_dup\n\n    def _incoming_dedup_hash(self, event):\n\"\"\"\n        Determines the criteria for what is considered to be a duplicate event if `accept_dupes` is False.\n        \"\"\"\n        if self.per_host_only:\n            return self.get_per_host_hash(event)\n        elif self.per_domain_only:\n            return self.get_per_domain_hash(event)\n        return hash(event)\n\n    def _outgoing_dedup_hash(self, event):\n\"\"\"\n        Determines the criteria for what is considered to be a duplicate event if `suppress_dupes` is True.\n        \"\"\"\n        return hash(event)\n\n    def get_per_host_hash(self, event):\n\"\"\"\n        Computes a per-host hash value for a given event. This method may be optionally overridden in subclasses.\n\n        The function uses the event's `host` and `port` or the parsed URL to create a string to be hashed.\n        The hash value is used for distinguishing events related to the same host.\n\n        Args:\n            event (Event): The event object containing host, port, or parsed URL information.\n\n        Returns:\n            int: The hash value computed for the host.\n\n        Examples:\n            &gt;&gt;&gt; event = self.make_event(\"https://example.com:8443\")\n            &gt;&gt;&gt; self.get_per_host_hash(event)\n\n        Notes:\n            - To change the behavior, override this method in your custom module.\n            - The hash value is dependent on the `host` and `port` or the `parsed` attribute in the event object.\n        \"\"\"\n        parsed = getattr(event, \"parsed\", None)\n        if parsed is None:\n            to_hash = self.helpers.make_netloc(event.host, event.port)\n        else:\n            to_hash = f\"{parsed.scheme}://{parsed.netloc}/\"\n        return hash(to_hash)\n\n    def get_per_domain_hash(self, event):\n\"\"\"\n        Computes a per-domain hash value for a given event. This method may be optionally overridden in subclasses.\n\n        Events with the same root domain will receive the same hash value.\n\n        Args:\n            event (Event): The event object containing host, port, or parsed URL information.\n\n        Returns:\n            int: The hash value computed for the domain.\n\n        Examples:\n            &gt;&gt;&gt; event = self.make_event(\"https://www.example.com:8443\")\n            &gt;&gt;&gt; self.get_per_domain_hash(event)\n        \"\"\"\n        _, domain = self.helpers.split_domain(event.host)\n        return hash(domain)\n\n    @property\n    def name(self):\n        return str(self._name)\n\n    @property\n    def helpers(self):\n        return self.scan.helpers\n\n    @property\n    def status(self):\n\"\"\"\n        Provides the current status of the module as a dictionary.\n\n        The dictionary contains the following keys:\n            - 'events': A sub-dictionary with 'incoming' and 'outgoing' keys, representing the number of events in the respective queues.\n            - 'tasks': The current value of the task counter.\n            - 'errored': A boolean value indicating if the module is in an error state.\n            - 'running': A boolean value indicating if the module is currently processing data.\n\n        Returns:\n            dict: A dictionary containing the current status of the module.\n\n        Examples:\n            &gt;&gt;&gt; self.status\n            {'events': {'incoming': 5, 'outgoing': 2}, 'tasks': 3, 'errored': False, 'running': True}\n        \"\"\"\n        status = {\n            \"events\": {\"incoming\": self.num_incoming_events, \"outgoing\": self.outgoing_event_queue.qsize()},\n            \"tasks\": self._task_counter.value,\n            \"errored\": self.errored,\n        }\n        status[\"running\"] = self.running\n        return status\n\n    @property\n    def running(self):\n\"\"\"Property indicating whether the module is currently processing data.\n\n        This property checks if the task counter (`self._task_counter.value`) is greater than zero,\n        indicating that there are ongoing tasks in the module.\n\n        Returns:\n            bool: True if the module is currently processing data, False otherwise.\n        \"\"\"\n        return self._task_counter.value &gt; 0\n\n    @property\n    def finished(self):\n\"\"\"Property indicating whether the module has finished processing.\n\n        This property checks three conditions to determine if the module is finished:\n        1. The module is not currently running (`self.running` is False).\n        2. The number of incoming events in the queue is zero or less (`self.num_incoming_events &lt;= 0`).\n        3. The number of outgoing events in the queue is zero or less (`self.outgoing_event_queue.qsize() &lt;= 0`).\n\n        Returns:\n            bool: True if the module has finished processing, False otherwise.\n        \"\"\"\n        return not self.running and self.num_incoming_events &lt;= 0 and self.outgoing_event_queue.qsize() &lt;= 0\n\n    async def request_with_fail_count(self, *args, **kwargs):\n\"\"\"Asynchronously perform an HTTP request while keeping track of consecutive failures.\n\n        This function wraps the `self.helpers.request` method, incrementing a failure counter if\n        the request returns None. When the failure counter exceeds `self.failed_request_abort_threshold`,\n        the module is set to an error state.\n\n        Args:\n            *args: Positional arguments to pass to `self.helpers.request`.\n            **kwargs: Keyword arguments to pass to `self.helpers.request`.\n\n        Returns:\n            Any: The response object or None if the request failed.\n\n        Raises:\n            None: Sets the module to an error state when the failure threshold is reached.\n        \"\"\"\n        r = await self.helpers.request(*args, **kwargs)\n        if r is None:\n            self._request_failures += 1\n        else:\n            self._request_failures = 0\n        if self._request_failures &gt;= self.failed_request_abort_threshold:\n            self.set_error_state(f\"Setting error state due to {self._request_failures:,} failed HTTP requests\")\n        return r\n\n    @property\n    def config(self):\n\"\"\"Property that provides easy access to the module's configuration in the scan's config.\n\n        This property serves as a shortcut to retrieve the module-specific configuration from\n        `self.scan.config`. If no configuration is found for this module, an empty dictionary is returned.\n\n        Returns:\n            dict: The configuration dictionary specific to this module.\n        \"\"\"\n        config = self.scan.config.get(\"modules\", {}).get(self.name, {})\n        if config is None:\n            config = {}\n        return config\n\n    @property\n    def incoming_event_queue(self):\n        if self._incoming_event_queue is None:\n            self._incoming_event_queue = asyncio.PriorityQueue()\n        return self._incoming_event_queue\n\n    @property\n    def outgoing_event_queue(self):\n        if self._outgoing_event_queue is None:\n            self._outgoing_event_queue = asyncio.PriorityQueue()\n        return self._outgoing_event_queue\n\n    @property\n    def priority(self):\n\"\"\"\n        Gets the priority level of the module as an integer.\n\n        The priority level is constrained to be between 1 and 5, inclusive.\n        A lower value indicates a higher priority.\n\n        Returns:\n            int: The priority level of the module, constrained between 1 and 5.\n\n        Examples:\n            &gt;&gt;&gt; self.priority\n            3\n        \"\"\"\n        return int(max(1, min(5, self._priority)))\n\n    @property\n    def auth_required(self):\n        return self.meta.get(\"auth_required\", False)\n\n    @property\n    def http_timeout(self):\n\"\"\"\n        Convenience shortcut to `http_timeout` in the config\n        \"\"\"\n        return self.scan.config.get(\"http_timeout\", 10)\n\n    @property\n    def log(self):\n        if getattr(self, \"_log\", None) is None:\n            self._log = logging.getLogger(f\"bbot.modules.{self.name}\")\n        return self._log\n\n    @property\n    def memory_usage(self):\n\"\"\"Property that calculates the current memory usage of the module in bytes.\n\n        This property uses the `get_size` function to estimate the memory consumption\n        of the module object. The depth of the object graph traversal is limited to 3 levels\n        to avoid performance issues. Commonly shared objects like `self.scan`, `self.helpers`,\n        are excluded from the calculation to prevent double-counting.\n\n        Returns:\n            int: The estimated memory usage of the module in bytes.\n        \"\"\"\n        seen = {self.scan, self.helpers, self.log}  # noqa\n        return get_size(self, max_depth=3, seen=seen)\n\n    def __str__(self):\n        return self.name\n\n    def log_table(self, *args, **kwargs):\n\"\"\"Logs a table to the console and optionally writes it to a file.\n\n        This function generates a table using `self.helpers.make_table`, then logs each line\n        of the table as an info-level log. If a table_name is provided, it also writes the table to a file.\n\n        Args:\n            *args: Variable length argument list to be passed to `self.helpers.make_table`.\n            **kwargs: Arbitrary keyword arguments. If 'table_name' is specified, the table will be written to a file.\n\n        Returns:\n            str: The generated table as a string.\n\n        Examples:\n            &gt;&gt;&gt; self.log_table(['Header1', 'Header2'], [['row1col1', 'row1col2'], ['row2col1', 'row2col2']], table_name=\"my_table\")\n        \"\"\"\n        table_name = kwargs.pop(\"table_name\", None)\n        table = self.helpers.make_table(*args, **kwargs)\n        for line in table.splitlines():\n            self.info(line)\n        if table_name is not None:\n            date = self.helpers.make_date()\n            filename = self.scan.home / f\"{self.helpers.tagify(table_name)}-table-{date}.txt\"\n            with open(filename, \"w\") as f:\n                f.write(table)\n            self.verbose(f\"Wrote {table_name} to {filename}\")\n        return table\n\n    def _is_graph_important(self, event):\n        return self._preserve_graph and getattr(event, \"_graph_important\", False)\n\n    def stdout(self, *args, **kwargs):\n\"\"\"Writes log messages directly to standard output.\n\n        This is typically reserved for output modules only, e.g. `human` or `json`.\n\n        Args:\n            *args: Variable length argument list to be passed to `self.log.stdout`.\n            **kwargs: Arbitrary keyword arguments to be passed to `self.log.stdout`.\n\n        Examples:\n            &gt;&gt;&gt; self.stdout(\"This will be printed to stdout\")\n        \"\"\"\n        self.log.stdout(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n\n    def debug(self, *args, trace=False, **kwargs):\n\"\"\"Logs debug messages and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.debug(\"This is a debug message\")\n            &gt;&gt;&gt; self.debug(\"This is a debug message with a trace\", trace=True)\n        \"\"\"\n        self.log.debug(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def verbose(self, *args, trace=False, **kwargs):\n\"\"\"Logs messages and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.verbose(\"This is a verbose message\")\n            &gt;&gt;&gt; self.verbose(\"This is a verbose message with a trace\", trace=True)\n        \"\"\"\n        self.log.verbose(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def hugeverbose(self, *args, trace=False, **kwargs):\n\"\"\"Logs a whole message in emboldened white text, and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.hugeverbose(\"This is a huge verbose message\")\n            &gt;&gt;&gt; self.hugeverbose(\"This is a huge verbose message with a trace\", trace=True)\n        \"\"\"\n        self.log.hugeverbose(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def info(self, *args, trace=False, **kwargs):\n\"\"\"Logs informational messages and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.info(\"This is an informational message\")\n            &gt;&gt;&gt; self.info(\"This is an informational message with a trace\", trace=True)\n        \"\"\"\n        self.log.info(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def hugeinfo(self, *args, trace=False, **kwargs):\n\"\"\"Logs a whole message in emboldened blue text, and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.hugeinfo(\"This is a huge informational message\")\n            &gt;&gt;&gt; self.hugeinfo(\"This is a huge informational message with a trace\", trace=True)\n        \"\"\"\n        self.log.hugeinfo(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def success(self, *args, trace=False, **kwargs):\n\"\"\"Logs a success message, and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.success(\"Operation completed successfully\")\n            &gt;&gt;&gt; self.success(\"Operation completed with a trace\", trace=True)\n        \"\"\"\n        self.log.success(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def hugesuccess(self, *args, trace=False, **kwargs):\n\"\"\"Logs a whole message in emboldened green text, and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.hugesuccess(\"This is a huge success message\")\n            &gt;&gt;&gt; self.hugesuccess(\"This is a huge success message with a trace\", trace=True)\n        \"\"\"\n        self.log.hugesuccess(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def warning(self, *args, trace=True, **kwargs):\n\"\"\"Logs a warning message, and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to True.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.warning(\"This is a warning message\")\n            &gt;&gt;&gt; self.warning(\"This is a warning message with a trace\", trace=False)\n        \"\"\"\n        self.log.warning(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def hugewarning(self, *args, trace=True, **kwargs):\n\"\"\"Logs a whole message in emboldened orange text, and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to True.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.hugewarning(\"This is a huge warning message\")\n            &gt;&gt;&gt; self.hugewarning(\"This is a huge warning message with a trace\", trace=False)\n        \"\"\"\n        self.log.hugewarning(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def error(self, *args, trace=True, **kwargs):\n\"\"\"Logs an error message, and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to True.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.error(\"This is an error message\")\n            &gt;&gt;&gt; self.error(\"This is an error message with a trace\", trace=False)\n        \"\"\"\n        self.log.error(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def trace(self):\n\"\"\"Logs the stack trace of the most recently caught exception.\n\n        This method captures the type, value, and traceback of the most recent exception and logs it using the trace level. It is typically used for debugging purposes.\n\n        Anything logged using this method will always be written to the scan's `debug.log`, even if debugging is not enabled.\n\n        Examples:\n            &gt;&gt;&gt; try:\n            &gt;&gt;&gt;     1 / 0\n            &gt;&gt;&gt; except ZeroDivisionError:\n            &gt;&gt;&gt;     self.trace()\n        \"\"\"\n        e_type, e_val, e_traceback = exc_info()\n        if e_type is not None:\n            self.log.trace(traceback.format_exc())\n\n    def critical(self, *args, trace=True, **kwargs):\n\"\"\"Logs a whole message in emboldened red text, and optionally the stack trace of the most recent exception.\n\n        Args:\n            *args: Variable-length argument list to pass to the logger.\n            trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to True.\n            **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n        Examples:\n            &gt;&gt;&gt; self.critical(\"This is a critical message\")\n            &gt;&gt;&gt; self.critical(\"This is a critical message with a trace\", trace=False)\n        \"\"\"\n        self.log.critical(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n        if trace:\n            self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.auth_secret","title":"auth_secret  <code>property</code>","text":"<pre><code>auth_secret\n</code></pre> <p>Indicates if the module is properly configured for authentication.</p> <p>This read-only property should be used to check whether all necessary attributes (e.g., API keys, tokens, etc.) are configured to perform authenticated requests in the module. Commonly used in setup or initialization steps.</p> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the module is properly configured for authentication, otherwise False.</p> </li> </ul>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.config","title":"config  <code>property</code>","text":"<pre><code>config\n</code></pre> <p>Property that provides easy access to the module's configuration in the scan's config.</p> <p>This property serves as a shortcut to retrieve the module-specific configuration from <code>self.scan.config</code>. If no configuration is found for this module, an empty dictionary is returned.</p> <p>Returns:</p> <ul> <li> <code>dict</code>        \u2013          <p>The configuration dictionary specific to this module.</p> </li> </ul>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.finished","title":"finished  <code>property</code>","text":"<pre><code>finished\n</code></pre> <p>Property indicating whether the module has finished processing.</p> <p>This property checks three conditions to determine if the module is finished: 1. The module is not currently running (<code>self.running</code> is False). 2. The number of incoming events in the queue is zero or less (<code>self.num_incoming_events &lt;= 0</code>). 3. The number of outgoing events in the queue is zero or less (<code>self.outgoing_event_queue.qsize() &lt;= 0</code>).</p> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the module has finished processing, False otherwise.</p> </li> </ul>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.http_timeout","title":"http_timeout  <code>property</code>","text":"<pre><code>http_timeout\n</code></pre> <p>Convenience shortcut to <code>http_timeout</code> in the config</p>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.memory_usage","title":"memory_usage  <code>property</code>","text":"<pre><code>memory_usage\n</code></pre> <p>Property that calculates the current memory usage of the module in bytes.</p> <p>This property uses the <code>get_size</code> function to estimate the memory consumption of the module object. The depth of the object graph traversal is limited to 3 levels to avoid performance issues. Commonly shared objects like <code>self.scan</code>, <code>self.helpers</code>, are excluded from the calculation to prevent double-counting.</p> <p>Returns:</p> <ul> <li> <code>int</code>        \u2013          <p>The estimated memory usage of the module in bytes.</p> </li> </ul>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.priority","title":"priority  <code>property</code>","text":"<pre><code>priority\n</code></pre> <p>Gets the priority level of the module as an integer.</p> <p>The priority level is constrained to be between 1 and 5, inclusive. A lower value indicates a higher priority.</p> <p>Returns:</p> <ul> <li> <code>int</code>        \u2013          <p>The priority level of the module, constrained between 1 and 5.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.priority\n3\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.running","title":"running  <code>property</code>","text":"<pre><code>running\n</code></pre> <p>Property indicating whether the module is currently processing data.</p> <p>This property checks if the task counter (<code>self._task_counter.value</code>) is greater than zero, indicating that there are ongoing tasks in the module.</p> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the module is currently processing data, False otherwise.</p> </li> </ul>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.status","title":"status  <code>property</code>","text":"<pre><code>status\n</code></pre> <p>Provides the current status of the module as a dictionary.</p> The dictionary contains the following keys <ul> <li>'events': A sub-dictionary with 'incoming' and 'outgoing' keys, representing the number of events in the respective queues.</li> <li>'tasks': The current value of the task counter.</li> <li>'errored': A boolean value indicating if the module is in an error state.</li> <li>'running': A boolean value indicating if the module is currently processing data.</li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>        \u2013          <p>A dictionary containing the current status of the module.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.status\n{'events': {'incoming': 5, 'outgoing': 2}, 'tasks': 3, 'errored': False, 'running': True}\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.__init__","title":"__init__","text":"<pre><code>__init__(scan)\n</code></pre> <p>Initializes a module instance.</p> <p>Parameters:</p> <ul> <li> <code>scan</code>         \u2013          <p>The BBOT scan object associated with this module instance.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>scan</code>         \u2013          <p>The scan object associated with this module.</p> </li> <li> <code>errored</code>             (<code>bool</code>)         \u2013          <p>Whether the module has errored out. Default is False.</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>def __init__(self, scan):\n\"\"\"Initializes a module instance.\n\n    Args:\n        scan: The BBOT scan object associated with this module instance.\n\n    Attributes:\n        scan: The scan object associated with this module.\n\n        errored (bool): Whether the module has errored out. Default is False.\n    \"\"\"\n    self.scan = scan\n    self.errored = False\n    self._log = None\n    self._incoming_event_queue = None\n    self._outgoing_event_queue = None\n    # track incoming events to prevent unwanted duplicates\n    self._incoming_dup_tracker = set()\n    # seconds since we've submitted a batch\n    self._last_submitted_batch = None\n    # additional callbacks to be executed alongside self.cleanup()\n    self.cleanup_callbacks = []\n    self._cleanedup = False\n    self._watched_events = None\n\n    self._task_counter = TaskCounter()\n\n    # string constant\n    self._custom_filter_criteria_msg = \"it did not meet custom filter criteria\"\n\n    # track number of failures (for .request_with_fail_count())\n    self._request_failures = 0\n\n    self._tasks = []\n    self._event_received = asyncio.Condition()\n    self._event_queued = asyncio.Condition()\n\n    # used for optional \"per host\" tracking\n    self._per_host_tracker = set()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.cleanup","title":"cleanup  <code>async</code>","text":"<pre><code>cleanup()\n</code></pre> <p>Asynchronously performs final cleanup operations after the scan is complete.</p> <p>This method can be overridden to implement custom cleanup logic. It is called only once per scan and may not raise events.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> Note <p>This method is called only once per scan and may not raise events.</p> Source code in <code>bbot/modules/base.py</code> <pre><code>async def cleanup(self):\n\"\"\"Asynchronously performs final cleanup operations after the scan is complete.\n\n    This method can be overridden to implement custom cleanup logic. It is called only once per scan and may not raise events.\n\n    Returns:\n        None\n\n    Note:\n        This method is called only once per scan and may not raise events.\n    \"\"\"\n    return\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.critical","title":"critical","text":"<pre><code>critical(*args, trace = True, **kwargs)\n</code></pre> <p>Logs a whole message in emboldened red text, and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to True.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.critical(\"This is a critical message\")\n&gt;&gt;&gt; self.critical(\"This is a critical message with a trace\", trace=False)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def critical(self, *args, trace=True, **kwargs):\n\"\"\"Logs a whole message in emboldened red text, and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to True.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.critical(\"This is a critical message\")\n        &gt;&gt;&gt; self.critical(\"This is a critical message with a trace\", trace=False)\n    \"\"\"\n    self.log.critical(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.debug","title":"debug","text":"<pre><code>debug(*args, trace = False, **kwargs)\n</code></pre> <p>Logs debug messages and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to False.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.debug(\"This is a debug message\")\n&gt;&gt;&gt; self.debug(\"This is a debug message with a trace\", trace=True)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def debug(self, *args, trace=False, **kwargs):\n\"\"\"Logs debug messages and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.debug(\"This is a debug message\")\n        &gt;&gt;&gt; self.debug(\"This is a debug message with a trace\", trace=True)\n    \"\"\"\n    self.log.debug(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.emit_event","title":"emit_event","text":"<pre><code>emit_event(*args, **kwargs)\n</code></pre> <p>Emit an event to the event queue and distribute it to interested modules.</p> <p>This is how modules \"return\" data.</p> <p>The method first creates an event object by calling <code>self.make_event()</code> with the provided arguments. Then, the event is queued for outgoing distribution using <code>self.queue_outgoing_event()</code>.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Positional arguments to be passed to <code>self.make_event()</code> for event creation.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Keyword arguments to be passed for event creation or configuration of the emit action. <pre><code>- on_success_callback: Optional callback function to execute upon successful event emission.\n- abort_if: Optional condition under which the event emission should be aborted.\n- quick: Optional flag to indicate whether the event should be processed quickly.\n</code></pre></p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.emit_event(\"www.evilcorp.com\", source=event, tags=[\"affiliate\"])\n</code></pre> <pre><code>&gt;&gt;&gt; new_event = self.make_event(\"1.2.3.4\", source=event)\n&gt;&gt;&gt; self.emit_event(new_event)\n</code></pre> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValidationError</code>           \u2013          <p>If the event cannot be validated (handled in <code>self.make_event()</code>).</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>def emit_event(self, *args, **kwargs):\n\"\"\"Emit an event to the event queue and distribute it to interested modules.\n\n    This is how modules \"return\" data.\n\n    The method first creates an event object by calling `self.make_event()` with the provided arguments.\n    Then, the event is queued for outgoing distribution using `self.queue_outgoing_event()`.\n\n    Args:\n        *args: Positional arguments to be passed to `self.make_event()` for event creation.\n        **kwargs: Keyword arguments to be passed for event creation or configuration of the emit action.\n            ```markdown\n            - on_success_callback: Optional callback function to execute upon successful event emission.\n            - abort_if: Optional condition under which the event emission should be aborted.\n            - quick: Optional flag to indicate whether the event should be processed quickly.\n            ```\n\n    Examples:\n        &gt;&gt;&gt; self.emit_event(\"www.evilcorp.com\", source=event, tags=[\"affiliate\"])\n\n        &gt;&gt;&gt; new_event = self.make_event(\"1.2.3.4\", source=event)\n        &gt;&gt;&gt; self.emit_event(new_event)\n\n    Returns:\n        None\n\n    Raises:\n        ValidationError: If the event cannot be validated (handled in `self.make_event()`).\n    \"\"\"\n    event_kwargs = dict(kwargs)\n    emit_kwargs = {}\n    for o in (\"on_success_callback\", \"abort_if\", \"quick\"):\n        v = event_kwargs.pop(o, None)\n        if v is not None:\n            emit_kwargs[o] = v\n    event = self.make_event(*args, **event_kwargs)\n    if event:\n        self.queue_outgoing_event(event, **emit_kwargs)\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.emit_event_wait","title":"emit_event_wait  <code>async</code>","text":"<pre><code>emit_event_wait(*args, **kwargs)\n</code></pre> <p>Emit an event to the event queue and await until there is space in the outgoing queue.</p> <p>This method is similar to <code>emit_event</code>, but it waits until there's sufficient space in the outgoing event queue before emitting the event. It utilizes the queue size threshold defined in <code>self._qsize</code>.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Positional arguments to be passed to <code>emit_event()</code> for event creation.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Keyword arguments to be passed to <code>emit_event()</code> for event creation or configuration.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> See Also <p>emit_event: For emitting an event without waiting on the queue size.</p> Source code in <code>bbot/modules/base.py</code> <pre><code>async def emit_event_wait(self, *args, **kwargs):\n\"\"\"Emit an event to the event queue and await until there is space in the outgoing queue.\n\n    This method is similar to `emit_event`, but it waits until there's sufficient space in the outgoing\n    event queue before emitting the event. It utilizes the queue size threshold defined in `self._qsize`.\n\n    Args:\n        *args: Positional arguments to be passed to `emit_event()` for event creation.\n        **kwargs: Keyword arguments to be passed to `emit_event()` for event creation or configuration.\n\n    Returns:\n        None\n\n    See Also:\n        emit_event: For emitting an event without waiting on the queue size.\n    \"\"\"\n    while self.outgoing_event_queue.qsize() &gt; self._qsize:\n        await self.helpers.sleep(0.2)\n    return self.emit_event(*args, **kwargs)\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.error","title":"error","text":"<pre><code>error(*args, trace = True, **kwargs)\n</code></pre> <p>Logs an error message, and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to True.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.error(\"This is an error message\")\n&gt;&gt;&gt; self.error(\"This is an error message with a trace\", trace=False)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def error(self, *args, trace=True, **kwargs):\n\"\"\"Logs an error message, and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to True.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.error(\"This is an error message\")\n        &gt;&gt;&gt; self.error(\"This is an error message with a trace\", trace=False)\n    \"\"\"\n    self.log.error(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.filter_event","title":"filter_event  <code>async</code>","text":"<pre><code>filter_event(event)\n</code></pre> <p>Asynchronously filters incoming events based on custom criteria.</p> <p>Override this method for more granular control over which events are accepted by your module. This method is called automatically before <code>handle_event()</code> for each incoming event that matches any in <code>watched_events</code>.</p> <p>Parameters:</p> <ul> <li> <code>event</code>             (<code>Event</code>)         \u2013          <p>The incoming Event object to be filtered.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>        \u2013          <p>A 2-tuple where the first value is a bool indicating whether the event should be accepted, and the second value is a string explaining the reason for its acceptance or rejection. By default, returns <code>(True, None)</code> to indicate acceptance without reason.</p> </li> </ul> Note <p>This method should be overridden if the module requires custom logic for event filtering.</p> Source code in <code>bbot/modules/base.py</code> <pre><code>async def filter_event(self, event):\n\"\"\"Asynchronously filters incoming events based on custom criteria.\n\n    Override this method for more granular control over which events are accepted by your module. This method is called automatically before `handle_event()` for each incoming event that matches any in `watched_events`.\n\n    Args:\n        event (Event): The incoming Event object to be filtered.\n\n    Returns:\n        tuple: A 2-tuple where the first value is a bool indicating whether the event should be accepted, and the second value is a string explaining the reason for its acceptance or rejection. By default, returns `(True, None)` to indicate acceptance without reason.\n\n    Note:\n        This method should be overridden if the module requires custom logic for event filtering.\n    \"\"\"\n    return True\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.finish","title":"finish  <code>async</code>","text":"<pre><code>finish()\n</code></pre> <p>Asynchronously performs final tasks as the scan nears completion.</p> <p>This method can be overridden to execute any necessary finalization logic. For example, if the module relies on a word cloud, you might wait for the scan to finish to ensure the word cloud is most complete before running an operation.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>async def finish(self):\n\"\"\"Asynchronously performs final tasks as the scan nears completion.\n\n    This method can be overridden to execute any necessary finalization logic. For example, if the module relies on a word cloud, you might wait for the scan to finish to ensure the word cloud is most complete before running an operation.\n\n    Returns:\n        None\n\n    Warnings:\n        This method may be called multiple times since it can raise events, which may re-trigger the \"finish\" phase of the scan. Optional to override.\n    \"\"\"\n    return\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.get_per_domain_hash","title":"get_per_domain_hash","text":"<pre><code>get_per_domain_hash(event)\n</code></pre> <p>Computes a per-domain hash value for a given event. This method may be optionally overridden in subclasses.</p> <p>Events with the same root domain will receive the same hash value.</p> <p>Parameters:</p> <ul> <li> <code>event</code>             (<code>Event</code>)         \u2013          <p>The event object containing host, port, or parsed URL information.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>        \u2013          <p>The hash value computed for the domain.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; event = self.make_event(\"https://www.example.com:8443\")\n&gt;&gt;&gt; self.get_per_domain_hash(event)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def get_per_domain_hash(self, event):\n\"\"\"\n    Computes a per-domain hash value for a given event. This method may be optionally overridden in subclasses.\n\n    Events with the same root domain will receive the same hash value.\n\n    Args:\n        event (Event): The event object containing host, port, or parsed URL information.\n\n    Returns:\n        int: The hash value computed for the domain.\n\n    Examples:\n        &gt;&gt;&gt; event = self.make_event(\"https://www.example.com:8443\")\n        &gt;&gt;&gt; self.get_per_domain_hash(event)\n    \"\"\"\n    _, domain = self.helpers.split_domain(event.host)\n    return hash(domain)\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.get_per_host_hash","title":"get_per_host_hash","text":"<pre><code>get_per_host_hash(event)\n</code></pre> <p>Computes a per-host hash value for a given event. This method may be optionally overridden in subclasses.</p> <p>The function uses the event's <code>host</code> and <code>port</code> or the parsed URL to create a string to be hashed. The hash value is used for distinguishing events related to the same host.</p> <p>Parameters:</p> <ul> <li> <code>event</code>             (<code>Event</code>)         \u2013          <p>The event object containing host, port, or parsed URL information.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>        \u2013          <p>The hash value computed for the host.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; event = self.make_event(\"https://example.com:8443\")\n&gt;&gt;&gt; self.get_per_host_hash(event)\n</code></pre> Notes <ul> <li>To change the behavior, override this method in your custom module.</li> <li>The hash value is dependent on the <code>host</code> and <code>port</code> or the <code>parsed</code> attribute in the event object.</li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>def get_per_host_hash(self, event):\n\"\"\"\n    Computes a per-host hash value for a given event. This method may be optionally overridden in subclasses.\n\n    The function uses the event's `host` and `port` or the parsed URL to create a string to be hashed.\n    The hash value is used for distinguishing events related to the same host.\n\n    Args:\n        event (Event): The event object containing host, port, or parsed URL information.\n\n    Returns:\n        int: The hash value computed for the host.\n\n    Examples:\n        &gt;&gt;&gt; event = self.make_event(\"https://example.com:8443\")\n        &gt;&gt;&gt; self.get_per_host_hash(event)\n\n    Notes:\n        - To change the behavior, override this method in your custom module.\n        - The hash value is dependent on the `host` and `port` or the `parsed` attribute in the event object.\n    \"\"\"\n    parsed = getattr(event, \"parsed\", None)\n    if parsed is None:\n        to_hash = self.helpers.make_netloc(event.host, event.port)\n    else:\n        to_hash = f\"{parsed.scheme}://{parsed.netloc}/\"\n    return hash(to_hash)\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.get_watched_events","title":"get_watched_events","text":"<pre><code>get_watched_events()\n</code></pre> <p>Retrieve the set of events that the module is interested in observing.</p> <p>Override this method if the set of events the module should watch needs to be determined dynamically, e.g., based on configuration options or other runtime conditions.</p> <p>Returns:</p> <ul> <li> <code>set</code>        \u2013          <p>The set of event types that this module will handle.</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>def get_watched_events(self):\n\"\"\"Retrieve the set of events that the module is interested in observing.\n\n    Override this method if the set of events the module should watch needs to be determined dynamically, e.g., based on configuration options or other runtime conditions.\n\n    Returns:\n        set: The set of event types that this module will handle.\n    \"\"\"\n    if self._watched_events is None:\n        self._watched_events = set(self.watched_events)\n    return self._watched_events\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.handle_batch","title":"handle_batch","text":"<pre><code>handle_batch(*events)\n</code></pre> <p>Handles incoming events in batches for optimized processing.</p> <p>This method is automatically called when multiple events that match any in <code>watched_events</code> are encountered and the <code>batch_size</code> attribute is set to a value greater than 1. Override this method to implement custom batch event-handling logic for your module.</p> <p>Parameters:</p> <ul> <li> <code>*events</code>             (<code>Event</code>, default:                 <code>()</code> )         \u2013          <p>A variable number of Event objects to be processed in a batch.</p> </li> </ul> Note <p>This method should be overridden if the <code>batch_size</code> attribute of the module is set to a value greater than 1.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>def handle_batch(self, *events):\n\"\"\"Handles incoming events in batches for optimized processing.\n\n    This method is automatically called when multiple events that match any in `watched_events` are encountered and the `batch_size` attribute is set to a value greater than 1. Override this method to implement custom batch event-handling logic for your module.\n\n    Args:\n        *events (Event): A variable number of Event objects to be processed in a batch.\n\n    Note:\n        This method should be overridden if the `batch_size` attribute of the module is set to a value greater than 1.\n\n    Returns:\n        None\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.handle_event","title":"handle_event  <code>async</code>","text":"<pre><code>handle_event(event)\n</code></pre> <p>Asynchronously handles incoming events that the module is configured to watch.</p> <p>This method is automatically invoked when an event that matches any in <code>watched_events</code> is encountered during a scan. Override this method to implement custom event-handling logic for your module.</p> <p>Parameters:</p> <ul> <li> <code>event</code>             (<code>Event</code>)         \u2013          <p>The event object containing details about the incoming event.</p> </li> </ul> Note <p>This method should be overridden if the <code>batch_size</code> attribute of the module is set to 1.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>async def handle_event(self, event):\n\"\"\"Asynchronously handles incoming events that the module is configured to watch.\n\n    This method is automatically invoked when an event that matches any in `watched_events` is encountered during a scan. Override this method to implement custom event-handling logic for your module.\n\n    Args:\n        event (Event): The event object containing details about the incoming event.\n\n    Note:\n        This method should be overridden if the `batch_size` attribute of the module is set to 1.\n\n    Returns:\n        None\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.hugeinfo","title":"hugeinfo","text":"<pre><code>hugeinfo(*args, trace = False, **kwargs)\n</code></pre> <p>Logs a whole message in emboldened blue text, and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to False.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.hugeinfo(\"This is a huge informational message\")\n&gt;&gt;&gt; self.hugeinfo(\"This is a huge informational message with a trace\", trace=True)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def hugeinfo(self, *args, trace=False, **kwargs):\n\"\"\"Logs a whole message in emboldened blue text, and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.hugeinfo(\"This is a huge informational message\")\n        &gt;&gt;&gt; self.hugeinfo(\"This is a huge informational message with a trace\", trace=True)\n    \"\"\"\n    self.log.hugeinfo(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.hugesuccess","title":"hugesuccess","text":"<pre><code>hugesuccess(*args, trace = False, **kwargs)\n</code></pre> <p>Logs a whole message in emboldened green text, and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to False.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.hugesuccess(\"This is a huge success message\")\n&gt;&gt;&gt; self.hugesuccess(\"This is a huge success message with a trace\", trace=True)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def hugesuccess(self, *args, trace=False, **kwargs):\n\"\"\"Logs a whole message in emboldened green text, and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.hugesuccess(\"This is a huge success message\")\n        &gt;&gt;&gt; self.hugesuccess(\"This is a huge success message with a trace\", trace=True)\n    \"\"\"\n    self.log.hugesuccess(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.hugeverbose","title":"hugeverbose","text":"<pre><code>hugeverbose(*args, trace = False, **kwargs)\n</code></pre> <p>Logs a whole message in emboldened white text, and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to False.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.hugeverbose(\"This is a huge verbose message\")\n&gt;&gt;&gt; self.hugeverbose(\"This is a huge verbose message with a trace\", trace=True)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def hugeverbose(self, *args, trace=False, **kwargs):\n\"\"\"Logs a whole message in emboldened white text, and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.hugeverbose(\"This is a huge verbose message\")\n        &gt;&gt;&gt; self.hugeverbose(\"This is a huge verbose message with a trace\", trace=True)\n    \"\"\"\n    self.log.hugeverbose(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.hugewarning","title":"hugewarning","text":"<pre><code>hugewarning(*args, trace = True, **kwargs)\n</code></pre> <p>Logs a whole message in emboldened orange text, and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to True.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.hugewarning(\"This is a huge warning message\")\n&gt;&gt;&gt; self.hugewarning(\"This is a huge warning message with a trace\", trace=False)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def hugewarning(self, *args, trace=True, **kwargs):\n\"\"\"Logs a whole message in emboldened orange text, and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to True.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.hugewarning(\"This is a huge warning message\")\n        &gt;&gt;&gt; self.hugewarning(\"This is a huge warning message with a trace\", trace=False)\n    \"\"\"\n    self.log.hugewarning(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.info","title":"info","text":"<pre><code>info(*args, trace = False, **kwargs)\n</code></pre> <p>Logs informational messages and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to False.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.info(\"This is an informational message\")\n&gt;&gt;&gt; self.info(\"This is an informational message with a trace\", trace=True)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def info(self, *args, trace=False, **kwargs):\n\"\"\"Logs informational messages and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.info(\"This is an informational message\")\n        &gt;&gt;&gt; self.info(\"This is an informational message with a trace\", trace=True)\n    \"\"\"\n    self.log.info(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.log_table","title":"log_table","text":"<pre><code>log_table(*args, **kwargs)\n</code></pre> <p>Logs a table to the console and optionally writes it to a file.</p> <p>This function generates a table using <code>self.helpers.make_table</code>, then logs each line of the table as an info-level log. If a table_name is provided, it also writes the table to a file.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable length argument list to be passed to <code>self.helpers.make_table</code>.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments. If 'table_name' is specified, the table will be written to a file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>The generated table as a string.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.log_table(['Header1', 'Header2'], [['row1col1', 'row1col2'], ['row2col1', 'row2col2']], table_name=\"my_table\")\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def log_table(self, *args, **kwargs):\n\"\"\"Logs a table to the console and optionally writes it to a file.\n\n    This function generates a table using `self.helpers.make_table`, then logs each line\n    of the table as an info-level log. If a table_name is provided, it also writes the table to a file.\n\n    Args:\n        *args: Variable length argument list to be passed to `self.helpers.make_table`.\n        **kwargs: Arbitrary keyword arguments. If 'table_name' is specified, the table will be written to a file.\n\n    Returns:\n        str: The generated table as a string.\n\n    Examples:\n        &gt;&gt;&gt; self.log_table(['Header1', 'Header2'], [['row1col1', 'row1col2'], ['row2col1', 'row2col2']], table_name=\"my_table\")\n    \"\"\"\n    table_name = kwargs.pop(\"table_name\", None)\n    table = self.helpers.make_table(*args, **kwargs)\n    for line in table.splitlines():\n        self.info(line)\n    if table_name is not None:\n        date = self.helpers.make_date()\n        filename = self.scan.home / f\"{self.helpers.tagify(table_name)}-table-{date}.txt\"\n        with open(filename, \"w\") as f:\n            f.write(table)\n        self.verbose(f\"Wrote {table_name} to {filename}\")\n    return table\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.make_event","title":"make_event","text":"<pre><code>make_event(*args, **kwargs)\n</code></pre> <p>Create an event for the scan.</p> <p>Raises a validation error if the event could not be created, unless raise_error is set to False.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Positional arguments to be passed to the scan's make_event method.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Keyword arguments to be passed to the scan's make_event method.</p> </li> <li> <code>raise_error</code>             (<code>bool</code>)         \u2013          <p>Whether to raise a validation error if the event could not be created. Defaults to False.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; new_event = self.make_event(\"1.2.3.4\", source=event)\n&gt;&gt;&gt; self.emit_event(new_event)\n</code></pre> <p>Returns:</p> <ul> <li>         \u2013          <p>Event or None: The created event, or None if a validation error occurred and raise_error was False.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValidationError</code>           \u2013          <p>If the event could not be validated and raise_error is True.</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>def make_event(self, *args, **kwargs):\n\"\"\"Create an event for the scan.\n\n    Raises a validation error if the event could not be created, unless raise_error is set to False.\n\n    Args:\n        *args: Positional arguments to be passed to the scan's make_event method.\n        **kwargs: Keyword arguments to be passed to the scan's make_event method.\n        raise_error (bool, optional): Whether to raise a validation error if the event could not be created. Defaults to False.\n\n    Examples:\n        &gt;&gt;&gt; new_event = self.make_event(\"1.2.3.4\", source=event)\n        &gt;&gt;&gt; self.emit_event(new_event)\n\n    Returns:\n        Event or None: The created event, or None if a validation error occurred and raise_error was False.\n\n    Raises:\n        ValidationError: If the event could not be validated and raise_error is True.\n    \"\"\"\n    raise_error = kwargs.pop(\"raise_error\", False)\n    try:\n        event = self.scan.make_event(*args, **kwargs)\n    except ValidationError as e:\n        if raise_error:\n            raise\n        self.warning(f\"{e}\")\n        return\n    if not event.module:\n        event.module = self\n    return event\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.ping","title":"ping  <code>async</code>","text":"<pre><code>ping()\n</code></pre> <p>Asynchronously checks the health of the configured API.</p> <p>This method is used in conjunction with require_api_key() to verify that the API is not just configured, but also responsive. This method should include an assert statement to validate the API's health, typically by making a test request to a known endpoint.</p> Example Usage <p>In your implementation, if the API has a \"/ping\" endpoint: async def ping(self):     r = await self.request_with_fail_count(f\"{self.base_url}/ping\")     resp_content = getattr(r, \"text\", \"\")     assert getattr(r, \"status_code\", 0) == 200, resp_content</p> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>AssertionError</code>           \u2013          <p>If the API does not respond as expected.</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>async def ping(self):\n\"\"\"Asynchronously checks the health of the configured API.\n\n    This method is used in conjunction with require_api_key() to verify that the API is not just configured, but also responsive. This method should include an assert statement to validate the API's health, typically by making a test request to a known endpoint.\n\n    Example Usage:\n        In your implementation, if the API has a \"/ping\" endpoint:\n        async def ping(self):\n            r = await self.request_with_fail_count(f\"{self.base_url}/ping\")\n            resp_content = getattr(r, \"text\", \"\")\n            assert getattr(r, \"status_code\", 0) == 200, resp_content\n\n    Returns:\n        None\n\n    Raises:\n        AssertionError: If the API does not respond as expected.\n    \"\"\"\n    return\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.queue_event","title":"queue_event  <code>async</code>","text":"<pre><code>queue_event(event, precheck = True)\n</code></pre> <p>Asynchronously queues an incoming event to the module's event queue for further processing.</p> <p>The function performs an initial check to see if the event is acceptable for queuing. If the event passes the check, it is put into the <code>incoming_event_queue</code>.</p> <p>Parameters:</p> <ul> <li> <code>event</code>         \u2013          <p>The event object to be queued.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>        \u2013          <p>The function doesn't return anything but modifies the state of the <code>incoming_event_queue</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await self.queue_event(some_event)\n</code></pre> <p>Raises:</p> <ul> <li> <code>AttributeError</code>           \u2013          <p>If the module is not in an acceptable state to queue incoming events.</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>async def queue_event(self, event, precheck=True):\n\"\"\"\n    Asynchronously queues an incoming event to the module's event queue for further processing.\n\n    The function performs an initial check to see if the event is acceptable for queuing.\n    If the event passes the check, it is put into the `incoming_event_queue`.\n\n    Args:\n        event: The event object to be queued.\n\n    Returns:\n        None: The function doesn't return anything but modifies the state of the `incoming_event_queue`.\n\n    Examples:\n        &gt;&gt;&gt; await self.queue_event(some_event)\n\n    Raises:\n        AttributeError: If the module is not in an acceptable state to queue incoming events.\n    \"\"\"\n    async with self._task_counter.count(\"queue_event()\", _log=False):\n        if self.incoming_event_queue is False:\n            self.debug(f\"Not in an acceptable state to queue incoming event\")\n            return\n        acceptable, reason = True, \"precheck was skipped\"\n        if precheck:\n            acceptable, reason = self._event_precheck(event)\n        if not acceptable:\n            if reason and reason != \"its type is not in watched_events\":\n                self.debug(f\"Not accepting {event} because {reason}\")\n            return\n        else:\n            self.debug(f\"Accepting {event} because {reason}\")\n        try:\n            self.incoming_event_queue.put_nowait(event)\n            async with self._event_received:\n                self._event_received.notify()\n            if event.type != \"FINISHED\":\n                self.scan.manager._new_activity = True\n        except AttributeError:\n            self.debug(f\"Not in an acceptable state to queue incoming event\")\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.queue_outgoing_event","title":"queue_outgoing_event","text":"<pre><code>queue_outgoing_event(event, **kwargs)\n</code></pre> <p>Queues an outgoing event to the module's outgoing event queue for further processing.</p> <p>The function attempts to put the event into the <code>outgoing_event_queue</code> immediately. If it's not possible due to the current state of the module, an AttributeError is raised, and a debug log is generated.</p> <p>Parameters:</p> <ul> <li> <code>event</code>         \u2013          <p>The event object to be queued.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments to be associated with the event.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>        \u2013          <p>The function doesn't return anything but modifies the state of the <code>outgoing_event_queue</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.queue_outgoing_event(some_outgoing_event, abort_if=lambda e: \"unresolved\" in e.tags)\n</code></pre> <p>Raises:</p> <ul> <li> <code>AttributeError</code>           \u2013          <p>If the module is not in an acceptable state to queue outgoing events.</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>def queue_outgoing_event(self, event, **kwargs):\n\"\"\"\n    Queues an outgoing event to the module's outgoing event queue for further processing.\n\n    The function attempts to put the event into the `outgoing_event_queue` immediately.\n    If it's not possible due to the current state of the module, an AttributeError is raised, and a debug log is generated.\n\n    Args:\n        event: The event object to be queued.\n        **kwargs: Additional keyword arguments to be associated with the event.\n\n    Returns:\n        None: The function doesn't return anything but modifies the state of the `outgoing_event_queue`.\n\n    Examples:\n        &gt;&gt;&gt; self.queue_outgoing_event(some_outgoing_event, abort_if=lambda e: \"unresolved\" in e.tags)\n\n    Raises:\n        AttributeError: If the module is not in an acceptable state to queue outgoing events.\n    \"\"\"\n    try:\n        self.outgoing_event_queue.put_nowait((event, kwargs))\n    except AttributeError:\n        self.debug(f\"Not in an acceptable state to queue outgoing event\")\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.report","title":"report  <code>async</code>","text":"<pre><code>report()\n</code></pre> <p>Asynchronously executes a final task after the scan is complete but before cleanup.</p> <p>This method can be overridden to aggregate data and raise summary events at the end of the scan.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> Note <p>This method is called only once per scan.</p> Source code in <code>bbot/modules/base.py</code> <pre><code>async def report(self):\n\"\"\"Asynchronously executes a final task after the scan is complete but before cleanup.\n\n    This method can be overridden to aggregate data and raise summary events at the end of the scan.\n\n    Returns:\n        None\n\n    Note:\n        This method is called only once per scan.\n    \"\"\"\n    return\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.request_with_fail_count","title":"request_with_fail_count  <code>async</code>","text":"<pre><code>request_with_fail_count(*args, **kwargs)\n</code></pre> <p>Asynchronously perform an HTTP request while keeping track of consecutive failures.</p> <p>This function wraps the <code>self.helpers.request</code> method, incrementing a failure counter if the request returns None. When the failure counter exceeds <code>self.failed_request_abort_threshold</code>, the module is set to an error state.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Positional arguments to pass to <code>self.helpers.request</code>.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Keyword arguments to pass to <code>self.helpers.request</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>        \u2013          <p>The response object or None if the request failed.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>None</code>           \u2013          <p>Sets the module to an error state when the failure threshold is reached.</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>async def request_with_fail_count(self, *args, **kwargs):\n\"\"\"Asynchronously perform an HTTP request while keeping track of consecutive failures.\n\n    This function wraps the `self.helpers.request` method, incrementing a failure counter if\n    the request returns None. When the failure counter exceeds `self.failed_request_abort_threshold`,\n    the module is set to an error state.\n\n    Args:\n        *args: Positional arguments to pass to `self.helpers.request`.\n        **kwargs: Keyword arguments to pass to `self.helpers.request`.\n\n    Returns:\n        Any: The response object or None if the request failed.\n\n    Raises:\n        None: Sets the module to an error state when the failure threshold is reached.\n    \"\"\"\n    r = await self.helpers.request(*args, **kwargs)\n    if r is None:\n        self._request_failures += 1\n    else:\n        self._request_failures = 0\n    if self._request_failures &gt;= self.failed_request_abort_threshold:\n        self.set_error_state(f\"Setting error state due to {self._request_failures:,} failed HTTP requests\")\n    return r\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.require_api_key","title":"require_api_key  <code>async</code>","text":"<pre><code>require_api_key()\n</code></pre> <p>Asynchronously checks if an API key is required and valid.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>bool or tuple: Returns True if API key is valid and ready.           Returns a tuple (None, \"error message\") otherwise.</p> </li> </ul> Notes <ul> <li>Fetches the API key from the configuration.</li> <li>Calls the 'ping()' method to test API accessibility.</li> <li>Sets the API key readiness status accordingly.</li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>async def require_api_key(self):\n\"\"\"\n    Asynchronously checks if an API key is required and valid.\n\n    Args:\n        None\n\n    Returns:\n        bool or tuple: Returns True if API key is valid and ready.\n                      Returns a tuple (None, \"error message\") otherwise.\n\n    Notes:\n        - Fetches the API key from the configuration.\n        - Calls the 'ping()' method to test API accessibility.\n        - Sets the API key readiness status accordingly.\n    \"\"\"\n    self.api_key = self.config.get(\"api_key\", \"\")\n    if self.auth_secret:\n        try:\n            await self.ping()\n            self.hugesuccess(f\"API is ready\")\n            return True\n        except Exception as e:\n            return None, f\"Error with API ({str(e).strip()})\"\n    else:\n        return None, \"No API key set\"\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.set_error_state","title":"set_error_state","text":"<pre><code>set_error_state(message = None, clear_outgoing_queue = False)\n</code></pre> <p>Puts the module into an errored state where it cannot accept new events. Optionally logs a warning message.</p> <p>The function sets the module's <code>errored</code> attribute to True and logs a warning with the optional message. It also clears the incoming event queue to prevent further processing and updates its status to False.</p> <p>Parameters:</p> <ul> <li> <code>message</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Additional message to be logged along with the warning.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>        \u2013          <p>The function doesn't return anything but updates the <code>errored</code> state and clears the incoming event queue.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.set_error_state()\n&gt;&gt;&gt; self.set_error_state(\"Failed to connect to the server\")\n</code></pre> Notes <ul> <li>The function sets <code>self._incoming_event_queue</code> to False to prevent its further use.</li> <li>If the module was already in an errored state, the function will not reset the error state or the queue.</li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>def set_error_state(self, message=None, clear_outgoing_queue=False):\n\"\"\"\n    Puts the module into an errored state where it cannot accept new events. Optionally logs a warning message.\n\n    The function sets the module's `errored` attribute to True and logs a warning with the optional message.\n    It also clears the incoming event queue to prevent further processing and updates its status to False.\n\n    Args:\n        message (str, optional): Additional message to be logged along with the warning.\n\n    Returns:\n        None: The function doesn't return anything but updates the `errored` state and clears the incoming event queue.\n\n    Examples:\n        &gt;&gt;&gt; self.set_error_state()\n        &gt;&gt;&gt; self.set_error_state(\"Failed to connect to the server\")\n\n    Notes:\n        - The function sets `self._incoming_event_queue` to False to prevent its further use.\n        - If the module was already in an errored state, the function will not reset the error state or the queue.\n    \"\"\"\n    if not self.errored:\n        log_msg = f\"Setting error state for module {self.name}\"\n        if message is not None:\n            log_msg += f\": {message}\"\n        self.warning(log_msg)\n        self.errored = True\n        # clear incoming queue\n        if self.incoming_event_queue is not False:\n            self.debug(f\"Emptying event_queue\")\n            with suppress(asyncio.queues.QueueEmpty):\n                while 1:\n                    self.incoming_event_queue.get_nowait()\n            # set queue to None to prevent its use\n            # if there are leftover objects in the queue, the scan will hang.\n            self._incoming_event_queue = False\n\n        if clear_outgoing_queue:\n            with suppress(asyncio.queues.QueueEmpty):\n                while 1:\n                    self.outgoing_event_queue.get_nowait()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.setup","title":"setup  <code>async</code>","text":"<pre><code>setup()\n</code></pre> <p>Asynchronously sets up the module at the beginning of the scan.</p> <p>This method can be overridden to perform any necessary setup logic.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>bool or None: True if setup was successful. None for a soft-fail, which will produce a warning but not abort the scan. False for a hard-fail, which will abort the scan.</p> </li> </ul> Source code in <code>bbot/modules/base.py</code> <pre><code>async def setup(self):\n\"\"\"Asynchronously sets up the module at the beginning of the scan.\n\n    This method can be overridden to perform any necessary setup logic.\n\n    Returns:\n        bool or None: True if setup was successful. None for a soft-fail, which will produce a warning but not abort the scan. False for a hard-fail, which will abort the scan.\n    \"\"\"\n    return True\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.stdout","title":"stdout","text":"<pre><code>stdout(*args, **kwargs)\n</code></pre> <p>Writes log messages directly to standard output.</p> <p>This is typically reserved for output modules only, e.g. <code>human</code> or <code>json</code>.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable length argument list to be passed to <code>self.log.stdout</code>.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to be passed to <code>self.log.stdout</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.stdout(\"This will be printed to stdout\")\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def stdout(self, *args, **kwargs):\n\"\"\"Writes log messages directly to standard output.\n\n    This is typically reserved for output modules only, e.g. `human` or `json`.\n\n    Args:\n        *args: Variable length argument list to be passed to `self.log.stdout`.\n        **kwargs: Arbitrary keyword arguments to be passed to `self.log.stdout`.\n\n    Examples:\n        &gt;&gt;&gt; self.stdout(\"This will be printed to stdout\")\n    \"\"\"\n    self.log.stdout(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.success","title":"success","text":"<pre><code>success(*args, trace = False, **kwargs)\n</code></pre> <p>Logs a success message, and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to False.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.success(\"Operation completed successfully\")\n&gt;&gt;&gt; self.success(\"Operation completed with a trace\", trace=True)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def success(self, *args, trace=False, **kwargs):\n\"\"\"Logs a success message, and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.success(\"Operation completed successfully\")\n        &gt;&gt;&gt; self.success(\"Operation completed with a trace\", trace=True)\n    \"\"\"\n    self.log.success(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.trace","title":"trace","text":"<pre><code>trace()\n</code></pre> <p>Logs the stack trace of the most recently caught exception.</p> <p>This method captures the type, value, and traceback of the most recent exception and logs it using the trace level. It is typically used for debugging purposes.</p> <p>Anything logged using this method will always be written to the scan's <code>debug.log</code>, even if debugging is not enabled.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; try:\n&gt;&gt;&gt;     1 / 0\n&gt;&gt;&gt; except ZeroDivisionError:\n&gt;&gt;&gt;     self.trace()\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def trace(self):\n\"\"\"Logs the stack trace of the most recently caught exception.\n\n    This method captures the type, value, and traceback of the most recent exception and logs it using the trace level. It is typically used for debugging purposes.\n\n    Anything logged using this method will always be written to the scan's `debug.log`, even if debugging is not enabled.\n\n    Examples:\n        &gt;&gt;&gt; try:\n        &gt;&gt;&gt;     1 / 0\n        &gt;&gt;&gt; except ZeroDivisionError:\n        &gt;&gt;&gt;     self.trace()\n    \"\"\"\n    e_type, e_val, e_traceback = exc_info()\n    if e_type is not None:\n        self.log.trace(traceback.format_exc())\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.verbose","title":"verbose","text":"<pre><code>verbose(*args, trace = False, **kwargs)\n</code></pre> <p>Logs messages and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to False.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.verbose(\"This is a verbose message\")\n&gt;&gt;&gt; self.verbose(\"This is a verbose message with a trace\", trace=True)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def verbose(self, *args, trace=False, **kwargs):\n\"\"\"Logs messages and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to False.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.verbose(\"This is a verbose message\")\n        &gt;&gt;&gt; self.verbose(\"This is a verbose message with a trace\", trace=True)\n    \"\"\"\n    self.log.verbose(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/basemodule/#bbot.modules.base.BaseModule.warning","title":"warning","text":"<pre><code>warning(*args, trace = True, **kwargs)\n</code></pre> <p>Logs a warning message, and optionally the stack trace of the most recent exception.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the logger.</p> </li> <li> <code>trace</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to log the stack trace of the most recently caught exception. Defaults to True.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the logger.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.warning(\"This is a warning message\")\n&gt;&gt;&gt; self.warning(\"This is a warning message with a trace\", trace=False)\n</code></pre> Source code in <code>bbot/modules/base.py</code> <pre><code>def warning(self, *args, trace=True, **kwargs):\n\"\"\"Logs a warning message, and optionally the stack trace of the most recent exception.\n\n    Args:\n        *args: Variable-length argument list to pass to the logger.\n        trace (bool, optional): Whether to log the stack trace of the most recently caught exception. Defaults to True.\n        **kwargs: Arbitrary keyword arguments to pass to the logger.\n\n    Examples:\n        &gt;&gt;&gt; self.warning(\"This is a warning message\")\n        &gt;&gt;&gt; self.warning(\"This is a warning message with a trace\", trace=False)\n    \"\"\"\n    self.log.warning(*args, extra={\"scan_id\": self.scan.id}, **kwargs)\n    if trace:\n        self.trace()\n</code></pre>"},{"location":"dev/event/","title":"Event","text":"<p>This is a developer reference. For a high-level description of BBOT events including a full list of event types, see Events</p>"},{"location":"dev/event/#bbot.core.event.base.make_event","title":"make_event","text":"<pre><code>make_event(data, event_type = None, source = None, module = None, scan = None, scans = None, tags = None, confidence = 5, dummy = False, internal = None)\n</code></pre> <p>Creates and returns a new event object or modifies an existing one.</p> <p>This function serves as a factory for creating new event objects, either by generating a new <code>Event</code> object or by updating an existing event with additional metadata. If <code>data</code> is already an event, it updates the event based on the additional parameters provided.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>Union[str, dict, BaseEvent]</code>)         \u2013          <p>The primary data for the event or an existing event object.</p> </li> <li> <code>event_type</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Type of the event, e.g., 'IP_ADDRESS'. Auto-detected if not provided.</p> </li> <li> <code>source</code>             (<code>BaseEvent</code>, default:                 <code>None</code> )         \u2013          <p>Source event leading to this event's discovery.</p> </li> <li> <code>module</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Module that discovered the event.</p> </li> <li> <code>scan</code>             (<code>Scan</code>, default:                 <code>None</code> )         \u2013          <p>BBOT Scan object associated with the event.</p> </li> <li> <code>scans</code>             (<code>List[Scan]</code>, default:                 <code>None</code> )         \u2013          <p>Multiple BBOT Scan objects, primarily used for unserialization.</p> </li> <li> <code>tags</code>             (<code>Union[str, List[str]]</code>, default:                 <code>None</code> )         \u2013          <p>Descriptive tags for the event, as a list or a single string.</p> </li> <li> <code>confidence</code>             (<code>int</code>, default:                 <code>5</code> )         \u2013          <p>Confidence level for the event, on a scale of 1-10. Defaults to 5.</p> </li> <li> <code>dummy</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Disables data validations if set to True. Defaults to False.</p> </li> <li> <code>internal</code>             (<code>Any</code>, default:                 <code>None</code> )         \u2013          <p>Makes the event internal if set to True. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BaseEvent</code>        \u2013          <p>A new or updated event object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValidationError</code>           \u2013          <p>Raised when there's an error in event data or type sanitization.</p> </li> </ul> <p>Examples:</p> <p>If inside a module, e.g. from within its <code>handle_event()</code>:</p> <pre><code>&gt;&gt;&gt; self.make_event(\"1.2.3.4\", source=event)\nIP_ADDRESS(\"1.2.3.4\", module=nmap, tags={'ipv4', 'distance-1'})\n</code></pre> <p>If you're outside a module but you have a scan object:</p> <pre><code>&gt;&gt;&gt; scan.make_event(\"1.2.3.4\", source=scan.root_event)\nIP_ADDRESS(\"1.2.3.4\", module=None, tags={'ipv4', 'distance-1'})\n</code></pre> <p>If you're outside a scan and just messing around:</p> <pre><code>&gt;&gt;&gt; from bbot.core.event.base import make_event\n&gt;&gt;&gt; make_event(\"1.2.3.4\", dummy=True)\nIP_ADDRESS(\"1.2.3.4\", module=None, tags={'ipv4'})\n</code></pre> Note <p>When working within a module's <code>handle_event()</code>, use the instance method <code>self.make_event()</code> instead of calling this function directly.</p> Source code in <code>bbot/core/event/base.py</code> <pre><code>def make_event(\n    data,\n    event_type=None,\n    source=None,\n    module=None,\n    scan=None,\n    scans=None,\n    tags=None,\n    confidence=5,\n    dummy=False,\n    internal=None,\n):\n\"\"\"\n    Creates and returns a new event object or modifies an existing one.\n\n    This function serves as a factory for creating new event objects, either by generating a new `Event`\n    object or by updating an existing event with additional metadata. If `data` is already an event,\n    it updates the event based on the additional parameters provided.\n\n    Parameters:\n        data (Union[str, dict, BaseEvent]): The primary data for the event or an existing event object.\n        event_type (str, optional): Type of the event, e.g., 'IP_ADDRESS'. Auto-detected if not provided.\n        source (BaseEvent, optional): Source event leading to this event's discovery.\n        module (str, optional): Module that discovered the event.\n        scan (Scan, optional): BBOT Scan object associated with the event.\n        scans (List[Scan], optional): Multiple BBOT Scan objects, primarily used for unserialization.\n        tags (Union[str, List[str]], optional): Descriptive tags for the event, as a list or a single string.\n        confidence (int, optional): Confidence level for the event, on a scale of 1-10. Defaults to 5.\n        dummy (bool, optional): Disables data validations if set to True. Defaults to False.\n        internal (Any, optional): Makes the event internal if set to True. Defaults to None.\n\n    Returns:\n        BaseEvent: A new or updated event object.\n\n    Raises:\n        ValidationError: Raised when there's an error in event data or type sanitization.\n\n    Examples:\n        If inside a module, e.g. from within its `handle_event()`:\n        &gt;&gt;&gt; self.make_event(\"1.2.3.4\", source=event)\n        IP_ADDRESS(\"1.2.3.4\", module=nmap, tags={'ipv4', 'distance-1'})\n\n        If you're outside a module but you have a scan object:\n        &gt;&gt;&gt; scan.make_event(\"1.2.3.4\", source=scan.root_event)\n        IP_ADDRESS(\"1.2.3.4\", module=None, tags={'ipv4', 'distance-1'})\n\n        If you're outside a scan and just messing around:\n        &gt;&gt;&gt; from bbot.core.event.base import make_event\n        &gt;&gt;&gt; make_event(\"1.2.3.4\", dummy=True)\n        IP_ADDRESS(\"1.2.3.4\", module=None, tags={'ipv4'})\n\n    Note:\n        When working within a module's `handle_event()`, use the instance method\n        `self.make_event()` instead of calling this function directly.\n    \"\"\"\n\n    # allow tags to be either a string or an array\n    if isinstance(tags, str):\n        tags = [tags]\n\n    if is_event(data):\n        if scan is not None and not data.scan:\n            data.scan = scan\n        if scans is not None and not data.scans:\n            data.scans = scans\n        if module is not None:\n            data.module = module\n        if source is not None:\n            data.source = source\n        if internal == True:\n            data.internal = True\n        event_type = data.type\n        return data\n    else:\n        if event_type is None:\n            event_type, data = get_event_type(data)\n            if not dummy:\n                log.debug(f'Autodetected event type \"{event_type}\" based on data: \"{data}\"')\n\n        event_type = str(event_type).strip().upper()\n\n        # Catch these common whoopsies\n        if event_type in (\"DNS_NAME\", \"IP_ADDRESS\"):\n            # DNS_NAME &lt;--&gt; EMAIL_ADDRESS confusion\n            if validators.soft_validate(data, \"email\"):\n                event_type = \"EMAIL_ADDRESS\"\n            else:\n                # DNS_NAME &lt;--&gt; IP_ADDRESS confusion\n                try:\n                    data = validators.validate_host(data)\n                except Exception as e:\n                    log.trace(traceback.format_exc())\n                    raise ValidationError(f'Error sanitizing event data \"{data}\" for type \"{event_type}\": {e}')\n                data_is_ip = is_ip(data)\n                if event_type == \"DNS_NAME\" and data_is_ip:\n                    event_type = \"IP_ADDRESS\"\n                elif event_type == \"IP_ADDRESS\" and not data_is_ip:\n                    event_type = \"DNS_NAME\"\n\n        event_class = globals().get(event_type, DefaultEvent)\n\n        return event_class(\n            data,\n            event_type=event_type,\n            source=source,\n            module=module,\n            scan=scan,\n            scans=scans,\n            tags=tags,\n            confidence=confidence,\n            _dummy=dummy,\n            _internal=internal,\n        )\n</code></pre>"},{"location":"dev/event/#bbot.core.event.base.event_from_json","title":"event_from_json","text":"<pre><code>event_from_json(j)\n</code></pre> <p>Creates an event object from a JSON dictionary.</p> <p>This function deserializes a JSON dictionary to create a new event object, using the <code>make_event</code> function for the actual object creation. It sets additional attributes such as the timestamp and scope distance based on the input JSON.</p> <p>Parameters:</p> <ul> <li> <code>j</code>             (<code>Dict</code>)         \u2013          <p>JSON dictionary containing the event attributes.       Must include keys \"data\" and \"type\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BaseEvent</code>        \u2013          <p>A new event object initialized with attributes from the JSON dictionary.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValidationError</code>           \u2013          <p>Raised when the JSON dictionary is missing required fields.</p> </li> </ul> Note <p>The function assumes that the input JSON dictionary is valid and may raise exceptions if required keys are missing. Make sure to validate the JSON input beforehand.</p> Source code in <code>bbot/core/event/base.py</code> <pre><code>def event_from_json(j):\n\"\"\"\n    Creates an event object from a JSON dictionary.\n\n    This function deserializes a JSON dictionary to create a new event object, using the `make_event` function\n    for the actual object creation. It sets additional attributes such as the timestamp and scope distance\n    based on the input JSON.\n\n    Parameters:\n        j (Dict): JSON dictionary containing the event attributes.\n                  Must include keys \"data\" and \"type\".\n\n    Returns:\n        BaseEvent: A new event object initialized with attributes from the JSON dictionary.\n\n    Raises:\n        ValidationError: Raised when the JSON dictionary is missing required fields.\n\n    Note:\n        The function assumes that the input JSON dictionary is valid and may raise exceptions\n        if required keys are missing. Make sure to validate the JSON input beforehand.\n    \"\"\"\n    try:\n        kwargs = {\n            \"data\": j[\"data\"],\n            \"event_type\": j[\"type\"],\n            \"scans\": j.get(\"scans\", []),\n            \"tags\": j.get(\"tags\", []),\n            \"confidence\": j.get(\"confidence\", 5),\n            \"dummy\": True,\n        }\n        event = make_event(**kwargs)\n\n        resolved_hosts = j.get(\"resolved_hosts\", [])\n        event._resolved_hosts = set(resolved_hosts)\n\n        event.timestamp = datetime.fromtimestamp(j[\"timestamp\"])\n        event.scope_distance = j[\"scope_distance\"]\n        source_id = j.get(\"source\", None)\n        if source_id is not None:\n            event._source_id = source_id\n        return event\n    except KeyError as e:\n        raise ValidationError(f\"Event missing required field: {e}\")\n</code></pre>"},{"location":"dev/event/#bbot.core.event.base.BaseEvent","title":"BaseEvent","text":"<p>Represents a piece of data discovered during a BBOT scan.</p> <p>An Event contains various attributes that provide metadata about the discovered data. The attributes assist in understanding the context of the Event and facilitate further filtering and querying. Events are integral in the construction of visual graphs and are the cornerstone of data exchange between BBOT modules.</p> <p>You can inherit from this class when creating a new event type. However, it's not always necessary. You only need to subclass if you want to layer additional functionality on top of the base class.</p> <p>Attributes:</p> <ul> <li> <code>type</code>             (<code>str</code>)         \u2013          <p>Specifies the type of the event, e.g., <code>IP_ADDRESS</code>, <code>DNS_NAME</code>.</p> </li> <li> <code>id</code>             (<code>str</code>)         \u2013          <p>A unique identifier for the event.</p> </li> <li> <code>data</code>             (<code>str or dict</code>)         \u2013          <p>The main data for the event, e.g., a URL or IP address.</p> </li> <li> <code>data_graph</code>             (<code>str</code>)         \u2013          <p>Representation of <code>self.data</code> for Neo4j graph nodes.</p> </li> <li> <code>data_human</code>             (<code>str</code>)         \u2013          <p>Representation of <code>self.data</code> for human output.</p> </li> <li> <code>data_id</code>             (<code>str</code>)         \u2013          <p>Representation of <code>self.data</code> used to calculate the event's ID (and ultimately its hash, which is used for deduplication)</p> </li> <li> <code>data_json</code>             (<code>str</code>)         \u2013          <p>Representation of <code>self.data</code> to be used in JSON serialization.</p> </li> <li> <code>host</code>             (<code>str, IPvXAddress, or IPvXNetwork</code>)         \u2013          <p>The associated IP address or hostname for the event</p> </li> <li> <code>host_stem</code>             (<code>str</code>)         \u2013          <p>An abbreviated representation of hostname that removes the TLD, e.g. \"www.evilcorp\". Used by the word cloud.</p> </li> <li> <code>port</code>             (<code>int or None</code>)         \u2013          <p>The port associated with the event, if applicable, else None.</p> </li> <li> <code>words</code>             (<code>set</code>)         \u2013          <p>A list of relevant keywords extracted from the event. Used by the word cloud.</p> </li> <li> <code>scope_distance</code>             (<code>int</code>)         \u2013          <p>Indicates how many hops the event is from the main scope; 0 means in-scope.</p> </li> <li> <code>web_spider_distance</code>             (<code>int</code>)         \u2013          <p>The spider distance from the web root, specific to web crawling.</p> </li> <li> <code>scan</code>             (<code>Scanner</code>)         \u2013          <p>The scan object that generated the event.</p> </li> <li> <code>timestamp</code>             (<code>datetime</code>)         \u2013          <p>The time at which the data was discovered.</p> </li> <li> <code>resolved_hosts</code>             (<code>list of str</code>)         \u2013          <p>List of hosts to which the event data resolves, applicable for URLs and DNS names.</p> </li> <li> <code>source</code>             (<code>BaseEvent</code>)         \u2013          <p>The source event that led to the discovery of this event.</p> </li> <li> <code>source_id</code>             (<code>str</code>)         \u2013          <p>The <code>id</code> attribute of the source event.</p> </li> <li> <code>tags</code>             (<code>set of str</code>)         \u2013          <p>Descriptive tags for the event, e.g., <code>mx-record</code>, <code>in-scope</code>.</p> </li> <li> <code>module</code>             (<code>BaseModule</code>)         \u2013          <p>The module that discovered the event.</p> </li> <li> <code>module_sequence</code>             (<code>str</code>)         \u2013          <p>The sequence of modules that participated in the discovery.</p> </li> </ul> <p>Examples:</p> <pre><code>{\n\"type\": \"URL\",\n\"id\": \"URL:017ec8e5dc158c0fd46f07169f8577fb4b45e89a\",\n\"data\": \"http://www.blacklanternsecurity.com/\",\n\"web_spider_distance\": 0,\n\"scope_distance\": 0,\n\"scan\": \"SCAN:4d786912dbc97be199da13074699c318e2067a7f\",\n\"timestamp\": 1688526222.723366,\n\"resolved_hosts\": [\"185.199.108.153\"],\n\"source\": \"OPEN_TCP_PORT:cf7e6a937b161217eaed99f0c566eae045d094c7\",\n\"tags\": [\"in-scope\", \"distance-0\", \"dir\", \"ip-185-199-108-153\", \"status-301\", \"http-title-301-moved-permanently\"],\n\"module\": \"httpx\",\n\"module_sequence\": \"httpx\"\n}\n</code></pre> Source code in <code>bbot/core/event/base.py</code> <pre><code>class BaseEvent:\n\"\"\"\n    Represents a piece of data discovered during a BBOT scan.\n\n    An Event contains various attributes that provide metadata about the discovered data.\n    The attributes assist in understanding the context of the Event and facilitate further\n    filtering and querying. Events are integral in the construction of visual graphs and\n    are the cornerstone of data exchange between BBOT modules.\n\n    You can inherit from this class when creating a new event type. However, it's not always\n    necessary. You only need to subclass if you want to layer additional functionality on\n    top of the base class.\n\n    Attributes:\n        type (str): Specifies the type of the event, e.g., `IP_ADDRESS`, `DNS_NAME`.\n        id (str): A unique identifier for the event.\n        data (str or dict): The main data for the event, e.g., a URL or IP address.\n        data_graph (str): Representation of `self.data` for Neo4j graph nodes.\n        data_human (str): Representation of `self.data` for human output.\n        data_id (str): Representation of `self.data` used to calculate the event's ID (and ultimately its hash, which is used for deduplication)\n        data_json (str): Representation of `self.data` to be used in JSON serialization.\n        host (str, IPvXAddress, or IPvXNetwork): The associated IP address or hostname for the event\n        host_stem (str): An abbreviated representation of hostname that removes the TLD, e.g. \"www.evilcorp\". Used by the word cloud.\n        port (int or None): The port associated with the event, if applicable, else None.\n        words (set): A list of relevant keywords extracted from the event. Used by the word cloud.\n        scope_distance (int): Indicates how many hops the event is from the main scope; 0 means in-scope.\n        web_spider_distance (int): The spider distance from the web root, specific to web crawling.\n        scan (Scanner): The scan object that generated the event.\n        timestamp (datetime.datetime): The time at which the data was discovered.\n        resolved_hosts (list of str): List of hosts to which the event data resolves, applicable for URLs and DNS names.\n        source (BaseEvent): The source event that led to the discovery of this event.\n        source_id (str): The `id` attribute of the source event.\n        tags (set of str): Descriptive tags for the event, e.g., `mx-record`, `in-scope`.\n        module (BaseModule): The module that discovered the event.\n        module_sequence (str): The sequence of modules that participated in the discovery.\n\n    Examples:\n        ```json\n        {\n            \"type\": \"URL\",\n            \"id\": \"URL:017ec8e5dc158c0fd46f07169f8577fb4b45e89a\",\n            \"data\": \"http://www.blacklanternsecurity.com/\",\n            \"web_spider_distance\": 0,\n            \"scope_distance\": 0,\n            \"scan\": \"SCAN:4d786912dbc97be199da13074699c318e2067a7f\",\n            \"timestamp\": 1688526222.723366,\n            \"resolved_hosts\": [\"185.199.108.153\"],\n            \"source\": \"OPEN_TCP_PORT:cf7e6a937b161217eaed99f0c566eae045d094c7\",\n            \"tags\": [\"in-scope\", \"distance-0\", \"dir\", \"ip-185-199-108-153\", \"status-301\", \"http-title-301-moved-permanently\"],\n            \"module\": \"httpx\",\n            \"module_sequence\": \"httpx\"\n        }\n        ```\n    \"\"\"\n\n    # Always emit this event type even if it's not in scope\n    _always_emit = False\n    # Always emit events with these tags even if they're not in scope\n    _always_emit_tags = [\"affiliate\"]\n    # Whether this event has been retroactively marked as part of an important discovery chain\n    _graph_important = False\n    # Exclude from output modules\n    _omit = False\n    # Disables certain data validations\n    _dummy = False\n    # Data validation, if data is a dictionary\n    _data_validator = None\n\n    def __init__(\n        self,\n        data,\n        event_type,\n        source=None,\n        module=None,\n        scan=None,\n        scans=None,\n        tags=None,\n        confidence=5,\n        timestamp=None,\n        _dummy=False,\n        _internal=None,\n    ):\n\"\"\"\n        Initializes an Event object with the given parameters.\n\n        In most cases, you should use `make_event()` instead of instantiating this class directly.\n        `make_event()` is much friendlier, and can auto-detect the event type for you.\n\n        Attributes:\n            data (str, dict): The primary data for the event.\n            event_type (str, optional): Type of the event, e.g., 'IP_ADDRESS'.\n            source (BaseEvent, optional): Source event that led to this event's discovery. Defaults to None.\n            module (str, optional): Module that discovered the event. Defaults to None.\n            scan (Scan, optional): BBOT Scan object. Required unless _dummy is True. Defaults to None.\n            scans (list of Scan, optional): BBOT Scan objects, used primarily when unserializing an Event from the database. Defaults to None.\n            tags (list of str, optional): Descriptive tags for the event. Defaults to None.\n            confidence (int, optional): Confidence level for the event, on a scale of 1-10. Defaults to 5.\n            timestamp (datetime, optional): Time of event discovery. Defaults to current UTC time.\n            _dummy (bool, optional): If True, disables certain data validations. Defaults to False.\n            _internal (Any, optional): If specified, makes the event internal. Defaults to None.\n\n        Raises:\n            ValidationError: If either `scan` or `source` are not specified and `_dummy` is False.\n        \"\"\"\n\n        self._id = None\n        self._hash = None\n        self.__host = None\n        self._port = None\n        self.__words = None\n        self._priority = None\n        self._module_priority = None\n        self._resolved_hosts = set()\n\n        # keep track of whether this event has been recorded by the scan\n        self._stats_recorded = False\n\n        self.timestamp = datetime.utcnow()\n\n        self._tags = set()\n        if tags is not None:\n            self._tags = set(tagify(s) for s in tags)\n\n        self._data = None\n        self._type = event_type\n        self.confidence = int(confidence)\n\n        # for creating one-off events without enforcing source requirement\n        self._dummy = _dummy\n        self._internal = False\n\n        self.module = module\n        # self.scan holds the instantiated scan object (for helpers, etc.)\n        self.scan = scan\n        if (not self.scan) and (not self._dummy):\n            raise ValidationError(f\"Must specify scan\")\n        # self.scans holds a list of scan IDs from scans that encountered this event\n        self.scans = []\n        if scans is not None:\n            self.scans = scans\n        if self.scan:\n            self.scans = list(set([self.scan.id] + self.scans))\n\n        # check type blacklist\n        self._check_omit()\n\n        self._scope_distance = -1\n\n        try:\n            self.data = self._sanitize_data(data)\n        except Exception as e:\n            log.trace(traceback.format_exc())\n            raise ValidationError(f'Error sanitizing event data \"{data}\" for type \"{self.type}\": {e}')\n\n        if not self.data:\n            raise ValidationError(f'Invalid event data \"{data}\" for type \"{self.type}\"')\n\n        self._source = None\n        self._source_id = None\n        self.source = source\n        if (not self.source) and (not self._dummy):\n            raise ValidationError(f\"Must specify event source\")\n\n        # internal events are not ingested by output modules\n        if not self._dummy:\n            # removed this second part because it was making certain sslcert events internal\n            if _internal:  # or source._internal:\n                self.internal = True\n\n        # an event indicating whether the event has undergone DNS resolution\n        self._resolved = asyncio.Event()\n\n    @property\n    def data(self):\n        return self._data\n\n    @property\n    def resolved_hosts(self):\n        if is_ip(self.host):\n            return {\n                self.host,\n            }\n        return self._resolved_hosts\n\n    @data.setter\n    def data(self, data):\n        self._hash = None\n        self._id = None\n        self.__host = None\n        self._port = None\n        self._data = data\n\n    @property\n    def internal(self):\n        return self._internal\n\n    @internal.setter\n    def internal(self, value):\n\"\"\"\n        Marks the event as internal, excluding it from output but allowing normal exchange between scan modules.\n\n        Internal events are typically speculative and may not be interesting by themselves but can lead to\n        the discovery of interesting events. This method sets the `_internal` attribute to True and adds the\n        \"internal\" tag.\n\n        Examples of internal events include `OPEN_TCP_PORT`s from the `speculate` module,\n        `IP_ADDRESS`es from the `ipneighbor` module, or out-of-scope `DNS_NAME`s that originate\n        from DNS resolutions.\n\n        The purpose of internal events is to enable speculative/explorative discovery without cluttering\n        the console with irrelevant or uninteresting events.\n        \"\"\"\n        if not value in (True, False):\n            raise ValueError(f'\"internal\" must be boolean, not {type(value)}')\n        if value == True:\n            self.add_tag(\"internal\")\n        else:\n            self.remove_tag(\"internal\")\n        self._internal = value\n\n    @property\n    def host(self):\n\"\"\"\n        An abbreviated representation of the data that allows comparison with other events.\n        For host types, this is a hostname.\n        This allows comparison of an email or a URL with a domain, and vice versa\n            bob@evilcorp.com        --&gt; evilcorp.com\n            https://evilcorp.com    --&gt; evilcorp.com\n            evilcorp.com:80         --&gt; evilcorp.com\n\n        For IP_* types, this is an instantiated object representing the event's data\n        E.g. for IP_ADDRESS, it could be an ipaddress.IPv4Address() or IPv6Address() object\n        \"\"\"\n        if self.__host is None:\n            self.__host = self._host()\n        return self.__host\n\n    @property\n    def port(self):\n        self.host\n        if getattr(self, \"parsed\", None):\n            if self.parsed.port is not None:\n                return self.parsed.port\n            elif self.parsed.scheme == \"https\":\n                return 443\n            elif self.parsed.scheme == \"http\":\n                return 80\n        return self._port\n\n    @property\n    def host_stem(self):\n\"\"\"\n        An abbreviated representation of hostname that removes the TLD\n            E.g. www.evilcorp.com --&gt; www.evilcorp\n        \"\"\"\n        if self.host and type(self.host) == str:\n            return domain_stem(self.host)\n        else:\n            return f\"{self.host}\"\n\n    @property\n    def words(self):\n        if self.__words is None:\n            self.__words = set(self._words())\n        return self.__words\n\n    def _words(self):\n        return set()\n\n    @property\n    def tags(self):\n        return self._tags\n\n    @tags.setter\n    def tags(self, tags):\n        if isinstance(tags, str):\n            tags = (tags,)\n        self._tags = set(tagify(s) for s in tags)\n\n    def add_tag(self, tag):\n        self._tags.add(tagify(tag))\n\n    def remove_tag(self, tag):\n        with suppress(KeyError):\n            self._tags.remove(tagify(tag))\n\n    @property\n    def always_emit(self):\n        always_emit_tags = any(t in self.tags for t in self._always_emit_tags)\n        no_host_information = not bool(self.host)\n        return self._always_emit or always_emit_tags or no_host_information\n\n    @property\n    def id(self):\n        if self._id is None:\n            self._id = make_event_id(self.data_id, self.type)\n        return self._id\n\n    @property\n    def scope_distance(self):\n        return self._scope_distance\n\n    @scope_distance.setter\n    def scope_distance(self, scope_distance):\n\"\"\"\n        Setter for the scope_distance attribute, ensuring it only decreases.\n\n        The scope_distance attribute is designed to never increase; it can only be set to smaller values than\n        the current one. If a larger value is provided, it is ignored. The setter also updates the event's\n        tags to reflect the new scope distance.\n\n        Parameters:\n            scope_distance (int): The new scope distance to set, must be a non-negative integer.\n\n        Note:\n            The method will automatically update the relevant 'distance-' tags associated with the event.\n        \"\"\"\n        if scope_distance &gt;= 0:\n            new_scope_distance = None\n            # ensure scope distance does not increase (only allow setting to smaller values)\n            if self.scope_distance == -1:\n                new_scope_distance = scope_distance\n            else:\n                new_scope_distance = min(self.scope_distance, scope_distance)\n            if self._scope_distance != new_scope_distance:\n                # remove old scope distance tags\n                for t in list(self.tags):\n                    if t.startswith(\"distance-\"):\n                        self.remove_tag(t)\n                if scope_distance == 0:\n                    self.add_tag(\"in-scope\")\n                    self.remove_tag(\"affiliate\")\n                else:\n                    self.remove_tag(\"in-scope\")\n                    self.add_tag(f\"distance-{new_scope_distance}\")\n                self._scope_distance = new_scope_distance\n            # apply recursively to parent events\n            source_scope_distance = getattr(self.source, \"scope_distance\", -1)\n            if source_scope_distance &gt;= 0 and self != self.source:\n                self.source.scope_distance = scope_distance + 1\n\n    @property\n    def source(self):\n        return self._source\n\n    @source.setter\n    def source(self, source):\n\"\"\"\n        Setter for the source attribute, ensuring it's a valid event and updating scope distance.\n\n        Sets the source of the event and automatically adjusts the scope distance based on the source event's\n        scope distance. The scope distance is incremented by 1 if the host of the source event is different\n        from the current event's host.\n\n        Parameters:\n            source (BaseEvent): The new source event to set. Must be a valid event object.\n\n        Note:\n            If an invalid source is provided and the event is not a dummy, a warning will be logged.\n        \"\"\"\n        if is_event(source):\n            self._source = source\n            hosts_are_same = self.host == source.host\n            if source.scope_distance &gt;= 0:\n                new_scope_distance = int(source.scope_distance)\n                # only increment the scope distance if the host changes\n                if not hosts_are_same:\n                    new_scope_distance += 1\n                self.scope_distance = new_scope_distance\n            # inherit affiliate tag\n            if hosts_are_same and \"affiliate\" in source.tags:\n                self.add_tag(\"affiliate\")\n        elif not self._dummy:\n            log.warning(f\"Tried to set invalid source on {self}: (got: {source})\")\n\n    @property\n    def source_id(self):\n        source_id = getattr(self.get_source(), \"id\", None)\n        if source_id is not None:\n            return source_id\n        return self._source_id\n\n    def get_source(self):\n\"\"\"\n        Takes into account events with the _omit flag\n        \"\"\"\n        if getattr(self.source, \"_omit\", False):\n            return self.source.get_source()\n        return self.source\n\n    def get_sources(self, omit=False):\n        sources = []\n        e = self\n        while 1:\n            if omit:\n                source = e.get_source()\n            else:\n                source = e.source\n            if e == source:\n                break\n            sources.append(source)\n            e = source\n        return sources\n\n    def _host(self):\n        return \"\"\n\n    def _sanitize_data(self, data):\n\"\"\"\n        Validates and sanitizes the event's data during instantiation.\n\n        By default, uses the '_data_load' method to pre-process the data and then applies the '_data_validator'\n        to validate and create a sanitized dictionary. Raises a ValidationError if any of the validations fail.\n        Subclasses can override this method to provide custom validation logic.\n\n        Returns:\n            Any: The sanitized data.\n\n        Raises:\n            ValidationError: If the data fails to validate.\n        \"\"\"\n        data = self._data_load(data)\n        if self._data_validator is not None:\n            if not isinstance(data, dict):\n                raise ValidationError(f\"data is not of type dict: {data}\")\n            data = self._data_validator(**data).model_dump(exclude_none=True)\n        return self.sanitize_data(data)\n\n    def sanitize_data(self, data):\n        return data\n\n    @property\n    def data_human(self):\n\"\"\"\n        Human representation of event.data\n        \"\"\"\n        return self._data_human()\n\n    def _data_human(self):\n        return str(self.data)\n\n    def _data_load(self, data):\n\"\"\"\n        How to load the event data (JSON-decode it, etc.)\n        \"\"\"\n        return data\n\n    @property\n    def data_id(self):\n\"\"\"\n        Representation of the event.data used to calculate the event's ID\n        \"\"\"\n        return self._data_id()\n\n    def _data_id(self):\n        return self.data\n\n    @property\n    def pretty_string(self):\n\"\"\"\n        A human-friendly representation of the event's data. Used for graph representation.\n\n        If the event's data is a dictionary, the function will try to return a JSON-formatted string.\n        Otherwise, it will use smart_decode to convert the data into a string representation.\n\n        Override if necessary.\n\n        Returns:\n            str: The graphical representation of the event's data.\n        \"\"\"\n        return self._pretty_string()\n\n    def _pretty_string(self):\n        if isinstance(self.data, dict):\n            with suppress(Exception):\n                return json.dumps(self.data, sort_keys=True)\n        return smart_decode(self.data)\n\n    @property\n    def data_graph(self):\n\"\"\"\n        Representation of event.data for neo4j graph nodes\n        \"\"\"\n        return self.pretty_string\n\n    @property\n    def data_json(self):\n\"\"\"\n        JSON representation of event.data\n        \"\"\"\n        return self.data\n\n    def __contains__(self, other):\n\"\"\"\n        Allows events to be compared using the \"in\" operator:\n        E.g.:\n            if some_event in other_event:\n                ...\n        \"\"\"\n        try:\n            other = make_event(other, dummy=True)\n        except ValidationError:\n            return False\n        # if hashes match\n        if other == self:\n            return True\n        # if hosts match\n        if self.host and other.host:\n            if self.host == other.host:\n                return True\n            # hostnames and IPs\n            return host_in_host(other.host, self.host)\n        return False\n\n    def json(self, mode=\"json\"):\n\"\"\"\n        Serializes the event object to a JSON-compatible dictionary.\n\n        By default, it includes attributes such as 'type', 'id', 'data', 'scope_distance', and others that are present.\n        Additional specific attributes can be serialized based on the mode specified.\n\n        Parameters:\n            mode (str): Specifies the data serialization mode. Default is \"json\". Other options include \"graph\", \"human\", and \"id\".\n\n        Returns:\n            dict: JSON-serializable dictionary representation of the event object.\n        \"\"\"\n        j = dict()\n        for i in (\"type\", \"id\"):\n            v = getattr(self, i, \"\")\n            if v:\n                j.update({i: v})\n        data_attr = getattr(self, f\"data_{mode}\", None)\n        if data_attr is not None:\n            j[\"data\"] = data_attr\n        else:\n            j[\"data\"] = smart_decode(self.data)\n        web_spider_distance = getattr(self, \"web_spider_distance\", None)\n        if web_spider_distance is not None:\n            j[\"web_spider_distance\"] = web_spider_distance\n        j[\"scope_distance\"] = self.scope_distance\n        if self.scan:\n            j[\"scan\"] = self.scan.id\n        j[\"timestamp\"] = self.timestamp.timestamp()\n        if self.host:\n            j[\"resolved_hosts\"] = [str(h) for h in self.resolved_hosts]\n        source_id = self.source_id\n        if source_id:\n            j[\"source\"] = source_id\n        if self.tags:\n            j.update({\"tags\": list(self.tags)})\n        if self.module:\n            j.update({\"module\": str(self.module)})\n        if self.module_sequence:\n            j.update({\"module_sequence\": str(self.module_sequence)})\n\n        # normalize non-primitive python objects\n        for k, v in list(j.items()):\n            if k == \"data\":\n                continue\n            if type(v) not in (str, int, float, bool, list, type(None)):\n                try:\n                    j[k] = json.dumps(v, sort_keys=True)\n                except Exception:\n                    j[k] = smart_decode(v)\n        return j\n\n    @staticmethod\n    def from_json(j):\n\"\"\"\n        Convenience shortcut to create an Event object from a JSON-compatible dictionary.\n\n        Calls the `event_from_json()` function to deserialize the event.\n\n        Parameters:\n            j (dict): The JSON-compatible dictionary containing event data.\n\n        Returns:\n            Event: The deserialized Event object.\n        \"\"\"\n        return event_from_json(j)\n\n    @property\n    def module_sequence(self):\n\"\"\"\n        Get a human-friendly string that represents the sequence of modules responsible for generating this event.\n\n        Includes the names of omitted source events to provide a complete view of the module sequence leading to this event.\n\n        Returns:\n            str: The module sequence in human-friendly format.\n        \"\"\"\n        module_name = getattr(self.module, \"name\", \"\")\n        if getattr(self.source, \"_omit\", False):\n            module_name = f\"{self.source.module_sequence}-&gt;{module_name}\"\n        return module_name\n\n    @property\n    def module_priority(self):\n        if self._module_priority is None:\n            module = getattr(self, \"module\", None)\n            self._module_priority = int(max(1, min(5, getattr(module, \"priority\", 3))))\n        return self._module_priority\n\n    @module_priority.setter\n    def module_priority(self, priority):\n        self._module_priority = int(max(1, min(5, priority)))\n\n    @property\n    def priority(self):\n        if self._priority is None:\n            timestamp = self.timestamp.timestamp()\n            if self.source.timestamp == self.timestamp:\n                self._priority = (timestamp,)\n            else:\n                self._priority = getattr(self.source, \"priority\", ()) + (timestamp,)\n\n        return self._priority\n\n    @property\n    def type(self):\n        return self._type\n\n    @type.setter\n    def type(self, val):\n        self._type = val\n        self._hash = None\n        self._id = None\n        self._check_omit()\n\n    def _check_omit(self):\n        if self.scan is not None:\n            omit_event_types = self.scan.config.get(\"omit_event_types\", [])\n            if omit_event_types and self.type in omit_event_types:\n                self._omit = True\n\n    def __iter__(self):\n\"\"\"\n        For dict(event)\n        \"\"\"\n        yield from self.json().items()\n\n    def __lt__(self, other):\n\"\"\"\n        For queue sorting\n        \"\"\"\n        return self.priority &lt; getattr(other, \"priority\", (0,))\n\n    def __gt__(self, other):\n\"\"\"\n        For queue sorting\n        \"\"\"\n        return self.priority &gt; getattr(other, \"priority\", (0,))\n\n    def __eq__(self, other):\n        try:\n            other = make_event(other, dummy=True)\n        except ValidationError:\n            return False\n        return hash(self) == hash(other)\n\n    def __hash__(self):\n        if self._hash is None:\n            self._hash = hash(self.id)\n        return self._hash\n\n    def __str__(self):\n        max_event_len = 80\n        d = str(self.data)\n        return f'{self.type}(\"{d[:max_event_len]}{(\"...\" if len(d) &gt; max_event_len else \"\")}\", module={self.module}, tags={self.tags})'\n\n    def __repr__(self):\n        return str(self)\n</code></pre>"},{"location":"dev/event/#bbot.core.event.base.BaseEvent.pretty_string","title":"pretty_string  <code>property</code>","text":"<pre><code>pretty_string\n</code></pre> <p>A human-friendly representation of the event's data. Used for graph representation.</p> <p>If the event's data is a dictionary, the function will try to return a JSON-formatted string. Otherwise, it will use smart_decode to convert the data into a string representation.</p> <p>Override if necessary.</p> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>The graphical representation of the event's data.</p> </li> </ul>"},{"location":"dev/event/#bbot.core.event.base.BaseEvent.module_sequence","title":"module_sequence  <code>property</code>","text":"<pre><code>module_sequence\n</code></pre> <p>Get a human-friendly string that represents the sequence of modules responsible for generating this event.</p> <p>Includes the names of omitted source events to provide a complete view of the module sequence leading to this event.</p> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>The module sequence in human-friendly format.</p> </li> </ul>"},{"location":"dev/event/#bbot.core.event.base.BaseEvent.__init__","title":"__init__","text":"<pre><code>__init__(data, event_type, source = None, module = None, scan = None, scans = None, tags = None, confidence = 5, timestamp = None, _dummy = False, _internal = None)\n</code></pre> <p>Initializes an Event object with the given parameters.</p> <p>In most cases, you should use <code>make_event()</code> instead of instantiating this class directly. <code>make_event()</code> is much friendlier, and can auto-detect the event type for you.</p> <p>Attributes:</p> <ul> <li> <code>data</code>             (<code>(str, dict)</code>)         \u2013          <p>The primary data for the event.</p> </li> <li> <code>event_type</code>             (<code>str</code>)         \u2013          <p>Type of the event, e.g., 'IP_ADDRESS'.</p> </li> <li> <code>source</code>             (<code>BaseEvent</code>)         \u2013          <p>Source event that led to this event's discovery. Defaults to None.</p> </li> <li> <code>module</code>             (<code>str</code>)         \u2013          <p>Module that discovered the event. Defaults to None.</p> </li> <li> <code>scan</code>             (<code>Scan</code>)         \u2013          <p>BBOT Scan object. Required unless _dummy is True. Defaults to None.</p> </li> <li> <code>scans</code>             (<code>list of Scan</code>)         \u2013          <p>BBOT Scan objects, used primarily when unserializing an Event from the database. Defaults to None.</p> </li> <li> <code>tags</code>             (<code>list of str</code>)         \u2013          <p>Descriptive tags for the event. Defaults to None.</p> </li> <li> <code>confidence</code>             (<code>int</code>)         \u2013          <p>Confidence level for the event, on a scale of 1-10. Defaults to 5.</p> </li> <li> <code>timestamp</code>             (<code>datetime</code>)         \u2013          <p>Time of event discovery. Defaults to current UTC time.</p> </li> <li> <code>_dummy</code>             (<code>bool</code>)         \u2013          <p>If True, disables certain data validations. Defaults to False.</p> </li> <li> <code>_internal</code>             (<code>Any</code>)         \u2013          <p>If specified, makes the event internal. Defaults to None.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValidationError</code>           \u2013          <p>If either <code>scan</code> or <code>source</code> are not specified and <code>_dummy</code> is False.</p> </li> </ul> Source code in <code>bbot/core/event/base.py</code> <pre><code>def __init__(\n    self,\n    data,\n    event_type,\n    source=None,\n    module=None,\n    scan=None,\n    scans=None,\n    tags=None,\n    confidence=5,\n    timestamp=None,\n    _dummy=False,\n    _internal=None,\n):\n\"\"\"\n    Initializes an Event object with the given parameters.\n\n    In most cases, you should use `make_event()` instead of instantiating this class directly.\n    `make_event()` is much friendlier, and can auto-detect the event type for you.\n\n    Attributes:\n        data (str, dict): The primary data for the event.\n        event_type (str, optional): Type of the event, e.g., 'IP_ADDRESS'.\n        source (BaseEvent, optional): Source event that led to this event's discovery. Defaults to None.\n        module (str, optional): Module that discovered the event. Defaults to None.\n        scan (Scan, optional): BBOT Scan object. Required unless _dummy is True. Defaults to None.\n        scans (list of Scan, optional): BBOT Scan objects, used primarily when unserializing an Event from the database. Defaults to None.\n        tags (list of str, optional): Descriptive tags for the event. Defaults to None.\n        confidence (int, optional): Confidence level for the event, on a scale of 1-10. Defaults to 5.\n        timestamp (datetime, optional): Time of event discovery. Defaults to current UTC time.\n        _dummy (bool, optional): If True, disables certain data validations. Defaults to False.\n        _internal (Any, optional): If specified, makes the event internal. Defaults to None.\n\n    Raises:\n        ValidationError: If either `scan` or `source` are not specified and `_dummy` is False.\n    \"\"\"\n\n    self._id = None\n    self._hash = None\n    self.__host = None\n    self._port = None\n    self.__words = None\n    self._priority = None\n    self._module_priority = None\n    self._resolved_hosts = set()\n\n    # keep track of whether this event has been recorded by the scan\n    self._stats_recorded = False\n\n    self.timestamp = datetime.utcnow()\n\n    self._tags = set()\n    if tags is not None:\n        self._tags = set(tagify(s) for s in tags)\n\n    self._data = None\n    self._type = event_type\n    self.confidence = int(confidence)\n\n    # for creating one-off events without enforcing source requirement\n    self._dummy = _dummy\n    self._internal = False\n\n    self.module = module\n    # self.scan holds the instantiated scan object (for helpers, etc.)\n    self.scan = scan\n    if (not self.scan) and (not self._dummy):\n        raise ValidationError(f\"Must specify scan\")\n    # self.scans holds a list of scan IDs from scans that encountered this event\n    self.scans = []\n    if scans is not None:\n        self.scans = scans\n    if self.scan:\n        self.scans = list(set([self.scan.id] + self.scans))\n\n    # check type blacklist\n    self._check_omit()\n\n    self._scope_distance = -1\n\n    try:\n        self.data = self._sanitize_data(data)\n    except Exception as e:\n        log.trace(traceback.format_exc())\n        raise ValidationError(f'Error sanitizing event data \"{data}\" for type \"{self.type}\": {e}')\n\n    if not self.data:\n        raise ValidationError(f'Invalid event data \"{data}\" for type \"{self.type}\"')\n\n    self._source = None\n    self._source_id = None\n    self.source = source\n    if (not self.source) and (not self._dummy):\n        raise ValidationError(f\"Must specify event source\")\n\n    # internal events are not ingested by output modules\n    if not self._dummy:\n        # removed this second part because it was making certain sslcert events internal\n        if _internal:  # or source._internal:\n            self.internal = True\n\n    # an event indicating whether the event has undergone DNS resolution\n    self._resolved = asyncio.Event()\n</code></pre>"},{"location":"dev/event/#bbot.core.event.base.BaseEvent.json","title":"json","text":"<pre><code>json(mode = 'json')\n</code></pre> <p>Serializes the event object to a JSON-compatible dictionary.</p> <p>By default, it includes attributes such as 'type', 'id', 'data', 'scope_distance', and others that are present. Additional specific attributes can be serialized based on the mode specified.</p> <p>Parameters:</p> <ul> <li> <code>mode</code>             (<code>str</code>, default:                 <code>'json'</code> )         \u2013          <p>Specifies the data serialization mode. Default is \"json\". Other options include \"graph\", \"human\", and \"id\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>        \u2013          <p>JSON-serializable dictionary representation of the event object.</p> </li> </ul> Source code in <code>bbot/core/event/base.py</code> <pre><code>def json(self, mode=\"json\"):\n\"\"\"\n    Serializes the event object to a JSON-compatible dictionary.\n\n    By default, it includes attributes such as 'type', 'id', 'data', 'scope_distance', and others that are present.\n    Additional specific attributes can be serialized based on the mode specified.\n\n    Parameters:\n        mode (str): Specifies the data serialization mode. Default is \"json\". Other options include \"graph\", \"human\", and \"id\".\n\n    Returns:\n        dict: JSON-serializable dictionary representation of the event object.\n    \"\"\"\n    j = dict()\n    for i in (\"type\", \"id\"):\n        v = getattr(self, i, \"\")\n        if v:\n            j.update({i: v})\n    data_attr = getattr(self, f\"data_{mode}\", None)\n    if data_attr is not None:\n        j[\"data\"] = data_attr\n    else:\n        j[\"data\"] = smart_decode(self.data)\n    web_spider_distance = getattr(self, \"web_spider_distance\", None)\n    if web_spider_distance is not None:\n        j[\"web_spider_distance\"] = web_spider_distance\n    j[\"scope_distance\"] = self.scope_distance\n    if self.scan:\n        j[\"scan\"] = self.scan.id\n    j[\"timestamp\"] = self.timestamp.timestamp()\n    if self.host:\n        j[\"resolved_hosts\"] = [str(h) for h in self.resolved_hosts]\n    source_id = self.source_id\n    if source_id:\n        j[\"source\"] = source_id\n    if self.tags:\n        j.update({\"tags\": list(self.tags)})\n    if self.module:\n        j.update({\"module\": str(self.module)})\n    if self.module_sequence:\n        j.update({\"module_sequence\": str(self.module_sequence)})\n\n    # normalize non-primitive python objects\n    for k, v in list(j.items()):\n        if k == \"data\":\n            continue\n        if type(v) not in (str, int, float, bool, list, type(None)):\n            try:\n                j[k] = json.dumps(v, sort_keys=True)\n            except Exception:\n                j[k] = smart_decode(v)\n    return j\n</code></pre>"},{"location":"dev/event/#bbot.core.event.base.BaseEvent.from_json","title":"from_json  <code>staticmethod</code>","text":"<pre><code>from_json(j)\n</code></pre> <p>Convenience shortcut to create an Event object from a JSON-compatible dictionary.</p> <p>Calls the <code>event_from_json()</code> function to deserialize the event.</p> <p>Parameters:</p> <ul> <li> <code>j</code>             (<code>dict</code>)         \u2013          <p>The JSON-compatible dictionary containing event data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Event</code>        \u2013          <p>The deserialized Event object.</p> </li> </ul> Source code in <code>bbot/core/event/base.py</code> <pre><code>@staticmethod\ndef from_json(j):\n\"\"\"\n    Convenience shortcut to create an Event object from a JSON-compatible dictionary.\n\n    Calls the `event_from_json()` function to deserialize the event.\n\n    Parameters:\n        j (dict): The JSON-compatible dictionary containing event data.\n\n    Returns:\n        Event: The deserialized Event object.\n    \"\"\"\n    return event_from_json(j)\n</code></pre>"},{"location":"dev/scanner/","title":"Scanner","text":""},{"location":"dev/scanner/#bbot.scanner.Scanner","title":"Scanner","text":"<p>A class representing a single BBOT scan</p> <p>Examples:</p> <p>Create scan with multiple targets:</p> <pre><code>&gt;&gt;&gt; my_scan = Scanner(\"evilcorp.com\", \"1.2.3.0/24\", modules=[\"nmap\", \"sslcert\", \"httpx\"])\n</code></pre> <p>Create scan with custom config:</p> <pre><code>&gt;&gt;&gt; config = {\"http_proxy\": \"http://127.0.0.1:8080\", \"modules\": {\"nmap\": {\"top_ports\": 2000}}}\n&gt;&gt;&gt; my_scan = Scanner(\"www.evilcorp.com\", modules=[\"nmap\", \"httpx\"], config=config)\n</code></pre> <p>Start the scan, iterating over events as they're discovered (synchronous):</p> <pre><code>&gt;&gt;&gt; for event in my_scan.start():\n&gt;&gt;&gt;     print(event)\n</code></pre> <p>Start the scan, iterating over events as they're discovered (asynchronous):</p> <pre><code>&gt;&gt;&gt; async for event in my_scan.async_start():\n&gt;&gt;&gt;     print(event)\n</code></pre> <p>Start the scan without consuming events (synchronous):</p> <pre><code>&gt;&gt;&gt; my_scan.start_without_generator()\n</code></pre> <p>Start the scan without consuming events (asynchronous):</p> <pre><code>&gt;&gt;&gt; await my_scan.async_start_without_generator()\n</code></pre> <p>Attributes:</p> <ul> <li> <code>status</code>             (<code>str</code>)         \u2013          <p>Status of scan, representing its current state. It can take on the following string values, each of which is mapped to an integer code in <code>_status_codes</code>: <pre><code>- \"NOT_STARTED\" (0): Initial status before the scan starts.\n- \"STARTING\" (1): Status when the scan is initializing.\n- \"RUNNING\" (2): Status when the scan is in progress.\n- \"FINISHING\" (3): Status when the scan is in the process of finalizing.\n- \"CLEANING_UP\" (4): Status when the scan is cleaning up resources.\n- \"ABORTING\" (5): Status when the scan is in the process of being aborted.\n- \"ABORTED\" (6): Status when the scan has been aborted.\n- \"FAILED\" (7): Status when the scan has encountered a failure.\n- \"FINISHED\" (8): Status when the scan has successfully completed.\n</code></pre></p> </li> <li> <code>_status_code</code>             (<code>int</code>)         \u2013          <p>The numerical representation of the current scan status, stored for internal use. It is mapped according to the values in <code>_status_codes</code>.</p> </li> <li> <code>target</code>             (<code>Target</code>)         \u2013          <p>Target of scan</p> </li> <li> <code>config</code>             (<code>DictConfig</code>)         \u2013          <p>BBOT config</p> </li> <li> <code>whitelist</code>             (<code>Target</code>)         \u2013          <p>Scan whitelist (by default this is the same as <code>target</code>)</p> </li> <li> <code>blacklist</code>             (<code>Target</code>)         \u2013          <p>Scan blacklist (this takes ultimate precedence)</p> </li> <li> <code>helpers</code>             (<code>ConfigAwareHelper</code>)         \u2013          <p>Helper containing various reusable functions, regexes, etc.</p> </li> <li> <code>manager</code>             (<code>ScanManager</code>)         \u2013          <p>Coordinates and monitors the flow of events between modules during a scan</p> </li> <li> <code>dispatcher</code>             (<code>Dispatcher</code>)         \u2013          <p>Triggers certain events when the scan <code>status</code> changes</p> </li> <li> <code>modules</code>             (<code>dict</code>)         \u2013          <p>Holds all loaded modules in this format: <code>{\"module_name\": Module()}</code></p> </li> <li> <code>stats</code>             (<code>ScanStats</code>)         \u2013          <p>Holds high-level scan statistics such as how many events have been produced and consumed by each module</p> </li> <li> <code>home</code>             (<code>Path</code>)         \u2013          <p>Base output directory of the scan (default: <code>~/.bbot/scans/&lt;scan_name&gt;</code>)</p> </li> <li> <code>running</code>             (<code>bool</code>)         \u2013          <p>Whether the scan is currently running.</p> </li> <li> <code>stopping</code>             (<code>bool</code>)         \u2013          <p>Whether the scan is currently stopping.</p> </li> <li> <code>stopped</code>             (<code>bool</code>)         \u2013          <p>Whether the scan is currently stopped.</p> </li> <li> <code>aborting</code>             (<code>bool</code>)         \u2013          <p>Whether the scan is aborted or currently aborting.</p> </li> </ul> Notes <ul> <li>The status is read-only once set to \"ABORTING\" until it transitions to \"ABORTED.\"</li> <li>Invalid statuses are logged but not applied.</li> <li>Setting a status will trigger the <code>on_status</code> event in the dispatcher.</li> </ul> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>class Scanner:\n\"\"\"A class representing a single BBOT scan\n\n    Examples:\n        Create scan with multiple targets:\n        &gt;&gt;&gt; my_scan = Scanner(\"evilcorp.com\", \"1.2.3.0/24\", modules=[\"nmap\", \"sslcert\", \"httpx\"])\n\n        Create scan with custom config:\n        &gt;&gt;&gt; config = {\"http_proxy\": \"http://127.0.0.1:8080\", \"modules\": {\"nmap\": {\"top_ports\": 2000}}}\n        &gt;&gt;&gt; my_scan = Scanner(\"www.evilcorp.com\", modules=[\"nmap\", \"httpx\"], config=config)\n\n        Start the scan, iterating over events as they're discovered (synchronous):\n        &gt;&gt;&gt; for event in my_scan.start():\n        &gt;&gt;&gt;     print(event)\n\n        Start the scan, iterating over events as they're discovered (asynchronous):\n        &gt;&gt;&gt; async for event in my_scan.async_start():\n        &gt;&gt;&gt;     print(event)\n\n        Start the scan without consuming events (synchronous):\n        &gt;&gt;&gt; my_scan.start_without_generator()\n\n        Start the scan without consuming events (asynchronous):\n        &gt;&gt;&gt; await my_scan.async_start_without_generator()\n\n    Attributes:\n        status (str): Status of scan, representing its current state. It can take on the following string values, each of which is mapped to an integer code in `_status_codes`:\n            ```markdown\n            - \"NOT_STARTED\" (0): Initial status before the scan starts.\n            - \"STARTING\" (1): Status when the scan is initializing.\n            - \"RUNNING\" (2): Status when the scan is in progress.\n            - \"FINISHING\" (3): Status when the scan is in the process of finalizing.\n            - \"CLEANING_UP\" (4): Status when the scan is cleaning up resources.\n            - \"ABORTING\" (5): Status when the scan is in the process of being aborted.\n            - \"ABORTED\" (6): Status when the scan has been aborted.\n            - \"FAILED\" (7): Status when the scan has encountered a failure.\n            - \"FINISHED\" (8): Status when the scan has successfully completed.\n            ```\n        _status_code (int): The numerical representation of the current scan status, stored for internal use. It is mapped according to the values in `_status_codes`.\n        target (Target): Target of scan\n        config (omegaconf.dictconfig.DictConfig): BBOT config\n        whitelist (Target): Scan whitelist (by default this is the same as `target`)\n        blacklist (Target): Scan blacklist (this takes ultimate precedence)\n        helpers (ConfigAwareHelper): Helper containing various reusable functions, regexes, etc.\n        manager (ScanManager): Coordinates and monitors the flow of events between modules during a scan\n        dispatcher (Dispatcher): Triggers certain events when the scan `status` changes\n        modules (dict): Holds all loaded modules in this format: `{\"module_name\": Module()}`\n        stats (ScanStats): Holds high-level scan statistics such as how many events have been produced and consumed by each module\n        home (pathlib.Path): Base output directory of the scan (default: `~/.bbot/scans/&lt;scan_name&gt;`)\n        running (bool): Whether the scan is currently running.\n        stopping (bool): Whether the scan is currently stopping.\n        stopped (bool): Whether the scan is currently stopped.\n        aborting (bool): Whether the scan is aborted or currently aborting.\n\n    Notes:\n        - The status is read-only once set to \"ABORTING\" until it transitions to \"ABORTED.\"\n        - Invalid statuses are logged but not applied.\n        - Setting a status will trigger the `on_status` event in the dispatcher.\n    \"\"\"\n\n    _status_codes = {\n        \"NOT_STARTED\": 0,\n        \"STARTING\": 1,\n        \"RUNNING\": 2,\n        \"FINISHING\": 3,\n        \"CLEANING_UP\": 4,\n        \"ABORTING\": 5,\n        \"ABORTED\": 6,\n        \"FAILED\": 7,\n        \"FINISHED\": 8,\n    }\n\n    def __init__(\n        self,\n        *targets,\n        whitelist=None,\n        blacklist=None,\n        scan_id=None,\n        name=None,\n        modules=None,\n        output_modules=None,\n        output_dir=None,\n        config=None,\n        dispatcher=None,\n        strict_scope=False,\n        force_start=False,\n    ):\n\"\"\"\n        Initializes the Scanner class.\n\n        Args:\n            *targets (str): Target(s) to scan.\n            whitelist (list, optional): Whitelisted target(s) to scan. Defaults to the same as `targets`.\n            blacklist (list, optional): Blacklisted target(s). Takes ultimate precedence. Defaults to empty.\n            scan_id (str, optional): Unique identifier for the scan. Auto-generates if None.\n            name (str, optional): Human-readable name of the scan. Auto-generates if None.\n            modules (list[str], optional): List of module names to use during the scan. Defaults to empty list.\n            output_modules (list[str], optional): List of output modules to use. Defaults to ['python'].\n            output_dir (str or Path, optional): Directory to store scan output. Defaults to BBOT home directory (`~/.bbot`).\n            config (dict, optional): Configuration settings. Merged with BBOT config.\n            dispatcher (Dispatcher, optional): Dispatcher object to use. Defaults to new Dispatcher.\n            strict_scope (bool, optional): If True, only targets explicitly in whitelist are scanned. Defaults to False.\n            force_start (bool, optional): If True, allows the scan to start even when module setups hard-fail. Defaults to False.\n        \"\"\"\n        if modules is None:\n            modules = []\n        if output_modules is None:\n            output_modules = [\"python\"]\n\n        if isinstance(modules, str):\n            modules = [modules]\n        if isinstance(output_modules, str):\n            output_modules = [output_modules]\n\n        if config is None:\n            config = OmegaConf.create({})\n        else:\n            config = OmegaConf.create(config)\n        self.config = OmegaConf.merge(bbot_config, config)\n        prepare_environment(self.config)\n        if self.config.get(\"debug\", False):\n            set_log_level(logging.DEBUG)\n\n        self.strict_scope = strict_scope\n        self.force_start = force_start\n\n        if scan_id is not None:\n            self.id = str(scan_id)\n        else:\n            self.id = f\"SCAN:{sha1(rand_string(20)).hexdigest()}\"\n        self._status = \"NOT_STARTED\"\n        self._status_code = 0\n\n        self.max_workers = max(1, self.config.get(\"max_threads\", 25))\n        self.helpers = ConfigAwareHelper(config=self.config, scan=self)\n\n        if name is None:\n            tries = 0\n            while 1:\n                if tries &gt; 5:\n                    self.name = f\"{self.helpers.rand_string(4)}_{self.helpers.rand_string(4)}\"\n                    break\n                self.name = random_name()\n                if output_dir is not None:\n                    home_path = Path(output_dir).resolve() / self.name\n                else:\n                    home_path = self.helpers.bbot_home / \"scans\" / self.name\n                if not home_path.exists():\n                    break\n                tries += 1\n        else:\n            self.name = str(name)\n\n        if output_dir is not None:\n            self.home = Path(output_dir).resolve() / self.name\n        else:\n            self.home = self.helpers.bbot_home / \"scans\" / self.name\n\n        self.target = Target(self, *targets, strict_scope=strict_scope, make_in_scope=True)\n\n        self.modules = OrderedDict({})\n        self._scan_modules = modules\n        self._internal_modules = list(self._internal_modules())\n        self._output_modules = output_modules\n        self._modules_loaded = False\n\n        if not whitelist:\n            self.whitelist = self.target.copy()\n        else:\n            self.whitelist = Target(self, *whitelist, strict_scope=strict_scope)\n        if not blacklist:\n            blacklist = []\n        self.blacklist = Target(self, *blacklist)\n\n        if dispatcher is None:\n            self.dispatcher = Dispatcher()\n        else:\n            self.dispatcher = dispatcher\n        self.dispatcher.set_scan(self)\n\n        self.manager = ScanManager(self)\n        self.stats = ScanStats(self)\n\n        # scope distance\n        self.scope_search_distance = max(0, int(self.config.get(\"scope_search_distance\", 0)))\n        self.scope_dns_search_distance = max(\n            self.scope_search_distance, int(self.config.get(\"scope_dns_search_distance\", 2))\n        )\n        self.scope_report_distance = int(self.config.get(\"scope_report_distance\", 1))\n\n        # custom HTTP headers warning\n        self.custom_http_headers = self.config.get(\"http_headers\", {})\n        if self.custom_http_headers:\n            self.warning(\n                \"You have enabled custom HTTP headers. These will be attached to all in-scope requests and all requests made by httpx.\"\n            )\n\n        # how often to print scan status\n        self.status_frequency = self.config.get(\"status_frequency\", 15)\n\n        self._prepped = False\n        self._finished_init = False\n        self._cleanedup = False\n\n        self.__loop = None\n        self._manager_worker_loop_tasks = []\n        self.init_events_task = None\n        self.ticker_task = None\n        self.dispatcher_tasks = []\n\n        # multiprocessing thread pool\n        try:\n            mp.set_start_method(\"spawn\")\n        except Exception:\n            self.warning(f\"Failed to set multiprocessing spawn method. This may negatively affect performance.\")\n        self.process_pool = ProcessPoolExecutor()\n\n        self._stopping = False\n\n        self._dns_regexes = None\n        self.__log_handlers = None\n        self._log_handler_backup = []\n\n    def _on_keyboard_interrupt(self, loop, event):\n        self.stop()\n\n    async def _prep(self):\n\"\"\"\n        Calls .load_modules() and .setup_modules() in preparation for a scan\n        \"\"\"\n\n        self.helpers.mkdir(self.home)\n        if not self._prepped:\n            start_msg = f\"Scan with {len(self._scan_modules):,} modules seeded with {len(self.target):,} targets\"\n            details = []\n            if self.whitelist != self.target:\n                details.append(f\"{len(self.whitelist):,} in whitelist\")\n            if self.blacklist:\n                details.append(f\"{len(self.blacklist):,} in blacklist\")\n            if details:\n                start_msg += f\" ({', '.join(details)})\"\n            self.hugeinfo(start_msg)\n\n            await self.load_modules()\n\n            self.info(f\"Setting up modules...\")\n            await self.setup_modules()\n\n            self.success(f\"Setup succeeded for {len(self.modules):,} modules.\")\n            self._prepped = True\n\n    def start(self):\n        for event in async_to_sync_gen(self.async_start()):\n            yield event\n\n    def start_without_generator(self):\n        for event in async_to_sync_gen(self.async_start()):\n            pass\n\n    async def async_start_without_generator(self):\n        async for event in self.async_start():\n            pass\n\n    async def async_start(self):\n\"\"\" \"\"\"\n        failed = True\n        scan_start_time = datetime.now()\n        try:\n            await self._prep()\n\n            self._start_log_handlers()\n\n            if not self.target:\n                self.warning(f\"No scan targets specified\")\n\n            # start status ticker\n            self.ticker_task = asyncio.create_task(self._status_ticker(self.status_frequency))\n\n            self.status = \"STARTING\"\n\n            if not self.modules:\n                self.error(f\"No modules loaded\")\n                self.status = \"FAILED\"\n                return\n            else:\n                self.hugesuccess(f\"Starting scan {self.name}\")\n\n            await self.dispatcher.on_start(self)\n\n            # start manager worker loops\n            self._manager_worker_loop_tasks = [\n                asyncio.create_task(self.manager._worker_loop()) for _ in range(self.max_workers)\n            ]\n\n            # distribute seed events\n            self.init_events_task = asyncio.create_task(self.manager.init_events())\n\n            self.status = \"RUNNING\"\n            self._start_modules()\n            self.verbose(f\"{len(self.modules):,} modules started\")\n\n            # main scan loop\n            while 1:\n                # abort if we're aborting\n                if self.aborting:\n                    self._drain_queues()\n                    break\n\n                if \"python\" in self.modules:\n                    events, finish = await self.modules[\"python\"]._events_waiting()\n                    for e in events:\n                        yield e\n\n                # if initialization finished and the scan is no longer active\n                if self._finished_init and not self.manager.active:\n                    new_activity = await self.finish()\n                    if not new_activity:\n                        break\n\n                await asyncio.sleep(0.1)\n\n            failed = False\n\n        except BaseException as e:\n            exception_chain = self.helpers.get_exception_chain(e)\n            if any(isinstance(exc, (KeyboardInterrupt, asyncio.CancelledError)) for exc in exception_chain):\n                self.stop()\n                failed = False\n            else:\n                try:\n                    raise\n                except ScanError as e:\n                    self.error(f\"{e}\")\n\n                except BBOTError as e:\n                    self.critical(f\"Error during scan: {e}\")\n\n                except Exception:\n                    self.critical(f\"Unexpected error during scan:\\n{traceback.format_exc()}\")\n\n        finally:\n            self._cancel_tasks()\n            await self._report()\n            await self._cleanup()\n\n            log_fn = self.hugesuccess\n            if self.status == \"ABORTING\":\n                self.status = \"ABORTED\"\n                log_fn = self.hugewarning\n            elif failed:\n                self.status = \"FAILED\"\n                log_fn = self.critical\n            else:\n                self.status = \"FINISHED\"\n\n            scan_run_time = datetime.now() - scan_start_time\n            scan_run_time = self.helpers.human_timedelta(scan_run_time)\n            log_fn(f\"Scan {self.name} completed in {scan_run_time} with status {self.status}\")\n\n            await self.dispatcher.on_finish(self)\n\n            self._stop_log_handlers()\n\n    def _start_modules(self):\n        self.verbose(f\"Starting module worker loops\")\n        for module_name, module in self.modules.items():\n            module.start()\n\n    async def setup_modules(self, remove_failed=True):\n\"\"\"Asynchronously initializes all loaded modules by invoking their `setup()` methods.\n\n        Args:\n            remove_failed (bool): Flag indicating whether to remove modules that fail setup.\n\n        Returns:\n            dict: Dictionary containing lists of module names categorized by their setup status.\n                  'succeeded' - List of modules that successfully set up.\n                  'hard_failed' - List of modules that encountered a hard failure during setup.\n                  'soft_failed' - List of modules that encountered a soft failure during setup.\n\n        Raises:\n            ScanError: If no output modules could be loaded.\n\n        Notes:\n            Hard-failed modules are set to an error state and removed if `remove_failed` is True.\n            Soft-failed modules are not set to an error state but are also removed if `remove_failed` is True.\n        \"\"\"\n        await self.load_modules()\n        self.verbose(f\"Setting up modules\")\n        succeeded = []\n        hard_failed = []\n        soft_failed = []\n\n        async for task in self.helpers.as_completed([m._setup() for m in self.modules.values()]):\n            module_name, status, msg = await task\n            if status == True:\n                self.debug(f\"Setup succeeded for {module_name} ({msg})\")\n                succeeded.append(module_name)\n            elif status == False:\n                self.error(f\"Setup hard-failed for {module_name}: {msg}\")\n                self.modules[module_name].set_error_state()\n                hard_failed.append(module_name)\n            else:\n                self.warning(f\"Setup soft-failed for {module_name}: {msg}\")\n                soft_failed.append(module_name)\n            if not status and remove_failed:\n                self.modules.pop(module_name)\n\n        num_output_modules = len([m for m in self.modules.values() if m._type == \"output\"])\n        if num_output_modules &lt; 1:\n            raise ScanError(\"Failed to load output modules. Aborting.\")\n        total_failed = len(hard_failed + soft_failed)\n        if hard_failed:\n            msg = f\"Setup hard-failed for {len(hard_failed):,} modules ({','.join(hard_failed)})\"\n            self._fail_setup(msg)\n        elif total_failed &gt; 0:\n            self.warning(f\"Setup failed for {total_failed:,} modules\")\n\n        return {\n            \"succeeded\": succeeded,\n            \"hard_failed\": hard_failed,\n            \"soft_failed\": soft_failed,\n        }\n\n    async def load_modules(self):\n\"\"\"Asynchronously import and instantiate all scan modules, including internal and output modules.\n\n        This method is automatically invoked by `setup_modules()`. It performs several key tasks in the following sequence:\n\n        1. Install dependencies for each module via `self.helpers.depsinstaller.install()`.\n        2. Load scan modules and updates the `modules` dictionary.\n        3. Load internal modules and updates the `modules` dictionary.\n        4. Load output modules and updates the `modules` dictionary.\n        5. Sorts modules based on their `_priority` attribute.\n\n        If any modules fail to load or their dependencies fail to install, a ScanError will be raised (unless `self.force_start` is set to True).\n\n        Attributes:\n            succeeded, failed (tuple): A tuple containing lists of modules that succeeded or failed during the dependency installation.\n            loaded_modules, loaded_internal_modules, loaded_output_modules (dict): Dictionaries of successfully loaded modules.\n            failed, failed_internal, failed_output (list): Lists of module names that failed to load.\n\n        Raises:\n            ScanError: If any module dependencies fail to install or modules fail to load, and if self.force_start is False.\n\n        Returns:\n            None\n\n        Note:\n            After all modules are loaded, they are sorted by `_priority` and stored in the `modules` dictionary.\n        \"\"\"\n        if not self._modules_loaded:\n            all_modules = list(set(self._scan_modules + self._output_modules + self._internal_modules))\n            if not all_modules:\n                self.warning(f\"No modules to load\")\n                return\n\n            if not self._scan_modules:\n                self.warning(f\"No scan modules to load\")\n\n            # install module dependencies\n            succeeded, failed = await self.helpers.depsinstaller.install(\n                *self._scan_modules, *self._output_modules, *self._internal_modules\n            )\n            if failed:\n                msg = f\"Failed to install dependencies for {len(failed):,} modules: {','.join(failed)}\"\n                self._fail_setup(msg)\n            modules = sorted([m for m in self._scan_modules if m in succeeded])\n            output_modules = sorted([m for m in self._output_modules if m in succeeded])\n            internal_modules = sorted([m for m in self._internal_modules if m in succeeded])\n\n            # Load scan modules\n            self.verbose(f\"Loading {len(modules):,} scan modules: {','.join(modules)}\")\n            loaded_modules, failed = self._load_modules(modules)\n            self.modules.update(loaded_modules)\n            if len(failed) &gt; 0:\n                msg = f\"Failed to load {len(failed):,} scan modules: {','.join(failed)}\"\n                self._fail_setup(msg)\n            if loaded_modules:\n                self.info(\n                    f\"Loaded {len(loaded_modules):,}/{len(self._scan_modules):,} scan modules ({','.join(loaded_modules)})\"\n                )\n\n            # Load internal modules\n            self.verbose(f\"Loading {len(internal_modules):,} internal modules: {','.join(internal_modules)}\")\n            loaded_internal_modules, failed_internal = self._load_modules(internal_modules)\n            self.modules.update(loaded_internal_modules)\n            if len(failed_internal) &gt; 0:\n                msg = f\"Failed to load {len(loaded_internal_modules):,} internal modules: {','.join(loaded_internal_modules)}\"\n                self._fail_setup(msg)\n            if loaded_internal_modules:\n                self.info(\n                    f\"Loaded {len(loaded_internal_modules):,}/{len(self._internal_modules):,} internal modules ({','.join(loaded_internal_modules)})\"\n                )\n\n            # Load output modules\n            self.verbose(f\"Loading {len(output_modules):,} output modules: {','.join(output_modules)}\")\n            loaded_output_modules, failed_output = self._load_modules(output_modules)\n            self.modules.update(loaded_output_modules)\n            if len(failed_output) &gt; 0:\n                msg = f\"Failed to load {len(failed_output):,} output modules: {','.join(failed_output)}\"\n                self._fail_setup(msg)\n            if loaded_output_modules:\n                self.info(\n                    f\"Loaded {len(loaded_output_modules):,}/{len(self._output_modules):,} output modules, ({','.join(loaded_output_modules)})\"\n                )\n\n            self.modules = OrderedDict(sorted(self.modules.items(), key=lambda x: getattr(x[-1], \"_priority\", 0)))\n            self._modules_loaded = True\n\n    def stop(self):\n\"\"\"Stops the in-progress scan and performs necessary cleanup.\n\n        This method sets the scan's status to \"ABORTING,\" cancels any pending tasks, and drains event queues. It also kills child processes spawned during the scan.\n\n        Returns:\n            None\n        \"\"\"\n        if not self._stopping:\n            self._stopping = True\n            self.status = \"ABORTING\"\n            self.hugewarning(f\"Aborting scan\")\n            self.trace()\n            self._cancel_tasks()\n            self._drain_queues()\n            self.helpers.kill_children()\n            self._drain_queues()\n            self.helpers.kill_children()\n\n    async def finish(self):\n\"\"\"Finalizes the scan by invoking the `finished()` method on all active modules if new activity is detected.\n\n        The method is idempotent and will return False if no new activity has been recorded since the last invocation.\n\n        Returns:\n            bool: True if new activity has been detected and the `finished()` method is invoked on all modules.\n                  False if no new activity has been detected since the last invocation.\n\n        Notes:\n            This method alters the scan's status to \"FINISHING\" if new activity is detected.\n        \"\"\"\n        # if new events were generated since last time we were here\n        if self.manager._new_activity:\n            self.manager._new_activity = False\n            self.status = \"FINISHING\"\n            # Trigger .finished() on every module and start over\n            log.info(\"Finishing scan\")\n            finished_event = self.make_event(\"FINISHED\", \"FINISHED\", dummy=True)\n            for module in self.modules.values():\n                await module.queue_event(finished_event)\n            self.verbose(\"Completed finish()\")\n            return True\n        # Return False if no new events were generated since last time\n        self.verbose(\"Completed final finish()\")\n        return False\n\n    def _drain_queues(self):\n\"\"\"Empties all the event queues for each loaded module and the manager's incoming event queue.\n\n        This method iteratively empties both the incoming and outgoing event queues of each module, as well as the incoming event queue of the scan manager.\n\n        Returns:\n            None\n        \"\"\"\n        self.debug(\"Draining queues\")\n        for module in self.modules.values():\n            with contextlib.suppress(asyncio.queues.QueueEmpty):\n                while 1:\n                    if module.incoming_event_queue:\n                        module.incoming_event_queue.get_nowait()\n            with contextlib.suppress(asyncio.queues.QueueEmpty):\n                while 1:\n                    if module.outgoing_event_queue:\n                        module.outgoing_event_queue.get_nowait()\n        with contextlib.suppress(asyncio.queues.QueueEmpty):\n            while 1:\n                self.manager.incoming_event_queue.get_nowait()\n        self.debug(\"Finished draining queues\")\n\n    def _cancel_tasks(self):\n\"\"\"Cancels all asynchronous tasks and shuts down the process pool.\n\n        This method collects all pending tasks from each module, the dispatcher,\n        and the scan manager. After collecting these tasks, it cancels them synchronously\n        using a helper function. Finally, it shuts down the process pool, canceling any\n        pending futures.\n\n        Returns:\n            None\n        \"\"\"\n        tasks = []\n        # module workers\n        for m in self.modules.values():\n            tasks += getattr(m, \"_tasks\", [])\n        # init events\n        if self.init_events_task:\n            tasks.append(self.init_events_task)\n        # ticker\n        if self.ticker_task:\n            tasks.append(self.ticker_task)\n        # dispatcher\n        tasks += self.dispatcher_tasks\n        # manager worker loops\n        tasks += self._manager_worker_loop_tasks\n        self.helpers.cancel_tasks_sync(tasks)\n        # process pool\n        self.process_pool.shutdown(cancel_futures=True)\n\n    async def _report(self):\n\"\"\"Asynchronously executes the `report()` method for each module in the scan.\n\n        This method is called once at the end of each scan and is responsible for\n        triggering the `report()` function for each module. It executes irrespective\n        of whether the scan was aborted or completed successfully. The method makes\n        use of an asynchronous context manager (`_acatch`) to handle exceptions and\n        a task counter to keep track of the task's context.\n\n        Returns:\n            None\n        \"\"\"\n        for mod in self.modules.values():\n            context = f\"{mod.name}.report()\"\n            async with self._acatch(context), mod._task_counter.count(context):\n                await mod.report()\n\n    async def _cleanup(self):\n\"\"\"Asynchronously executes the `cleanup()` method for each module in the scan.\n\n        This method is called once at the end of the scan to perform resource cleanup\n        tasks. It is executed regardless of whether the scan was aborted or completed\n        successfully. The scan status is set to \"CLEANING_UP\" during the execution.\n        After calling the `cleanup()` method for each module, it performs additional\n        cleanup tasks such as removing the scan's home directory if empty and cleaning\n        old scans.\n\n        Returns:\n            None\n        \"\"\"\n        self.status = \"CLEANING_UP\"\n        for mod in self.modules.values():\n            await mod._cleanup()\n        if not self._cleanedup:\n            self._cleanedup = True\n            with contextlib.suppress(Exception):\n                self.home.rmdir()\n            self.helpers.clean_old_scans()\n\n    def in_scope(self, e):\n\"\"\"\n        Check whether a hostname, url, IP, etc. is in scope.\n        Accepts either events or string data.\n\n        Checks whitelist and blacklist.\n        If `e` is an event and its scope distance is zero, it will be considered in-scope.\n\n        Examples:\n            Check if a URL is in scope:\n            &gt;&gt;&gt; scan.in_scope(\"http://www.evilcorp.com\")\n            True\n        \"\"\"\n        try:\n            e = make_event(e, dummy=True)\n        except ValidationError:\n            return False\n        in_scope = e.scope_distance == 0 or self.whitelisted(e)\n        return in_scope and not self.blacklisted(e)\n\n    def blacklisted(self, e):\n\"\"\"\n        Check whether a hostname, url, IP, etc. is blacklisted.\n        \"\"\"\n        e = make_event(e, dummy=True)\n        return e in self.blacklist\n\n    def whitelisted(self, e):\n\"\"\"\n        Check whether a hostname, url, IP, etc. is whitelisted.\n        \"\"\"\n        e = make_event(e, dummy=True)\n        return e in self.whitelist\n\n    @property\n    def word_cloud(self):\n        return self.helpers.word_cloud\n\n    @property\n    def stopping(self):\n        return not self.running\n\n    @property\n    def stopped(self):\n        return self._status_code &gt; 5\n\n    @property\n    def running(self):\n        return 0 &lt; self._status_code &lt; 4\n\n    @property\n    def aborting(self):\n        return 5 &lt;= self._status_code &lt;= 6\n\n    @property\n    def status(self):\n        return self._status\n\n    @status.setter\n    def status(self, status):\n\"\"\"\n        Block setting after status has been aborted\n        \"\"\"\n        status = str(status).strip().upper()\n        if status in self._status_codes:\n            if self.status == \"ABORTING\" and not status == \"ABORTED\":\n                self.debug(f'Attempt to set invalid status \"{status}\" on aborted scan')\n            else:\n                if status != self._status:\n                    self._status = status\n                    self._status_code = self._status_codes[status]\n                    self.dispatcher_tasks.append(\n                        asyncio.create_task(self.dispatcher.catch(self.dispatcher.on_status, self._status, self.id))\n                    )\n                else:\n                    self.debug(f'Scan status is already \"{status}\"')\n        else:\n            self.debug(f'Attempt to set invalid status \"{status}\" on scan')\n\n    def make_event(self, *args, **kwargs):\n        kwargs[\"scan\"] = self\n        event = make_event(*args, **kwargs)\n        return event\n\n    @property\n    def root_event(self):\n\"\"\"\n        The root scan event, e.g.:\n            ```json\n            {\n              \"type\": \"SCAN\",\n              \"id\": \"SCAN:1188928d942ace8e3befae0bdb9c3caa22705f54\",\n              \"data\": \"pixilated_kathryn (SCAN:1188928d942ace8e3befae0bdb9c3caa22705f54)\",\n              \"scope_distance\": 0,\n              \"scan\": \"SCAN:1188928d942ace8e3befae0bdb9c3caa22705f54\",\n              \"timestamp\": 1694548779.616255,\n              \"source\": \"SCAN:1188928d942ace8e3befae0bdb9c3caa22705f54\",\n              \"tags\": [\n                \"distance-0\"\n              ],\n              \"module\": \"TARGET\",\n              \"module_sequence\": \"TARGET\"\n            }\n            ```\n        \"\"\"\n        root_event = self.make_event(data=f\"{self.name} ({self.id})\", event_type=\"SCAN\", dummy=True)\n        root_event._id = self.id\n        root_event.scope_distance = 0\n        root_event._resolved.set()\n        root_event.source = root_event\n        root_event.module = self.helpers._make_dummy_module(name=\"TARGET\", _type=\"TARGET\")\n        return root_event\n\n    def run_in_executor(self, callback, *args, **kwargs):\n\"\"\"\n        Run a synchronous task in the event loop's default thread pool executor\n\n        Examples:\n            Execute callback:\n            &gt;&gt;&gt; result = await self.scan.run_in_executor(callback_fn, arg1, arg2)\n        \"\"\"\n        callback = partial(callback, **kwargs)\n        return self._loop.run_in_executor(None, callback, *args)\n\n    def run_in_executor_mp(self, callback, *args, **kwargs):\n\"\"\"\n        Same as run_in_executor() except with a process pool executor\n        Use only in cases where callback is CPU-bound\n\n        Examples:\n            Execute callback:\n            &gt;&gt;&gt; result = await self.scan.run_in_executor_mp(callback_fn, arg1, arg2)\n        \"\"\"\n        callback = partial(callback, **kwargs)\n        return self._loop.run_in_executor(self.process_pool, callback, *args)\n\n    @property\n    def dns_regexes(self):\n\"\"\"\n        A list of DNS hostname regexes generated from the scan target\n        For the purpose of extracting hostnames\n\n        Examples:\n            Extract hostnames from text:\n            &gt;&gt;&gt; for regex in scan.dns_regexes:\n            ...     for match in regex.finditer(response.text):\n            ...         hostname = match.group().lower()\n        \"\"\"\n        if self._dns_regexes is None:\n            dns_targets = set(t.host for t in self.target if t.host and isinstance(t.host, str))\n            dns_whitelist = set(t.host for t in self.whitelist if t.host and isinstance(t.host, str))\n            dns_targets.update(dns_whitelist)\n            dns_targets = sorted(dns_targets, key=len)\n            dns_targets_set = set()\n            dns_regexes = []\n            for t in dns_targets:\n                if not any(x in dns_targets_set for x in self.helpers.domain_parents(t, include_self=True)):\n                    dns_targets_set.add(t)\n                    dns_regexes.append(re.compile(r\"((?:(?:[\\w-]+)\\.)+\" + re.escape(t) + \")\", re.I))\n            self._dns_regexes = dns_regexes\n\n        return self._dns_regexes\n\n    @property\n    def useragent(self):\n\"\"\"\n        Convenient shortcut to the HTTP user-agent configured for the scan\n        \"\"\"\n        return self.config.get(\"user_agent\", \"BBOT\")\n\n    @property\n    def json(self):\n\"\"\"\n        A dictionary representation of the scan including its name, ID, targets, whitelist, blacklist, and modules\n        \"\"\"\n        j = dict()\n        for i in (\"id\", \"name\"):\n            v = getattr(self, i, \"\")\n            if v:\n                j.update({i: v})\n        if self.target:\n            j.update({\"targets\": [str(e.data) for e in self.target]})\n        if self.whitelist:\n            j.update({\"whitelist\": [str(e.data) for e in self.whitelist]})\n        if self.blacklist:\n            j.update({\"blacklist\": [str(e.data) for e in self.blacklist]})\n        if self.modules:\n            j.update({\"modules\": [str(m) for m in self.modules]})\n        return j\n\n    def debug(self, *args, trace=False, **kwargs):\n        log.debug(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def verbose(self, *args, trace=False, **kwargs):\n        log.verbose(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def hugeverbose(self, *args, trace=False, **kwargs):\n        log.hugeverbose(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def info(self, *args, trace=False, **kwargs):\n        log.info(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def hugeinfo(self, *args, trace=False, **kwargs):\n        log.hugeinfo(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def success(self, *args, trace=False, **kwargs):\n        log.success(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def hugesuccess(self, *args, trace=False, **kwargs):\n        log.hugesuccess(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def warning(self, *args, trace=True, **kwargs):\n        log.warning(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def hugewarning(self, *args, trace=True, **kwargs):\n        log.hugewarning(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def error(self, *args, trace=True, **kwargs):\n        log.error(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    def trace(self):\n        e_type, e_val, e_traceback = exc_info()\n        if e_type is not None:\n            log.trace(traceback.format_exc())\n\n    def critical(self, *args, trace=True, **kwargs):\n        log.critical(*args, extra={\"scan_id\": self.id}, **kwargs)\n        if trace:\n            self.trace()\n\n    @property\n    def log_level(self):\n\"\"\"\n        Return the current log level, e.g. logging.INFO\n        \"\"\"\n        return get_log_level()\n\n    @property\n    def _log_handlers(self):\n        if self.__log_handlers is None:\n            self.helpers.mkdir(self.home)\n            main_handler = logging.handlers.TimedRotatingFileHandler(\n                str(self.home / \"scan.log\"), when=\"d\", interval=1, backupCount=14\n            )\n            main_handler.addFilter(\n                lambda x: x.levelno not in (logging.STDOUT, logging.TRACE) and x.levelno &gt;= logging.VERBOSE\n            )\n            debug_handler = logging.handlers.TimedRotatingFileHandler(\n                str(self.home / \"debug.log\"), when=\"d\", interval=1, backupCount=14\n            )\n            debug_handler.addFilter(lambda x: x.levelno != logging.STDOUT and x.levelno &gt;= logging.DEBUG)\n            self.__log_handlers = [main_handler, debug_handler]\n        return self.__log_handlers\n\n    def _start_log_handlers(self):\n        # add log handlers\n        for handler in self._log_handlers:\n            add_log_handler(handler)\n        # temporarily disable main ones\n        for handler_name in (\"file_main\", \"file_debug\"):\n            handler = get_log_handlers().get(handler_name, None)\n            if handler is not None and handler not in self._log_handler_backup:\n                self._log_handler_backup.append(handler)\n                remove_log_handler(handler)\n\n    def _stop_log_handlers(self):\n        # remove log handlers\n        for handler in self._log_handlers:\n            remove_log_handler(handler)\n        # restore main ones\n        for handler in self._log_handler_backup:\n            add_log_handler(handler)\n\n    def _internal_modules(self):\n        for modname in module_loader.preloaded(type=\"internal\"):\n            if self.config.get(modname, True):\n                yield modname\n\n    def _fail_setup(self, msg):\n        msg = str(msg)\n        if not self.force_start:\n            msg += \" (--force to run module anyway)\"\n        if self.force_start:\n            self.error(msg)\n        else:\n            raise ScanError(msg)\n\n    @property\n    def _loop(self):\n        if self.__loop is None:\n            self.__loop = asyncio.get_event_loop()\n        return self.__loop\n\n    def _load_modules(self, modules):\n        modules = [str(m) for m in modules]\n        loaded_modules = {}\n        failed = set()\n        for module_name, module_class in module_loader.load_modules(modules).items():\n            if module_class:\n                try:\n                    loaded_modules[module_name] = module_class(self)\n                    self.verbose(f'Loaded module \"{module_name}\"')\n                    continue\n                except Exception:\n                    self.warning(f\"Failed to load module {module_class}\")\n            else:\n                self.warning(f'Failed to load unknown module \"{module_name}\"')\n            failed.add(module_name)\n        return loaded_modules, failed\n\n    async def _status_ticker(self, interval=15):\n        async with self._acatch():\n            while 1:\n                await asyncio.sleep(interval)\n                self.manager.modules_status(_log=True)\n\n    @contextlib.asynccontextmanager\n    async def _acatch(self, context=\"scan\", finally_callback=None):\n\"\"\"\n        Async version of catch()\n\n        async with catch():\n            await do_stuff()\n        \"\"\"\n        try:\n            yield\n        except BaseException as e:\n            self._handle_exception(e, context=context)\n\n    def _handle_exception(self, e, context=\"scan\", finally_callback=None):\n        if callable(context):\n            context = f\"{context.__qualname__}()\"\n        filename, lineno, funcname = self.helpers.get_traceback_details(e)\n        exception_chain = self.helpers.get_exception_chain(e)\n        if any(isinstance(exc, KeyboardInterrupt) for exc in exception_chain):\n            log.debug(f\"Interrupted\")\n            self.stop()\n        elif isinstance(e, BrokenPipeError):\n            log.debug(f\"BrokenPipeError in {filename}:{lineno}:{funcname}(): {e}\")\n        elif isinstance(e, asyncio.CancelledError):\n            raise\n        elif isinstance(e, Exception):\n            log.error(f\"Error in {context}: {filename}:{lineno}:{funcname}(): {e}\")\n            log.trace(traceback.format_exc())\n        if callable(finally_callback):\n            finally_callback(e)\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.dns_regexes","title":"dns_regexes  <code>property</code>","text":"<pre><code>dns_regexes\n</code></pre> <p>A list of DNS hostname regexes generated from the scan target For the purpose of extracting hostnames</p> <p>Examples:</p> <p>Extract hostnames from text:</p> <pre><code>&gt;&gt;&gt; for regex in scan.dns_regexes:\n...     for match in regex.finditer(response.text):\n...         hostname = match.group().lower()\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.json","title":"json  <code>property</code>","text":"<pre><code>json\n</code></pre> <p>A dictionary representation of the scan including its name, ID, targets, whitelist, blacklist, and modules</p>"},{"location":"dev/scanner/#bbot.scanner.Scanner.log_level","title":"log_level  <code>property</code>","text":"<pre><code>log_level\n</code></pre> <p>Return the current log level, e.g. logging.INFO</p>"},{"location":"dev/scanner/#bbot.scanner.Scanner.root_event","title":"root_event  <code>property</code>","text":"<pre><code>root_event\n</code></pre> <p>The root scan event, e.g.:     <pre><code>{\n\"type\": \"SCAN\",\n\"id\": \"SCAN:1188928d942ace8e3befae0bdb9c3caa22705f54\",\n\"data\": \"pixilated_kathryn (SCAN:1188928d942ace8e3befae0bdb9c3caa22705f54)\",\n\"scope_distance\": 0,\n\"scan\": \"SCAN:1188928d942ace8e3befae0bdb9c3caa22705f54\",\n\"timestamp\": 1694548779.616255,\n\"source\": \"SCAN:1188928d942ace8e3befae0bdb9c3caa22705f54\",\n\"tags\": [\n\"distance-0\"\n],\n\"module\": \"TARGET\",\n\"module_sequence\": \"TARGET\"\n}\n</code></pre></p>"},{"location":"dev/scanner/#bbot.scanner.Scanner.useragent","title":"useragent  <code>property</code>","text":"<pre><code>useragent\n</code></pre> <p>Convenient shortcut to the HTTP user-agent configured for the scan</p>"},{"location":"dev/scanner/#bbot.scanner.Scanner.__init__","title":"__init__","text":"<pre><code>__init__(*targets, whitelist = None, blacklist = None, scan_id = None, name = None, modules = None, output_modules = None, output_dir = None, config = None, dispatcher = None, strict_scope = False, force_start = False)\n</code></pre> <p>Initializes the Scanner class.</p> <p>Parameters:</p> <ul> <li> <code>*targets</code>             (<code>str</code>, default:                 <code>()</code> )         \u2013          <p>Target(s) to scan.</p> </li> <li> <code>whitelist</code>             (<code>list</code>, default:                 <code>None</code> )         \u2013          <p>Whitelisted target(s) to scan. Defaults to the same as <code>targets</code>.</p> </li> <li> <code>blacklist</code>             (<code>list</code>, default:                 <code>None</code> )         \u2013          <p>Blacklisted target(s). Takes ultimate precedence. Defaults to empty.</p> </li> <li> <code>scan_id</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Unique identifier for the scan. Auto-generates if None.</p> </li> <li> <code>name</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Human-readable name of the scan. Auto-generates if None.</p> </li> <li> <code>modules</code>             (<code>list[str]</code>, default:                 <code>None</code> )         \u2013          <p>List of module names to use during the scan. Defaults to empty list.</p> </li> <li> <code>output_modules</code>             (<code>list[str]</code>, default:                 <code>None</code> )         \u2013          <p>List of output modules to use. Defaults to ['python'].</p> </li> <li> <code>output_dir</code>             (<code>str or Path</code>, default:                 <code>None</code> )         \u2013          <p>Directory to store scan output. Defaults to BBOT home directory (<code>~/.bbot</code>).</p> </li> <li> <code>config</code>             (<code>dict</code>, default:                 <code>None</code> )         \u2013          <p>Configuration settings. Merged with BBOT config.</p> </li> <li> <code>dispatcher</code>             (<code>Dispatcher</code>, default:                 <code>None</code> )         \u2013          <p>Dispatcher object to use. Defaults to new Dispatcher.</p> </li> <li> <code>strict_scope</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If True, only targets explicitly in whitelist are scanned. Defaults to False.</p> </li> <li> <code>force_start</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If True, allows the scan to start even when module setups hard-fail. Defaults to False.</p> </li> </ul> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>def __init__(\n    self,\n    *targets,\n    whitelist=None,\n    blacklist=None,\n    scan_id=None,\n    name=None,\n    modules=None,\n    output_modules=None,\n    output_dir=None,\n    config=None,\n    dispatcher=None,\n    strict_scope=False,\n    force_start=False,\n):\n\"\"\"\n    Initializes the Scanner class.\n\n    Args:\n        *targets (str): Target(s) to scan.\n        whitelist (list, optional): Whitelisted target(s) to scan. Defaults to the same as `targets`.\n        blacklist (list, optional): Blacklisted target(s). Takes ultimate precedence. Defaults to empty.\n        scan_id (str, optional): Unique identifier for the scan. Auto-generates if None.\n        name (str, optional): Human-readable name of the scan. Auto-generates if None.\n        modules (list[str], optional): List of module names to use during the scan. Defaults to empty list.\n        output_modules (list[str], optional): List of output modules to use. Defaults to ['python'].\n        output_dir (str or Path, optional): Directory to store scan output. Defaults to BBOT home directory (`~/.bbot`).\n        config (dict, optional): Configuration settings. Merged with BBOT config.\n        dispatcher (Dispatcher, optional): Dispatcher object to use. Defaults to new Dispatcher.\n        strict_scope (bool, optional): If True, only targets explicitly in whitelist are scanned. Defaults to False.\n        force_start (bool, optional): If True, allows the scan to start even when module setups hard-fail. Defaults to False.\n    \"\"\"\n    if modules is None:\n        modules = []\n    if output_modules is None:\n        output_modules = [\"python\"]\n\n    if isinstance(modules, str):\n        modules = [modules]\n    if isinstance(output_modules, str):\n        output_modules = [output_modules]\n\n    if config is None:\n        config = OmegaConf.create({})\n    else:\n        config = OmegaConf.create(config)\n    self.config = OmegaConf.merge(bbot_config, config)\n    prepare_environment(self.config)\n    if self.config.get(\"debug\", False):\n        set_log_level(logging.DEBUG)\n\n    self.strict_scope = strict_scope\n    self.force_start = force_start\n\n    if scan_id is not None:\n        self.id = str(scan_id)\n    else:\n        self.id = f\"SCAN:{sha1(rand_string(20)).hexdigest()}\"\n    self._status = \"NOT_STARTED\"\n    self._status_code = 0\n\n    self.max_workers = max(1, self.config.get(\"max_threads\", 25))\n    self.helpers = ConfigAwareHelper(config=self.config, scan=self)\n\n    if name is None:\n        tries = 0\n        while 1:\n            if tries &gt; 5:\n                self.name = f\"{self.helpers.rand_string(4)}_{self.helpers.rand_string(4)}\"\n                break\n            self.name = random_name()\n            if output_dir is not None:\n                home_path = Path(output_dir).resolve() / self.name\n            else:\n                home_path = self.helpers.bbot_home / \"scans\" / self.name\n            if not home_path.exists():\n                break\n            tries += 1\n    else:\n        self.name = str(name)\n\n    if output_dir is not None:\n        self.home = Path(output_dir).resolve() / self.name\n    else:\n        self.home = self.helpers.bbot_home / \"scans\" / self.name\n\n    self.target = Target(self, *targets, strict_scope=strict_scope, make_in_scope=True)\n\n    self.modules = OrderedDict({})\n    self._scan_modules = modules\n    self._internal_modules = list(self._internal_modules())\n    self._output_modules = output_modules\n    self._modules_loaded = False\n\n    if not whitelist:\n        self.whitelist = self.target.copy()\n    else:\n        self.whitelist = Target(self, *whitelist, strict_scope=strict_scope)\n    if not blacklist:\n        blacklist = []\n    self.blacklist = Target(self, *blacklist)\n\n    if dispatcher is None:\n        self.dispatcher = Dispatcher()\n    else:\n        self.dispatcher = dispatcher\n    self.dispatcher.set_scan(self)\n\n    self.manager = ScanManager(self)\n    self.stats = ScanStats(self)\n\n    # scope distance\n    self.scope_search_distance = max(0, int(self.config.get(\"scope_search_distance\", 0)))\n    self.scope_dns_search_distance = max(\n        self.scope_search_distance, int(self.config.get(\"scope_dns_search_distance\", 2))\n    )\n    self.scope_report_distance = int(self.config.get(\"scope_report_distance\", 1))\n\n    # custom HTTP headers warning\n    self.custom_http_headers = self.config.get(\"http_headers\", {})\n    if self.custom_http_headers:\n        self.warning(\n            \"You have enabled custom HTTP headers. These will be attached to all in-scope requests and all requests made by httpx.\"\n        )\n\n    # how often to print scan status\n    self.status_frequency = self.config.get(\"status_frequency\", 15)\n\n    self._prepped = False\n    self._finished_init = False\n    self._cleanedup = False\n\n    self.__loop = None\n    self._manager_worker_loop_tasks = []\n    self.init_events_task = None\n    self.ticker_task = None\n    self.dispatcher_tasks = []\n\n    # multiprocessing thread pool\n    try:\n        mp.set_start_method(\"spawn\")\n    except Exception:\n        self.warning(f\"Failed to set multiprocessing spawn method. This may negatively affect performance.\")\n    self.process_pool = ProcessPoolExecutor()\n\n    self._stopping = False\n\n    self._dns_regexes = None\n    self.__log_handlers = None\n    self._log_handler_backup = []\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.blacklisted","title":"blacklisted","text":"<pre><code>blacklisted(e)\n</code></pre> <p>Check whether a hostname, url, IP, etc. is blacklisted.</p> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>def blacklisted(self, e):\n\"\"\"\n    Check whether a hostname, url, IP, etc. is blacklisted.\n    \"\"\"\n    e = make_event(e, dummy=True)\n    return e in self.blacklist\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.finish","title":"finish  <code>async</code>","text":"<pre><code>finish()\n</code></pre> <p>Finalizes the scan by invoking the <code>finished()</code> method on all active modules if new activity is detected.</p> <p>The method is idempotent and will return False if no new activity has been recorded since the last invocation.</p> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if new activity has been detected and the <code>finished()</code> method is invoked on all modules.   False if no new activity has been detected since the last invocation.</p> </li> </ul> Notes <p>This method alters the scan's status to \"FINISHING\" if new activity is detected.</p> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>async def finish(self):\n\"\"\"Finalizes the scan by invoking the `finished()` method on all active modules if new activity is detected.\n\n    The method is idempotent and will return False if no new activity has been recorded since the last invocation.\n\n    Returns:\n        bool: True if new activity has been detected and the `finished()` method is invoked on all modules.\n              False if no new activity has been detected since the last invocation.\n\n    Notes:\n        This method alters the scan's status to \"FINISHING\" if new activity is detected.\n    \"\"\"\n    # if new events were generated since last time we were here\n    if self.manager._new_activity:\n        self.manager._new_activity = False\n        self.status = \"FINISHING\"\n        # Trigger .finished() on every module and start over\n        log.info(\"Finishing scan\")\n        finished_event = self.make_event(\"FINISHED\", \"FINISHED\", dummy=True)\n        for module in self.modules.values():\n            await module.queue_event(finished_event)\n        self.verbose(\"Completed finish()\")\n        return True\n    # Return False if no new events were generated since last time\n    self.verbose(\"Completed final finish()\")\n    return False\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.in_scope","title":"in_scope","text":"<pre><code>in_scope(e)\n</code></pre> <p>Check whether a hostname, url, IP, etc. is in scope. Accepts either events or string data.</p> <p>Checks whitelist and blacklist. If <code>e</code> is an event and its scope distance is zero, it will be considered in-scope.</p> <p>Examples:</p> <p>Check if a URL is in scope:</p> <pre><code>&gt;&gt;&gt; scan.in_scope(\"http://www.evilcorp.com\")\nTrue\n</code></pre> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>def in_scope(self, e):\n\"\"\"\n    Check whether a hostname, url, IP, etc. is in scope.\n    Accepts either events or string data.\n\n    Checks whitelist and blacklist.\n    If `e` is an event and its scope distance is zero, it will be considered in-scope.\n\n    Examples:\n        Check if a URL is in scope:\n        &gt;&gt;&gt; scan.in_scope(\"http://www.evilcorp.com\")\n        True\n    \"\"\"\n    try:\n        e = make_event(e, dummy=True)\n    except ValidationError:\n        return False\n    in_scope = e.scope_distance == 0 or self.whitelisted(e)\n    return in_scope and not self.blacklisted(e)\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.load_modules","title":"load_modules  <code>async</code>","text":"<pre><code>load_modules()\n</code></pre> <p>Asynchronously import and instantiate all scan modules, including internal and output modules.</p> <p>This method is automatically invoked by <code>setup_modules()</code>. It performs several key tasks in the following sequence:</p> <ol> <li>Install dependencies for each module via <code>self.helpers.depsinstaller.install()</code>.</li> <li>Load scan modules and updates the <code>modules</code> dictionary.</li> <li>Load internal modules and updates the <code>modules</code> dictionary.</li> <li>Load output modules and updates the <code>modules</code> dictionary.</li> <li>Sorts modules based on their <code>_priority</code> attribute.</li> </ol> <p>If any modules fail to load or their dependencies fail to install, a ScanError will be raised (unless <code>self.force_start</code> is set to True).</p> <p>Attributes:</p> <ul> <li> <code>succeeded,</code>             (<code>failed (tuple</code>)         \u2013          <p>A tuple containing lists of modules that succeeded or failed during the dependency installation.</p> </li> <li> <code>loaded_modules,</code>             (<code>loaded_internal_modules, loaded_output_modules (dict</code>)         \u2013          <p>Dictionaries of successfully loaded modules.</p> </li> <li> <code>failed,</code>             (<code>failed_internal, failed_output (list</code>)         \u2013          <p>Lists of module names that failed to load.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ScanError</code>           \u2013          <p>If any module dependencies fail to install or modules fail to load, and if self.force_start is False.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> Note <p>After all modules are loaded, they are sorted by <code>_priority</code> and stored in the <code>modules</code> dictionary.</p> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>async def load_modules(self):\n\"\"\"Asynchronously import and instantiate all scan modules, including internal and output modules.\n\n    This method is automatically invoked by `setup_modules()`. It performs several key tasks in the following sequence:\n\n    1. Install dependencies for each module via `self.helpers.depsinstaller.install()`.\n    2. Load scan modules and updates the `modules` dictionary.\n    3. Load internal modules and updates the `modules` dictionary.\n    4. Load output modules and updates the `modules` dictionary.\n    5. Sorts modules based on their `_priority` attribute.\n\n    If any modules fail to load or their dependencies fail to install, a ScanError will be raised (unless `self.force_start` is set to True).\n\n    Attributes:\n        succeeded, failed (tuple): A tuple containing lists of modules that succeeded or failed during the dependency installation.\n        loaded_modules, loaded_internal_modules, loaded_output_modules (dict): Dictionaries of successfully loaded modules.\n        failed, failed_internal, failed_output (list): Lists of module names that failed to load.\n\n    Raises:\n        ScanError: If any module dependencies fail to install or modules fail to load, and if self.force_start is False.\n\n    Returns:\n        None\n\n    Note:\n        After all modules are loaded, they are sorted by `_priority` and stored in the `modules` dictionary.\n    \"\"\"\n    if not self._modules_loaded:\n        all_modules = list(set(self._scan_modules + self._output_modules + self._internal_modules))\n        if not all_modules:\n            self.warning(f\"No modules to load\")\n            return\n\n        if not self._scan_modules:\n            self.warning(f\"No scan modules to load\")\n\n        # install module dependencies\n        succeeded, failed = await self.helpers.depsinstaller.install(\n            *self._scan_modules, *self._output_modules, *self._internal_modules\n        )\n        if failed:\n            msg = f\"Failed to install dependencies for {len(failed):,} modules: {','.join(failed)}\"\n            self._fail_setup(msg)\n        modules = sorted([m for m in self._scan_modules if m in succeeded])\n        output_modules = sorted([m for m in self._output_modules if m in succeeded])\n        internal_modules = sorted([m for m in self._internal_modules if m in succeeded])\n\n        # Load scan modules\n        self.verbose(f\"Loading {len(modules):,} scan modules: {','.join(modules)}\")\n        loaded_modules, failed = self._load_modules(modules)\n        self.modules.update(loaded_modules)\n        if len(failed) &gt; 0:\n            msg = f\"Failed to load {len(failed):,} scan modules: {','.join(failed)}\"\n            self._fail_setup(msg)\n        if loaded_modules:\n            self.info(\n                f\"Loaded {len(loaded_modules):,}/{len(self._scan_modules):,} scan modules ({','.join(loaded_modules)})\"\n            )\n\n        # Load internal modules\n        self.verbose(f\"Loading {len(internal_modules):,} internal modules: {','.join(internal_modules)}\")\n        loaded_internal_modules, failed_internal = self._load_modules(internal_modules)\n        self.modules.update(loaded_internal_modules)\n        if len(failed_internal) &gt; 0:\n            msg = f\"Failed to load {len(loaded_internal_modules):,} internal modules: {','.join(loaded_internal_modules)}\"\n            self._fail_setup(msg)\n        if loaded_internal_modules:\n            self.info(\n                f\"Loaded {len(loaded_internal_modules):,}/{len(self._internal_modules):,} internal modules ({','.join(loaded_internal_modules)})\"\n            )\n\n        # Load output modules\n        self.verbose(f\"Loading {len(output_modules):,} output modules: {','.join(output_modules)}\")\n        loaded_output_modules, failed_output = self._load_modules(output_modules)\n        self.modules.update(loaded_output_modules)\n        if len(failed_output) &gt; 0:\n            msg = f\"Failed to load {len(failed_output):,} output modules: {','.join(failed_output)}\"\n            self._fail_setup(msg)\n        if loaded_output_modules:\n            self.info(\n                f\"Loaded {len(loaded_output_modules):,}/{len(self._output_modules):,} output modules, ({','.join(loaded_output_modules)})\"\n            )\n\n        self.modules = OrderedDict(sorted(self.modules.items(), key=lambda x: getattr(x[-1], \"_priority\", 0)))\n        self._modules_loaded = True\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.run_in_executor","title":"run_in_executor","text":"<pre><code>run_in_executor(callback, *args, **kwargs)\n</code></pre> <p>Run a synchronous task in the event loop's default thread pool executor</p> <p>Examples:</p> <p>Execute callback:</p> <pre><code>&gt;&gt;&gt; result = await self.scan.run_in_executor(callback_fn, arg1, arg2)\n</code></pre> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>def run_in_executor(self, callback, *args, **kwargs):\n\"\"\"\n    Run a synchronous task in the event loop's default thread pool executor\n\n    Examples:\n        Execute callback:\n        &gt;&gt;&gt; result = await self.scan.run_in_executor(callback_fn, arg1, arg2)\n    \"\"\"\n    callback = partial(callback, **kwargs)\n    return self._loop.run_in_executor(None, callback, *args)\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.run_in_executor_mp","title":"run_in_executor_mp","text":"<pre><code>run_in_executor_mp(callback, *args, **kwargs)\n</code></pre> <p>Same as run_in_executor() except with a process pool executor Use only in cases where callback is CPU-bound</p> <p>Examples:</p> <p>Execute callback:</p> <pre><code>&gt;&gt;&gt; result = await self.scan.run_in_executor_mp(callback_fn, arg1, arg2)\n</code></pre> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>def run_in_executor_mp(self, callback, *args, **kwargs):\n\"\"\"\n    Same as run_in_executor() except with a process pool executor\n    Use only in cases where callback is CPU-bound\n\n    Examples:\n        Execute callback:\n        &gt;&gt;&gt; result = await self.scan.run_in_executor_mp(callback_fn, arg1, arg2)\n    \"\"\"\n    callback = partial(callback, **kwargs)\n    return self._loop.run_in_executor(self.process_pool, callback, *args)\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.setup_modules","title":"setup_modules  <code>async</code>","text":"<pre><code>setup_modules(remove_failed = True)\n</code></pre> <p>Asynchronously initializes all loaded modules by invoking their <code>setup()</code> methods.</p> <p>Parameters:</p> <ul> <li> <code>remove_failed</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Flag indicating whether to remove modules that fail setup.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>        \u2013          <p>Dictionary containing lists of module names categorized by their setup status.   'succeeded' - List of modules that successfully set up.   'hard_failed' - List of modules that encountered a hard failure during setup.   'soft_failed' - List of modules that encountered a soft failure during setup.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ScanError</code>           \u2013          <p>If no output modules could be loaded.</p> </li> </ul> Notes <p>Hard-failed modules are set to an error state and removed if <code>remove_failed</code> is True. Soft-failed modules are not set to an error state but are also removed if <code>remove_failed</code> is True.</p> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>async def setup_modules(self, remove_failed=True):\n\"\"\"Asynchronously initializes all loaded modules by invoking their `setup()` methods.\n\n    Args:\n        remove_failed (bool): Flag indicating whether to remove modules that fail setup.\n\n    Returns:\n        dict: Dictionary containing lists of module names categorized by their setup status.\n              'succeeded' - List of modules that successfully set up.\n              'hard_failed' - List of modules that encountered a hard failure during setup.\n              'soft_failed' - List of modules that encountered a soft failure during setup.\n\n    Raises:\n        ScanError: If no output modules could be loaded.\n\n    Notes:\n        Hard-failed modules are set to an error state and removed if `remove_failed` is True.\n        Soft-failed modules are not set to an error state but are also removed if `remove_failed` is True.\n    \"\"\"\n    await self.load_modules()\n    self.verbose(f\"Setting up modules\")\n    succeeded = []\n    hard_failed = []\n    soft_failed = []\n\n    async for task in self.helpers.as_completed([m._setup() for m in self.modules.values()]):\n        module_name, status, msg = await task\n        if status == True:\n            self.debug(f\"Setup succeeded for {module_name} ({msg})\")\n            succeeded.append(module_name)\n        elif status == False:\n            self.error(f\"Setup hard-failed for {module_name}: {msg}\")\n            self.modules[module_name].set_error_state()\n            hard_failed.append(module_name)\n        else:\n            self.warning(f\"Setup soft-failed for {module_name}: {msg}\")\n            soft_failed.append(module_name)\n        if not status and remove_failed:\n            self.modules.pop(module_name)\n\n    num_output_modules = len([m for m in self.modules.values() if m._type == \"output\"])\n    if num_output_modules &lt; 1:\n        raise ScanError(\"Failed to load output modules. Aborting.\")\n    total_failed = len(hard_failed + soft_failed)\n    if hard_failed:\n        msg = f\"Setup hard-failed for {len(hard_failed):,} modules ({','.join(hard_failed)})\"\n        self._fail_setup(msg)\n    elif total_failed &gt; 0:\n        self.warning(f\"Setup failed for {total_failed:,} modules\")\n\n    return {\n        \"succeeded\": succeeded,\n        \"hard_failed\": hard_failed,\n        \"soft_failed\": soft_failed,\n    }\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.stop","title":"stop","text":"<pre><code>stop()\n</code></pre> <p>Stops the in-progress scan and performs necessary cleanup.</p> <p>This method sets the scan's status to \"ABORTING,\" cancels any pending tasks, and drains event queues. It also kills child processes spawned during the scan.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>def stop(self):\n\"\"\"Stops the in-progress scan and performs necessary cleanup.\n\n    This method sets the scan's status to \"ABORTING,\" cancels any pending tasks, and drains event queues. It also kills child processes spawned during the scan.\n\n    Returns:\n        None\n    \"\"\"\n    if not self._stopping:\n        self._stopping = True\n        self.status = \"ABORTING\"\n        self.hugewarning(f\"Aborting scan\")\n        self.trace()\n        self._cancel_tasks()\n        self._drain_queues()\n        self.helpers.kill_children()\n        self._drain_queues()\n        self.helpers.kill_children()\n</code></pre>"},{"location":"dev/scanner/#bbot.scanner.Scanner.whitelisted","title":"whitelisted","text":"<pre><code>whitelisted(e)\n</code></pre> <p>Check whether a hostname, url, IP, etc. is whitelisted.</p> Source code in <code>bbot/scanner/scanner.py</code> <pre><code>def whitelisted(self, e):\n\"\"\"\n    Check whether a hostname, url, IP, etc. is whitelisted.\n    \"\"\"\n    e = make_event(e, dummy=True)\n    return e in self.whitelist\n</code></pre>"},{"location":"dev/target/","title":"Target","text":""},{"location":"dev/target/#bbot.scanner.target.Target","title":"Target","text":"<p>A class representing a target. Can contain an unlimited number of hosts, IP or IP ranges, URLs, etc.</p> <p>Attributes:</p> <ul> <li> <code>make_in_scope</code>             (<code>bool</code>)         \u2013          <p>Specifies whether to mark contained events as in-scope.</p> </li> <li> <code>scan</code>             (<code>Scan</code>)         \u2013          <p>Reference to the Scan object that instantiated the Target.</p> </li> <li> <code>_events</code>             (<code>dict</code>)         \u2013          <p>Dictionary mapping hosts to events related to the target.</p> </li> <li> <code>strict_scope</code>             (<code>bool</code>)         \u2013          <p>Flag indicating whether to consider child domains in-scope. If set to True, only the exact hosts specified and not their children are considered part of the target.</p> </li> </ul> <p>Examples:</p> <p>Basic usage</p> <pre><code>&gt;&gt;&gt; target = Target(scan, \"evilcorp.com\", \"1.2.3.0/24\")\n&gt;&gt;&gt; len(target)\n257\n&gt;&gt;&gt; list(t.events)\n[\n    DNS_NAME(\"evilcorp.com\", module=TARGET, tags={'domain', 'distance-1', 'target'}),\n    IP_RANGE(\"1.2.3.0/24\", module=TARGET, tags={'ipv4', 'distance-1', 'target'})\n]\n&gt;&gt;&gt; \"www.evilcorp.com\" in target\nTrue\n&gt;&gt;&gt; \"1.2.3.4\" in target\nTrue\n&gt;&gt;&gt; \"4.3.2.1\" in target\nFalse\n&gt;&gt;&gt; \"https://admin.evilcorp.com\" in target\nTrue\n&gt;&gt;&gt; \"bob@evilcorp.com\" in target\nTrue\n</code></pre> <p>Event correlation</p> <pre><code>&gt;&gt;&gt; target.get(\"www.evilcorp.com\")\nDNS_NAME(\"evilcorp.com\", module=TARGET, tags={'domain', 'distance-1', 'target'})\n&gt;&gt;&gt; target.get(\"1.2.3.4\")\nIP_RANGE(\"1.2.3.0/24\", module=TARGET, tags={'ipv4', 'distance-1', 'target'})\n</code></pre> <p>Target comparison</p> <pre><code>&gt;&gt;&gt; target2 = Targets(scan, \"www.evilcorp.com\")\n&gt;&gt;&gt; target2 == target\nFalse\n&gt;&gt;&gt; target2 in target\nTrue\n&gt;&gt;&gt; target in target2\nFalse\n</code></pre> Notes <ul> <li>Targets are only precise down to the individual host. Ports and protocols are not considered in scope calculations.</li> <li>If you specify \"https://evilcorp.com:8443\" as a target, all of evilcorp.com (including subdomains and other ports and protocols) will be considered part of the target</li> <li>If you do not want to include child subdomains, use <code>strict_scope=True</code></li> </ul> Source code in <code>bbot/scanner/target.py</code> <pre><code>class Target:\n\"\"\"\n    A class representing a target. Can contain an unlimited number of hosts, IP or IP ranges, URLs, etc.\n\n    Attributes:\n        make_in_scope (bool): Specifies whether to mark contained events as in-scope.\n        scan (Scan): Reference to the Scan object that instantiated the Target.\n        _events (dict): Dictionary mapping hosts to events related to the target.\n        strict_scope (bool): Flag indicating whether to consider child domains in-scope.\n            If set to True, only the exact hosts specified and not their children are considered part of the target.\n\n    Examples:\n        Basic usage\n        &gt;&gt;&gt; target = Target(scan, \"evilcorp.com\", \"1.2.3.0/24\")\n        &gt;&gt;&gt; len(target)\n        257\n        &gt;&gt;&gt; list(t.events)\n        [\n            DNS_NAME(\"evilcorp.com\", module=TARGET, tags={'domain', 'distance-1', 'target'}),\n            IP_RANGE(\"1.2.3.0/24\", module=TARGET, tags={'ipv4', 'distance-1', 'target'})\n        ]\n        &gt;&gt;&gt; \"www.evilcorp.com\" in target\n        True\n        &gt;&gt;&gt; \"1.2.3.4\" in target\n        True\n        &gt;&gt;&gt; \"4.3.2.1\" in target\n        False\n        &gt;&gt;&gt; \"https://admin.evilcorp.com\" in target\n        True\n        &gt;&gt;&gt; \"bob@evilcorp.com\" in target\n        True\n\n        Event correlation\n        &gt;&gt;&gt; target.get(\"www.evilcorp.com\")\n        DNS_NAME(\"evilcorp.com\", module=TARGET, tags={'domain', 'distance-1', 'target'})\n        &gt;&gt;&gt; target.get(\"1.2.3.4\")\n        IP_RANGE(\"1.2.3.0/24\", module=TARGET, tags={'ipv4', 'distance-1', 'target'})\n\n        Target comparison\n        &gt;&gt;&gt; target2 = Targets(scan, \"www.evilcorp.com\")\n        &gt;&gt;&gt; target2 == target\n        False\n        &gt;&gt;&gt; target2 in target\n        True\n        &gt;&gt;&gt; target in target2\n        False\n\n    Notes:\n        - Targets are only precise down to the individual host. Ports and protocols are not considered in scope calculations.\n        - If you specify \"https://evilcorp.com:8443\" as a target, all of evilcorp.com (including subdomains and other ports and protocols) will be considered part of the target\n        - If you do not want to include child subdomains, use `strict_scope=True`\n    \"\"\"\n\n    def __init__(self, scan, *targets, strict_scope=False, make_in_scope=False):\n\"\"\"\n        Initialize a Target object.\n\n        Args:\n            scan (Scan): Reference to the Scan object that instantiated the Target.\n            *targets: One or more targets (e.g., domain names, IP ranges) to be included in this Target.\n            strict_scope (bool, optional): Flag to control whether only the exact hosts are considered in-scope.\n                                           Defaults to False.\n            make_in_scope (bool, optional): Flag to control whether contained events are marked as in-scope.\n                                            Defaults to False.\n\n        Attributes:\n            scan (Scan): Reference to the Scan object.\n            strict_scope (bool): Flag to control in-scope conditions. If True, only exact hosts are considered.\n\n        Notes:\n            - If you are instantiating a target from within a BBOT module, use `self.helpers.make_target()` instead. (this removes the need to pass in a scan object.)\n            - The strict_scope flag can be set to restrict scope calculation to only exactly-matching hosts and not their child subdomains.\n            - Each target is processed and stored as an `Event` in the '_events' dictionary.\n        \"\"\"\n        self.scan = scan\n        self.strict_scope = strict_scope\n        self.make_in_scope = make_in_scope\n\n        self._dummy_module = TargetDummyModule(scan)\n        self._events = dict()\n        if len(targets) &gt; 0:\n            log.verbose(f\"Creating events from {len(targets):,} targets\")\n        for t in targets:\n            self.add_target(t)\n\n        self._hash = None\n\n    def add_target(self, t):\n\"\"\"\n        Add a target or merge events from another Target object into this Target.\n\n        Args:\n            t: The target to be added. It can be either a string, an event object, or another Target object.\n\n        Attributes Modified:\n            _events (dict): The dictionary is updated to include the new target's events.\n\n        Examples:\n            &gt;&gt;&gt; target.add_target('example.com')\n\n        Notes:\n            - If `t` is of the same class as this Target, all its events are merged.\n            - If `t` is an event, it is directly added to `_events`.\n            - If `make_in_scope` is True, the scope distance of the event is set to 0.\n        \"\"\"\n        if type(t) == self.__class__:\n            for k, v in t._events.items():\n                try:\n                    self._events[k].update(v)\n                except KeyError:\n                    self._events[k] = set(t._events[k])\n        else:\n            if is_event(t):\n                event = t\n            else:\n                event = self.scan.make_event(\n                    t, source=self.scan.root_event, module=self._dummy_module, tags=[\"target\"]\n                )\n            if self.make_in_scope:\n                event.scope_distance = 0\n            try:\n                self._events[event.host].add(event)\n            except KeyError:\n                self._events[event.host] = {\n                    event,\n                }\n\n    @property\n    def events(self):\n\"\"\"\n        A generator property that yields all events in the target.\n\n        Yields:\n            Event object: One of the Event objects stored in the `_events` dictionary.\n\n        Examples:\n            &gt;&gt;&gt; target = Target(scan, \"example.com\")\n            &gt;&gt;&gt; for event in target.events:\n            ...     print(event)\n\n        Notes:\n            - This property is read-only.\n            - Iterating over this property gives you one event at a time from the `_events` dictionary.\n        \"\"\"\n        for _events in self._events.values():\n            yield from _events\n\n    def copy(self):\n\"\"\"\n        Creates and returns a copy of the Target object, including a shallow copy of the `_events` attribute.\n\n        Returns:\n            Target: A new Target object with the same `scan` and `strict_scope` attributes as the original.\n                    A shallow copy of the `_events` dictionary is made.\n\n        Examples:\n            &gt;&gt;&gt; original_target = Target(scan, \"example.com\")\n            &gt;&gt;&gt; copied_target = original_target.copy()\n            &gt;&gt;&gt; copied_target is original_target\n            False\n            &gt;&gt;&gt; copied_target == original_target\n            True\n            &gt;&gt;&gt; copied_target in original_target\n            True\n            &gt;&gt;&gt; original_target in copied_target\n            True\n\n        Notes:\n            - The `scan` object reference is kept intact in the copied Target object.\n        \"\"\"\n        self_copy = self.__class__(self.scan, strict_scope=self.strict_scope)\n        self_copy._events = dict(self._events)\n        return self_copy\n\n    def get(self, host):\n\"\"\"\n        Gets the event associated with the specified host from the target's `_events` dictionary.\n\n        Args:\n            host (Event, Target, or str): The hostname, IP, URL, or event to look for.\n\n        Returns:\n            Event or None: Returns the Event object associated with the given host if it exists, otherwise returns None.\n\n        Examples:\n            &gt;&gt;&gt; target = Target(scan, \"evilcorp.com\", \"1.2.3.0/24\")\n            &gt;&gt;&gt; target.get(\"www.evilcorp.com\")\n            DNS_NAME(\"evilcorp.com\", module=TARGET, tags={'domain', 'distance-1', 'target'})\n            &gt;&gt;&gt; target.get(\"1.2.3.4\")\n            IP_RANGE(\"1.2.3.0/24\", module=TARGET, tags={'ipv4', 'distance-1', 'target'})\n\n        Notes:\n            - The method returns the first event that matches the given host.\n            - If `strict_scope` is False, it will also consider parent domains and IP ranges.\n        \"\"\"\n\n        try:\n            other = make_event(host, dummy=True)\n        except ValidationError:\n            return\n        if other.host:\n            with suppress(KeyError, StopIteration):\n                return next(iter(self._events[other.host]))\n            if self.scan.helpers.is_ip_type(other.host):\n                for n in self.scan.helpers.ip_network_parents(other.host, include_self=True):\n                    with suppress(KeyError, StopIteration):\n                        return next(iter(self._events[n]))\n            elif not self.strict_scope:\n                for h in self.scan.helpers.domain_parents(other.host):\n                    with suppress(KeyError, StopIteration):\n                        return next(iter(self._events[h]))\n\n    def _contains(self, other):\n        if self.get(other) is not None:\n            return True\n        return False\n\n    def __str__(self):\n        return \",\".join([str(e.data) for e in self.events][:5])\n\n    def __iter__(self):\n        yield from self.events\n\n    def __contains__(self, other):\n        # if \"other\" is a Target\n        if type(other) == self.__class__:\n            contained_in_self = [self._contains(e) for e in other.events]\n            return all(contained_in_self)\n        else:\n            return self._contains(other)\n\n    def __bool__(self):\n        return bool(self._events)\n\n    def __eq__(self, other):\n        return hash(self) == hash(other)\n\n    def __hash__(self):\n        if self._hash is None:\n            events = tuple(sorted(list(self.events), key=lambda e: hash(e)))\n            self._hash = hash(events)\n        return self._hash\n\n    def __len__(self):\n\"\"\"\n        Calculates and returns the total number of hosts within this target, not counting duplicate events.\n\n        Returns:\n            int: The total number of unique hosts present within the target's `_events`.\n\n        Examples:\n            &gt;&gt;&gt; target = Target(scan, \"evilcorp.com\", \"1.2.3.0/24\")\n            &gt;&gt;&gt; len(target)\n            257\n\n        Notes:\n            - If a host is represented as an IP network, all individual IP addresses in that network are counted.\n            - For other types of hosts, each unique event is counted as one.\n        \"\"\"\n        num_hosts = 0\n        for host, _events in self._events.items():\n            if type(host) in (ipaddress.IPv4Network, ipaddress.IPv6Network):\n                num_hosts += host.num_addresses\n            else:\n                num_hosts += len(_events)\n        return num_hosts\n</code></pre>"},{"location":"dev/target/#bbot.scanner.target.Target.events","title":"events  <code>property</code>","text":"<pre><code>events\n</code></pre> <p>A generator property that yields all events in the target.</p> <p>Yields:</p> <ul> <li>         \u2013          <p>Event object: One of the Event objects stored in the <code>_events</code> dictionary.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; target = Target(scan, \"example.com\")\n&gt;&gt;&gt; for event in target.events:\n...     print(event)\n</code></pre> Notes <ul> <li>This property is read-only.</li> <li>Iterating over this property gives you one event at a time from the <code>_events</code> dictionary.</li> </ul>"},{"location":"dev/target/#bbot.scanner.target.Target.__init__","title":"__init__","text":"<pre><code>__init__(scan, *targets, strict_scope = False, make_in_scope = False)\n</code></pre> <p>Initialize a Target object.</p> <p>Parameters:</p> <ul> <li> <code>scan</code>             (<code>Scan</code>)         \u2013          <p>Reference to the Scan object that instantiated the Target.</p> </li> <li> <code>*targets</code>         \u2013          <p>One or more targets (e.g., domain names, IP ranges) to be included in this Target.</p> </li> <li> <code>strict_scope</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Flag to control whether only the exact hosts are considered in-scope.                            Defaults to False.</p> </li> <li> <code>make_in_scope</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Flag to control whether contained events are marked as in-scope.                             Defaults to False.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>scan</code>             (<code>Scan</code>)         \u2013          <p>Reference to the Scan object.</p> </li> <li> <code>strict_scope</code>             (<code>bool</code>)         \u2013          <p>Flag to control in-scope conditions. If True, only exact hosts are considered.</p> </li> </ul> Notes <ul> <li>If you are instantiating a target from within a BBOT module, use <code>self.helpers.make_target()</code> instead. (this removes the need to pass in a scan object.)</li> <li>The strict_scope flag can be set to restrict scope calculation to only exactly-matching hosts and not their child subdomains.</li> <li>Each target is processed and stored as an <code>Event</code> in the '_events' dictionary.</li> </ul> Source code in <code>bbot/scanner/target.py</code> <pre><code>def __init__(self, scan, *targets, strict_scope=False, make_in_scope=False):\n\"\"\"\n    Initialize a Target object.\n\n    Args:\n        scan (Scan): Reference to the Scan object that instantiated the Target.\n        *targets: One or more targets (e.g., domain names, IP ranges) to be included in this Target.\n        strict_scope (bool, optional): Flag to control whether only the exact hosts are considered in-scope.\n                                       Defaults to False.\n        make_in_scope (bool, optional): Flag to control whether contained events are marked as in-scope.\n                                        Defaults to False.\n\n    Attributes:\n        scan (Scan): Reference to the Scan object.\n        strict_scope (bool): Flag to control in-scope conditions. If True, only exact hosts are considered.\n\n    Notes:\n        - If you are instantiating a target from within a BBOT module, use `self.helpers.make_target()` instead. (this removes the need to pass in a scan object.)\n        - The strict_scope flag can be set to restrict scope calculation to only exactly-matching hosts and not their child subdomains.\n        - Each target is processed and stored as an `Event` in the '_events' dictionary.\n    \"\"\"\n    self.scan = scan\n    self.strict_scope = strict_scope\n    self.make_in_scope = make_in_scope\n\n    self._dummy_module = TargetDummyModule(scan)\n    self._events = dict()\n    if len(targets) &gt; 0:\n        log.verbose(f\"Creating events from {len(targets):,} targets\")\n    for t in targets:\n        self.add_target(t)\n\n    self._hash = None\n</code></pre>"},{"location":"dev/target/#bbot.scanner.target.Target.add_target","title":"add_target","text":"<pre><code>add_target(t)\n</code></pre> <p>Add a target or merge events from another Target object into this Target.</p> <p>Parameters:</p> <ul> <li> <code>t</code>         \u2013          <p>The target to be added. It can be either a string, an event object, or another Target object.</p> </li> </ul> Attributes Modified <p>_events (dict): The dictionary is updated to include the new target's events.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; target.add_target('example.com')\n</code></pre> Notes <ul> <li>If <code>t</code> is of the same class as this Target, all its events are merged.</li> <li>If <code>t</code> is an event, it is directly added to <code>_events</code>.</li> <li>If <code>make_in_scope</code> is True, the scope distance of the event is set to 0.</li> </ul> Source code in <code>bbot/scanner/target.py</code> <pre><code>def add_target(self, t):\n\"\"\"\n    Add a target or merge events from another Target object into this Target.\n\n    Args:\n        t: The target to be added. It can be either a string, an event object, or another Target object.\n\n    Attributes Modified:\n        _events (dict): The dictionary is updated to include the new target's events.\n\n    Examples:\n        &gt;&gt;&gt; target.add_target('example.com')\n\n    Notes:\n        - If `t` is of the same class as this Target, all its events are merged.\n        - If `t` is an event, it is directly added to `_events`.\n        - If `make_in_scope` is True, the scope distance of the event is set to 0.\n    \"\"\"\n    if type(t) == self.__class__:\n        for k, v in t._events.items():\n            try:\n                self._events[k].update(v)\n            except KeyError:\n                self._events[k] = set(t._events[k])\n    else:\n        if is_event(t):\n            event = t\n        else:\n            event = self.scan.make_event(\n                t, source=self.scan.root_event, module=self._dummy_module, tags=[\"target\"]\n            )\n        if self.make_in_scope:\n            event.scope_distance = 0\n        try:\n            self._events[event.host].add(event)\n        except KeyError:\n            self._events[event.host] = {\n                event,\n            }\n</code></pre>"},{"location":"dev/target/#bbot.scanner.target.Target.copy","title":"copy","text":"<pre><code>copy()\n</code></pre> <p>Creates and returns a copy of the Target object, including a shallow copy of the <code>_events</code> attribute.</p> <p>Returns:</p> <ul> <li> <code>Target</code>        \u2013          <p>A new Target object with the same <code>scan</code> and <code>strict_scope</code> attributes as the original.     A shallow copy of the <code>_events</code> dictionary is made.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; original_target = Target(scan, \"example.com\")\n&gt;&gt;&gt; copied_target = original_target.copy()\n&gt;&gt;&gt; copied_target is original_target\nFalse\n&gt;&gt;&gt; copied_target == original_target\nTrue\n&gt;&gt;&gt; copied_target in original_target\nTrue\n&gt;&gt;&gt; original_target in copied_target\nTrue\n</code></pre> Notes <ul> <li>The <code>scan</code> object reference is kept intact in the copied Target object.</li> </ul> Source code in <code>bbot/scanner/target.py</code> <pre><code>def copy(self):\n\"\"\"\n    Creates and returns a copy of the Target object, including a shallow copy of the `_events` attribute.\n\n    Returns:\n        Target: A new Target object with the same `scan` and `strict_scope` attributes as the original.\n                A shallow copy of the `_events` dictionary is made.\n\n    Examples:\n        &gt;&gt;&gt; original_target = Target(scan, \"example.com\")\n        &gt;&gt;&gt; copied_target = original_target.copy()\n        &gt;&gt;&gt; copied_target is original_target\n        False\n        &gt;&gt;&gt; copied_target == original_target\n        True\n        &gt;&gt;&gt; copied_target in original_target\n        True\n        &gt;&gt;&gt; original_target in copied_target\n        True\n\n    Notes:\n        - The `scan` object reference is kept intact in the copied Target object.\n    \"\"\"\n    self_copy = self.__class__(self.scan, strict_scope=self.strict_scope)\n    self_copy._events = dict(self._events)\n    return self_copy\n</code></pre>"},{"location":"dev/target/#bbot.scanner.target.Target.get","title":"get","text":"<pre><code>get(host)\n</code></pre> <p>Gets the event associated with the specified host from the target's <code>_events</code> dictionary.</p> <p>Parameters:</p> <ul> <li> <code>host</code>             (<code>Event, Target, or str</code>)         \u2013          <p>The hostname, IP, URL, or event to look for.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>Event or None: Returns the Event object associated with the given host if it exists, otherwise returns None.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; target = Target(scan, \"evilcorp.com\", \"1.2.3.0/24\")\n&gt;&gt;&gt; target.get(\"www.evilcorp.com\")\nDNS_NAME(\"evilcorp.com\", module=TARGET, tags={'domain', 'distance-1', 'target'})\n&gt;&gt;&gt; target.get(\"1.2.3.4\")\nIP_RANGE(\"1.2.3.0/24\", module=TARGET, tags={'ipv4', 'distance-1', 'target'})\n</code></pre> Notes <ul> <li>The method returns the first event that matches the given host.</li> <li>If <code>strict_scope</code> is False, it will also consider parent domains and IP ranges.</li> </ul> Source code in <code>bbot/scanner/target.py</code> <pre><code>def get(self, host):\n\"\"\"\n    Gets the event associated with the specified host from the target's `_events` dictionary.\n\n    Args:\n        host (Event, Target, or str): The hostname, IP, URL, or event to look for.\n\n    Returns:\n        Event or None: Returns the Event object associated with the given host if it exists, otherwise returns None.\n\n    Examples:\n        &gt;&gt;&gt; target = Target(scan, \"evilcorp.com\", \"1.2.3.0/24\")\n        &gt;&gt;&gt; target.get(\"www.evilcorp.com\")\n        DNS_NAME(\"evilcorp.com\", module=TARGET, tags={'domain', 'distance-1', 'target'})\n        &gt;&gt;&gt; target.get(\"1.2.3.4\")\n        IP_RANGE(\"1.2.3.0/24\", module=TARGET, tags={'ipv4', 'distance-1', 'target'})\n\n    Notes:\n        - The method returns the first event that matches the given host.\n        - If `strict_scope` is False, it will also consider parent domains and IP ranges.\n    \"\"\"\n\n    try:\n        other = make_event(host, dummy=True)\n    except ValidationError:\n        return\n    if other.host:\n        with suppress(KeyError, StopIteration):\n            return next(iter(self._events[other.host]))\n        if self.scan.helpers.is_ip_type(other.host):\n            for n in self.scan.helpers.ip_network_parents(other.host, include_self=True):\n                with suppress(KeyError, StopIteration):\n                    return next(iter(self._events[n]))\n        elif not self.strict_scope:\n            for h in self.scan.helpers.domain_parents(other.host):\n                with suppress(KeyError, StopIteration):\n                    return next(iter(self._events[h]))\n</code></pre>"},{"location":"dev/helpers/","title":"BBOT Helpers","text":"<p>In this section are various helper functions that are designed to make your life easier when devving on BBOT. Whether you're extending BBOT by writing a module or working on its core engine, these functions are designed to act as useful machine parts to perform essential tasks, such as making a web request or executing a DNS query.</p> <p>The vast majority of these helpers can be accessed directly from the <code>.helpers</code> attribute of a scan or module, like so:</p> <pre><code>class MyModule(BaseModule):\n\n    ...\n\n    async def handle_event(self, event):\n        # Web Request\n        response = await self.helpers.request(\"https://www.evilcorp.com\")\n\n        # DNS query\n        for ip in await self.helpers.resolve(\"www.evilcorp.com\"):\n            self.hugesuccess(str(ip))\n\n        # Execute shell command\n        completed_process = self.helpers.run(\"ls\", \"-l\")\n        self.hugesuccess(completed_process.stdout)\n\n        # Split a DNS name into subdomain / domain\n        self.helpers.split_domain(\"www.internal.evilcorp.co.uk\")\n        # (\"www.internal\", \"evilcorp.co.uk\")\n</code></pre> <p>Next Up: Command Helpers --&gt;</p>"},{"location":"dev/helpers/command/","title":"Command Helpers","text":"<p>These are helpers related to executing shell commands. They are used throughout BBOT and its modules for executing various binaries such as <code>nmap</code>, <code>nuclei</code>, etc.</p> <p>Note that these helpers can be invoked directly from <code>self.helpers</code>, e.g.:</p> <pre><code>self.helpers.run(\"ls\", \"-l\")\n</code></pre>"},{"location":"dev/helpers/command/#bbot.core.helpers.command.run","title":"run  <code>async</code>","text":"<pre><code>run(self, *command, check = False, text = True, **kwargs)\n</code></pre> <p>Runs a command asynchronously and gets its output as a string.</p> <pre><code>This method is a simple helper for executing a command and capturing its output.\nIf an error occurs during execution, it can optionally raise an error or just log the stderr.\n\nArgs:\n    *command (str): The command to run as separate arguments.\n    check (bool, optional): If set to True, raises an error if the subprocess exits with a non-zero status.\n                            Defaults to False.\n    text (bool, optional): If set to True, decodes the subprocess output to string. Defaults to True.\n    **kwargs (dict): Additional keyword arguments for the subprocess.\n\nReturns:\n    CompletedProcess: A completed process object with attributes for the command, return code, stdout, and stderr.\n\nRaises:\n    CalledProcessError: If the subprocess exits with a non-zero status and `check=True`.\n\nExamples:\n    &gt;&gt;&gt; process = await run([\"ls\", \"/tmp\"])\n    &gt;&gt;&gt; process.stdout\n    \"file1.txt\n</code></pre> <p>file2.txt\"</p> Source code in <code>bbot/core/helpers/command.py</code> <pre><code>async def run(self, *command, check=False, text=True, **kwargs):\n\"\"\"Runs a command asynchronously and gets its output as a string.\n\n    This method is a simple helper for executing a command and capturing its output.\n    If an error occurs during execution, it can optionally raise an error or just log the stderr.\n\n    Args:\n        *command (str): The command to run as separate arguments.\n        check (bool, optional): If set to True, raises an error if the subprocess exits with a non-zero status.\n                                Defaults to False.\n        text (bool, optional): If set to True, decodes the subprocess output to string. Defaults to True.\n        **kwargs (dict): Additional keyword arguments for the subprocess.\n\n    Returns:\n        CompletedProcess: A completed process object with attributes for the command, return code, stdout, and stderr.\n\n    Raises:\n        CalledProcessError: If the subprocess exits with a non-zero status and `check=True`.\n\n    Examples:\n        &gt;&gt;&gt; process = await run([\"ls\", \"/tmp\"])\n        &gt;&gt;&gt; process.stdout\n        \"file1.txt\\nfile2.txt\"\n    \"\"\"\n    proc, _input, command = await self._spawn_proc(*command, **kwargs)\n    if proc is not None:\n        if _input is not None:\n            if isinstance(_input, (list, tuple)):\n                _input = b\"\\n\".join(smart_encode(i) for i in _input) + b\"\\n\"\n            else:\n                _input = smart_encode(_input)\n        stdout, stderr = await proc.communicate(_input)\n\n        # surface stderr\n        if text:\n            if stderr is not None:\n                stderr = smart_decode(stderr)\n            if stdout is not None:\n                stdout = smart_decode(stdout)\n        if proc.returncode:\n            if check:\n                raise CalledProcessError(proc.returncode, command, output=stdout, stderr=stderr)\n            if stderr:\n                command_str = \" \".join(command)\n                log.warning(f\"Stderr for run({command_str}):\\n\\t{stderr}\")\n\n        return CompletedProcess(command, proc.returncode, stdout, stderr)\n</code></pre>"},{"location":"dev/helpers/command/#bbot.core.helpers.command.run_live","title":"run_live  <code>async</code>","text":"<pre><code>run_live(self, *command, check = False, text = True, **kwargs)\n</code></pre> <p>Runs a command asynchronously and iterates through its output line by line in realtime.</p> <p>This method is useful for executing a command and capturing its output on-the-fly, as it is generated. If an error occurs during execution, it can optionally raise an error or just log the stderr.</p> <p>Parameters:</p> <ul> <li> <code>*command</code>             (<code>str</code>, default:                 <code>()</code> )         \u2013          <p>The command to run as separate arguments.</p> </li> <li> <code>check</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If set to True, raises an error if the subprocess exits with a non-zero status.                     Defaults to False.</p> </li> <li> <code>text</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If set to True, decodes the subprocess output to string. Defaults to True.</p> </li> <li> <code>**kwargs</code>             (<code>dict</code>, default:                 <code>{}</code> )         \u2013          <p>Additional keyword arguments for the subprocess.</p> </li> </ul> <p>Yields:</p> <ul> <li>         \u2013          <p>str or bytes: The output lines of the command, either as a decoded string (if <code>text=True</code>)           or as bytes (if <code>text=False</code>).</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>CalledProcessError</code>           \u2013          <p>If the subprocess exits with a non-zero status and <code>check=True</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; async for line in run_live([\"tail\", \"-f\", \"/var/log/auth.log\"]):\n...     log.info(line)\n</code></pre> Source code in <code>bbot/core/helpers/command.py</code> <pre><code>async def run_live(self, *command, check=False, text=True, **kwargs):\n\"\"\"Runs a command asynchronously and iterates through its output line by line in realtime.\n\n    This method is useful for executing a command and capturing its output on-the-fly, as it is generated.\n    If an error occurs during execution, it can optionally raise an error or just log the stderr.\n\n    Args:\n        *command (str): The command to run as separate arguments.\n        check (bool, optional): If set to True, raises an error if the subprocess exits with a non-zero status.\n                                Defaults to False.\n        text (bool, optional): If set to True, decodes the subprocess output to string. Defaults to True.\n        **kwargs (dict): Additional keyword arguments for the subprocess.\n\n    Yields:\n        str or bytes: The output lines of the command, either as a decoded string (if `text=True`)\n                      or as bytes (if `text=False`).\n\n    Raises:\n        CalledProcessError: If the subprocess exits with a non-zero status and `check=True`.\n\n    Examples:\n        &gt;&gt;&gt; async for line in run_live([\"tail\", \"-f\", \"/var/log/auth.log\"]):\n        ...     log.info(line)\n    \"\"\"\n    proc, _input, command = await self._spawn_proc(*command, **kwargs)\n    if proc is not None:\n        input_task = None\n        if _input is not None:\n            input_task = asyncio.create_task(_write_stdin(proc, _input))\n\n        while 1:\n            try:\n                line = await proc.stdout.readline()\n            except ValueError as e:\n                command_str = \" \".join([str(c) for c in command])\n                log.warning(f\"Error executing command {command_str}: {e}\")\n                log.trace(traceback.format_exc())\n                continue\n            if not line:\n                break\n            if text:\n                line = smart_decode(line).rstrip(\"\\r\\n\")\n            else:\n                line = line.rstrip(b\"\\r\\n\")\n            yield line\n\n        if input_task is not None:\n            try:\n                await input_task\n            except ConnectionError:\n                log.trace(f\"ConnectionError in command: {command}, kwargs={kwargs}\")\n                log.trace(traceback.format_exc())\n        await proc.wait()\n\n        if proc.returncode:\n            stdout, stderr = await proc.communicate()\n            if text:\n                if stderr is not None:\n                    stderr = smart_decode(stderr)\n                if stdout is not None:\n                    stdout = smart_decode(stdout)\n            if check:\n                raise CalledProcessError(proc.returncode, command, output=stdout, stderr=stderr)\n            # surface stderr\n            if stderr:\n                command_str = \" \".join(command)\n                log.warning(f\"Stderr for run_live({command_str}):\\n\\t{stderr}\")\n</code></pre>"},{"location":"dev/helpers/dns/","title":"DNS","text":"<p>These are helpers related to DNS resolution. They are used throughout BBOT and its modules for performing DNS lookups and detecting DNS wildcards, etc.</p> <p>Note that these helpers can be invoked directly from <code>self.helpers</code>, e.g.:</p> <pre><code>self.helpers.resolve(\"evilcorp.com\")\n</code></pre>"},{"location":"dev/helpers/dns/#bbot.core.helpers.dns.DNSHelper","title":"DNSHelper","text":"<p>Helper class for DNS-related operations within BBOT.</p> <p>This class provides mechanisms for host resolution, wildcard domain detection, event tagging, and more. It centralizes all DNS-related activities in BBOT, offering both synchronous and asynchronous methods for DNS resolution, as well as various utilities for batch resolution and DNS query filtering.</p> <p>Attributes:</p> <ul> <li> <code>parent_helper</code>         \u2013          <p>A reference to the instantiated <code>ConfigAwareHelper</code> (typically <code>scan.helpers</code>).</p> </li> <li> <code>resolver</code>             (<code>BBOTAsyncResolver</code>)         \u2013          <p>An asynchronous DNS resolver tailored for BBOT with rate-limiting capabilities.</p> </li> <li> <code>timeout</code>             (<code>int</code>)         \u2013          <p>The timeout value for DNS queries. Defaults to 5 seconds.</p> </li> <li> <code>retries</code>             (<code>int</code>)         \u2013          <p>The number of retries for failed DNS queries. Defaults to 1.</p> </li> <li> <code>abort_threshold</code>             (<code>int</code>)         \u2013          <p>The threshold for aborting after consecutive failed queries. Defaults to 50.</p> </li> <li> <code>max_dns_resolve_distance</code>             (<code>int</code>)         \u2013          <p>Maximum allowed distance for DNS resolution. Defaults to 4.</p> </li> <li> <code>all_rdtypes</code>             (<code>list</code>)         \u2013          <p>A list of DNS record types to be considered during operations.</p> </li> <li> <code>wildcard_ignore</code>             (<code>tuple</code>)         \u2013          <p>Domains to be ignored during wildcard detection.</p> </li> <li> <code>wildcard_tests</code>             (<code>int</code>)         \u2013          <p>Number of tests to be run for wildcard detection. Defaults to 5.</p> </li> <li> <code>_wildcard_cache</code>             (<code>dict</code>)         \u2013          <p>Cache for wildcard detection results.</p> </li> <li> <code>_dns_cache</code>             (<code>CacheDict</code>)         \u2013          <p>Cache for DNS resolution results, limited in size.</p> </li> <li> <code>_event_cache</code>             (<code>CacheDict</code>)         \u2013          <p>Cache for event resolution results, tags. Limited in size.</p> </li> <li> <code>resolver_file</code>             (<code>Path</code>)         \u2013          <p>File containing system's current resolver nameservers.</p> </li> <li> <code>filter_bad_ptrs</code>             (<code>bool</code>)         \u2013          <p>Whether to filter out DNS names that appear to be auto-generated PTR records. Defaults to True.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>parent_helper</code>         \u2013          <p>The parent helper object with configuration details and utilities.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>DNSError</code>           \u2013          <p>If an issue arises when creating the BBOTAsyncResolver instance.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dns_helper = DNSHelper(parent_config)\n&gt;&gt;&gt; resolved_host = dns_helper.resolver.resolve(\"example.com\")\n</code></pre> Source code in <code>bbot/core/helpers/dns.py</code> <pre><code>class DNSHelper:\n\"\"\"Helper class for DNS-related operations within BBOT.\n\n    This class provides mechanisms for host resolution, wildcard domain detection, event tagging, and more.\n    It centralizes all DNS-related activities in BBOT, offering both synchronous and asynchronous methods\n    for DNS resolution, as well as various utilities for batch resolution and DNS query filtering.\n\n    Attributes:\n        parent_helper: A reference to the instantiated `ConfigAwareHelper` (typically `scan.helpers`).\n        resolver (BBOTAsyncResolver): An asynchronous DNS resolver tailored for BBOT with rate-limiting capabilities.\n        timeout (int): The timeout value for DNS queries. Defaults to 5 seconds.\n        retries (int): The number of retries for failed DNS queries. Defaults to 1.\n        abort_threshold (int): The threshold for aborting after consecutive failed queries. Defaults to 50.\n        max_dns_resolve_distance (int): Maximum allowed distance for DNS resolution. Defaults to 4.\n        all_rdtypes (list): A list of DNS record types to be considered during operations.\n        wildcard_ignore (tuple): Domains to be ignored during wildcard detection.\n        wildcard_tests (int): Number of tests to be run for wildcard detection. Defaults to 5.\n        _wildcard_cache (dict): Cache for wildcard detection results.\n        _dns_cache (CacheDict): Cache for DNS resolution results, limited in size.\n        _event_cache (CacheDict): Cache for event resolution results, tags. Limited in size.\n        resolver_file (Path): File containing system's current resolver nameservers.\n        filter_bad_ptrs (bool): Whether to filter out DNS names that appear to be auto-generated PTR records. Defaults to True.\n\n    Args:\n        parent_helper: The parent helper object with configuration details and utilities.\n\n    Raises:\n        DNSError: If an issue arises when creating the BBOTAsyncResolver instance.\n\n    Examples:\n        &gt;&gt;&gt; dns_helper = DNSHelper(parent_config)\n        &gt;&gt;&gt; resolved_host = dns_helper.resolver.resolve(\"example.com\")\n    \"\"\"\n\n    all_rdtypes = [\"A\", \"AAAA\", \"SRV\", \"MX\", \"NS\", \"SOA\", \"CNAME\", \"TXT\"]\n\n    def __init__(self, parent_helper):\n        self.parent_helper = parent_helper\n        try:\n            self.resolver = BBOTAsyncResolver(_parent_helper=self.parent_helper)\n        except Exception as e:\n            raise DNSError(f\"Failed to create BBOT DNS resolver: {e}\")\n        self.timeout = self.parent_helper.config.get(\"dns_timeout\", 5)\n        self.retries = self.parent_helper.config.get(\"dns_retries\", 1)\n        self.abort_threshold = self.parent_helper.config.get(\"dns_abort_threshold\", 50)\n        self.max_dns_resolve_distance = self.parent_helper.config.get(\"max_dns_resolve_distance\", 5)\n        self.resolver.timeout = self.timeout\n        self.resolver.lifetime = self.timeout\n        self._resolver_list = None\n\n        # skip certain queries\n        dns_omit_queries = self.parent_helper.config.get(\"dns_omit_queries\", None)\n        if not dns_omit_queries:\n            dns_omit_queries = []\n        self.dns_omit_queries = dict()\n        for d in dns_omit_queries:\n            d = d.split(\":\")\n            if len(d) == 2:\n                rdtype, query = d\n                rdtype = rdtype.upper()\n                query = query.lower()\n                try:\n                    self.dns_omit_queries[rdtype].add(query)\n                except KeyError:\n                    self.dns_omit_queries[rdtype] = {query}\n\n        self.wildcard_ignore = self.parent_helper.config.get(\"dns_wildcard_ignore\", None)\n        if not self.wildcard_ignore:\n            self.wildcard_ignore = []\n        self.wildcard_ignore = tuple([str(d).strip().lower() for d in self.wildcard_ignore])\n        self.wildcard_tests = self.parent_helper.config.get(\"dns_wildcard_tests\", 5)\n        self._wildcard_cache = dict()\n        # since wildcard detection takes some time, This is to prevent multiple\n        # modules from kicking off wildcard detection for the same domain at the same time\n        self._wildcard_lock = NamedLock()\n        self._dns_connectivity_lock = asyncio.Lock()\n        self._last_dns_success = None\n        self._last_connectivity_warning = time.time()\n        # keeps track of warnings issued for wildcard detection to prevent duplicate warnings\n        self._dns_warnings = set()\n        self._errors = dict()\n        self.fallback_nameservers_file = self.parent_helper.wordlist_dir / \"nameservers.txt\"\n        self._debug = self.parent_helper.config.get(\"dns_debug\", False)\n        self._dummy_modules = dict()\n        self._dns_cache = self.parent_helper.CacheDict(max_size=100000)\n        self._event_cache = self.parent_helper.CacheDict(max_size=10000)\n        self._event_cache_locks = NamedLock()\n\n        # for mocking DNS queries\n        self._orig_resolve_raw = None\n        self._mock_table = {}\n\n        # copy the system's current resolvers to a text file for tool use\n        self.system_resolvers = dns.resolver.Resolver().nameservers\n        self.resolver_file = self.parent_helper.tempfile(self.system_resolvers, pipe=False)\n\n        self.filter_bad_ptrs = self.parent_helper.config.get(\"dns_filter_ptrs\", True)\n\n    async def resolve(self, query, **kwargs):\n\"\"\"Resolve DNS names and IP addresses to their corresponding results.\n\n        This is a high-level function that can translate a given domain name to its associated IP addresses\n        or an IP address to its corresponding domain names. It's structured for ease of use within modules\n        and will abstract away most of the complexity of DNS resolution, returning a simple set of results.\n\n        Args:\n            query (str): The domain name or IP address to resolve.\n            **kwargs: Additional arguments to be passed to the resolution process.\n\n        Returns:\n            set: A set containing resolved domain names or IP addresses.\n\n        Examples:\n            &gt;&gt;&gt; results = await resolve(\"1.2.3.4\")\n            {\"evilcorp.com\"}\n\n            &gt;&gt;&gt; results = await resolve(\"evilcorp.com\")\n            {\"1.2.3.4\", \"dead::beef\"}\n        \"\"\"\n        results = set()\n        try:\n            r = await self.resolve_raw(query, **kwargs)\n            if r:\n                raw_results, errors = r\n                for rdtype, answers in raw_results:\n                    for answer in answers:\n                        for _, t in self.extract_targets(answer):\n                            results.add(t)\n        except BaseException:\n            log.trace(f\"Caught exception in resolve({query}, {kwargs}):\")\n            log.trace(traceback.format_exc())\n            raise\n\n        self.debug(f\"Results for {query} with kwargs={kwargs}: {results}\")\n        return results\n\n    async def resolve_raw(self, query, **kwargs):\n\"\"\"Resolves the given query to its associated DNS records.\n\n        This function is a foundational method for DNS resolution in this class. It understands both IP addresses and\n        hostnames and returns their associated records in a raw format provided by the dnspython library.\n\n        Args:\n            query (str): The IP address or hostname to resolve.\n            type (str or list[str], optional): Specifies the DNS record type(s) to fetch. Can be a single type like 'A'\n                or a list like ['A', 'AAAA']. If set to 'any', 'all', or '*', it fetches all supported types. If not\n                specified, the function defaults to fetching 'A' and 'AAAA' records.\n            **kwargs: Additional arguments that might be passed to the resolver.\n\n        Returns:\n            tuple: A tuple containing two lists:\n                - list: A list of tuples where each tuple consists of a record type string (like 'A') and the associated\n                  raw dnspython answer.\n                - list: A list of tuples where each tuple consists of a record type string and the associated error if\n                  there was an issue fetching the record.\n\n        Examples:\n            &gt;&gt;&gt; await resolve_raw(\"8.8.8.8\")\n            ([('PTR', &lt;dns.resolver.Answer object at 0x7f4a47cdb1d0&gt;)], [])\n\n            &gt;&gt;&gt; await resolve_raw(\"dns.google\")\n            ([('A', &lt;dns.resolver.Answer object at 0x7f4a47ce46d0&gt;), ('AAAA', &lt;dns.resolver.Answer object at 0x7f4a47ce4710&gt;)], [])\n        \"\"\"\n        # DNS over TCP is more reliable\n        # But setting this breaks DNS resolution on Ubuntu because systemd-resolve doesn't support TCP\n        # kwargs[\"tcp\"] = True\n        results = []\n        errors = []\n        try:\n            query = str(query).strip()\n            if is_ip(query):\n                kwargs.pop(\"type\", None)\n                kwargs.pop(\"rdtype\", None)\n                results, errors = await self._resolve_ip(query, **kwargs)\n                return [(\"PTR\", results)], [(\"PTR\", e) for e in errors]\n            else:\n                types = [\"A\", \"AAAA\"]\n                kwargs.pop(\"rdtype\", None)\n                if \"type\" in kwargs:\n                    t = kwargs.pop(\"type\")\n                    types = self._parse_rdtype(t, default=types)\n                for t in types:\n                    r, e = await self._resolve_hostname(query, rdtype=t, **kwargs)\n                    if r:\n                        results.append((t, r))\n                    for error in e:\n                        errors.append((t, error))\n        except BaseException:\n            log.trace(f\"Caught exception in resolve_raw({query}, {kwargs}):\")\n            log.trace(traceback.format_exc())\n            raise\n\n        return (results, errors)\n\n    async def _resolve_hostname(self, query, **kwargs):\n\"\"\"Translate a hostname into its corresponding IP addresses.\n\n        This is the foundational function for converting a domain name into its associated IP addresses. It's designed\n        for internal use within the class and handles retries, caching, and a variety of error/timeout scenarios.\n        It also respects certain configurations that might ask to skip certain types of queries. Results are returned\n        in the default dnspython answer object format.\n\n        Args:\n            query (str): The hostname to resolve.\n            rdtype (str, optional): The type of DNS record to query (e.g., 'A', 'AAAA'). Defaults to 'A'.\n            retries (int, optional): The number of times to retry on failure. Defaults to class-wide `retries`.\n            use_cache (bool, optional): Whether to check the cache before trying a fresh resolution. Defaults to True.\n            **kwargs: Additional arguments that might be passed to the resolver.\n\n        Returns:\n            tuple: A tuple containing:\n                - list: A list of resolved IP addresses.\n                - list: A list of errors encountered during the resolution process.\n\n        Examples:\n            &gt;&gt;&gt; results, errors = await _resolve_hostname(\"google.com\")\n            (&lt;dns.resolver.Answer object at 0x7f4a4b2caf50&gt;, [])\n        \"\"\"\n        self.debug(f\"Resolving {query} with kwargs={kwargs}\")\n        results = []\n        errors = []\n        rdtype = kwargs.get(\"rdtype\", \"A\")\n\n        # skip certain queries if requested\n        if rdtype in self.dns_omit_queries:\n            if any(h == query or query.endswith(f\".{h}\") for h in self.dns_omit_queries[rdtype]):\n                self.debug(f\"Skipping {rdtype}:{query} because it's omitted in the config\")\n                return results, errors\n\n        parent = self.parent_helper.parent_domain(query)\n        retries = kwargs.pop(\"retries\", self.retries)\n        use_cache = kwargs.pop(\"use_cache\", True)\n        tries_left = int(retries) + 1\n        parent_hash = hash(f\"{parent}:{rdtype}\")\n        dns_cache_hash = hash(f\"{query}:{rdtype}\")\n        while tries_left &gt; 0:\n            try:\n                if use_cache:\n                    results = self._dns_cache.get(dns_cache_hash, [])\n                if not results:\n                    error_count = self._errors.get(parent_hash, 0)\n                    if error_count &gt;= self.abort_threshold:\n                        connectivity = await self._connectivity_check()\n                        if connectivity:\n                            log.verbose(\n                                f'Aborting query \"{query}\" because failed {rdtype} queries for \"{parent}\" ({error_count:,}) exceeded abort threshold ({self.abort_threshold:,})'\n                            )\n                            if parent_hash not in self._dns_warnings:\n                                log.verbose(\n                                    f'Aborting future {rdtype} queries to \"{parent}\" because error count ({error_count:,}) exceeded abort threshold ({self.abort_threshold:,})'\n                                )\n                            self._dns_warnings.add(parent_hash)\n                            return results, errors\n                    results = await self._catch(self.resolver.resolve, query, **kwargs)\n                    if use_cache:\n                        self._dns_cache[dns_cache_hash] = results\n                    if parent_hash in self._errors:\n                        self._errors[parent_hash] = 0\n                break\n            except (\n                dns.resolver.NoNameservers,\n                dns.exception.Timeout,\n                dns.resolver.LifetimeTimeout,\n                TimeoutError,\n            ) as e:\n                try:\n                    self._errors[parent_hash] += 1\n                except KeyError:\n                    self._errors[parent_hash] = 1\n                errors.append(e)\n                # don't retry if we get a SERVFAIL\n                if isinstance(e, dns.resolver.NoNameservers):\n                    break\n                tries_left -= 1\n                err_msg = (\n                    f'DNS error or timeout for {rdtype} query \"{query}\" ({self._errors[parent_hash]:,} so far): {e}'\n                )\n                if tries_left &gt; 0:\n                    retry_num = (retries + 1) - tries_left\n                    self.debug(err_msg)\n                    self.debug(f\"Retry (#{retry_num}) resolving {query} with kwargs={kwargs}\")\n                else:\n                    log.verbose(err_msg)\n\n        if results:\n            self._last_dns_success = time.time()\n\n        return results, errors\n\n    async def _resolve_ip(self, query, **kwargs):\n\"\"\"Translate an IP address into a corresponding DNS name.\n\n        This is the most basic function that will convert an IP address into its associated domain name. It handles\n        retries, caching, and multiple types of timeout/error scenarios internally. The function is intended for\n        internal use and should not be directly called by modules without understanding its intricacies.\n\n        Args:\n            query (str): The IP address to be reverse-resolved.\n            retries (int, optional): The number of times to retry on failure. Defaults to 0.\n            use_cache (bool, optional): Whether to check the cache for the result before attempting resolution. Defaults to True.\n            **kwargs: Additional arguments to be passed to the resolution process.\n\n        Returns:\n            tuple: A tuple containing:\n                - list: A list of resolved domain names (in default dnspython answer format).\n                - list: A list of errors encountered during resolution.\n\n        Examples:\n            &gt;&gt;&gt; results, errors = await _resolve_ip(\"8.8.8.8\")\n            (&lt;dns.resolver.Answer object at 0x7f4a47cdb1d0&gt;, [])\n        \"\"\"\n        self.debug(f\"Reverse-resolving {query} with kwargs={kwargs}\")\n        retries = kwargs.pop(\"retries\", 0)\n        use_cache = kwargs.pop(\"use_cache\", True)\n        tries_left = int(retries) + 1\n        results = []\n        errors = []\n        dns_cache_hash = hash(f\"{query}:PTR\")\n        while tries_left &gt; 0:\n            try:\n                if use_cache:\n                    results = self._dns_cache.get(dns_cache_hash, [])\n                if not results:\n                    results = await self._catch(self.resolver.resolve_address, query, **kwargs)\n                    if use_cache:\n                        self._dns_cache[dns_cache_hash] = results\n                break\n            except (\n                dns.exception.Timeout,\n                dns.resolver.LifetimeTimeout,\n                dns.resolver.NoNameservers,\n                TimeoutError,\n            ) as e:\n                errors.append(e)\n                # don't retry if we get a SERVFAIL\n                if isinstance(e, dns.resolver.NoNameservers):\n                    self.debug(f\"{e} (query={query}, kwargs={kwargs})\")\n                    break\n                else:\n                    tries_left -= 1\n                    if tries_left &gt; 0:\n                        retry_num = (retries + 2) - tries_left\n                        self.debug(f\"Retrying (#{retry_num}) {query} with kwargs={kwargs}\")\n\n        if results:\n            self._last_dns_success = time.time()\n\n        return results, errors\n\n    async def handle_wildcard_event(self, event, children):\n\"\"\"\n        Used within BBOT's scan manager to detect and tag DNS wildcard events.\n\n        Wildcards are detected for every major record type. If a wildcard is detected, its data\n        is overwritten, for example: `_wildcard.evilcorp.com`.\n\n        Args:\n            event (object): The event to check for wildcards.\n            children (list): A list of the event's resulting DNS children after resolution.\n\n        Returns:\n            None: This method modifies the `event` in place and does not return a value.\n\n        Examples:\n            &gt;&gt;&gt; handle_wildcard_event(event, children)\n            # The `event` might now have tags like [\"wildcard\", \"a-wildcard\", \"aaaa-wildcard\"] and\n            # its `data` attribute might be modified to \"_wildcard.evilcorp.com\" if it was detected\n            # as a wildcard.\n        \"\"\"\n        log.debug(f\"Entering handle_wildcard_event({event}, children={children})\")\n        try:\n            event_host = str(event.host)\n            # wildcard checks\n            if not is_ip(event.host):\n                # check if the dns name itself is a wildcard entry\n                wildcard_rdtypes = await self.is_wildcard(event_host)\n                for rdtype, (is_wildcard, wildcard_host) in wildcard_rdtypes.items():\n                    wildcard_tag = \"error\"\n                    if is_wildcard == True:\n                        event.add_tag(\"wildcard\")\n                        wildcard_tag = \"wildcard\"\n                    event.add_tag(f\"{rdtype.lower()}-{wildcard_tag}\")\n\n            # wildcard event modification (www.evilcorp.com --&gt; _wildcard.evilcorp.com)\n            if not is_ip(event.host) and children:\n                if wildcard_rdtypes:\n                    # these are the rdtypes that successfully resolve\n                    resolved_rdtypes = set([c.upper() for c in children])\n                    # these are the rdtypes that have wildcards\n                    wildcard_rdtypes_set = set(wildcard_rdtypes)\n                    # consider the event a full wildcard if all its records are wildcards\n                    event_is_wildcard = False\n                    if resolved_rdtypes:\n                        event_is_wildcard = all(r in wildcard_rdtypes_set for r in resolved_rdtypes)\n\n                    if event_is_wildcard:\n                        if event.type in (\"DNS_NAME\",) and not \"_wildcard\" in event.data.split(\".\"):\n                            wildcard_parent = self.parent_helper.parent_domain(event_host)\n                            for rdtype, (_is_wildcard, _parent_domain) in wildcard_rdtypes.items():\n                                if _is_wildcard:\n                                    wildcard_parent = _parent_domain\n                                    break\n                            wildcard_data = f\"_wildcard.{wildcard_parent}\"\n                            if wildcard_data != event.data:\n                                log.debug(\n                                    f'Wildcard detected, changing event.data \"{event.data}\" --&gt; \"{wildcard_data}\"'\n                                )\n                                event.data = wildcard_data\n                else:\n                    # check if this domain is using wildcard dns\n                    event_target = \"target\" in event.tags\n                    wildcard_domain_results = await self.is_wildcard_domain(event_host, log_info=event_target)\n                    for hostname, wildcard_domain_rdtypes in wildcard_domain_results.items():\n                        if wildcard_domain_rdtypes:\n                            event.add_tag(\"wildcard-domain\")\n                            for rdtype, ips in wildcard_domain_rdtypes.items():\n                                event.add_tag(f\"{rdtype.lower()}-wildcard-domain\")\n        finally:\n            log.debug(f\"Finished handle_wildcard_event({event}, children={children})\")\n\n    async def resolve_event(self, event, minimal=False):\n\"\"\"\n        Tag the given event with the appropriate DNS record types and optionally create child\n        events based on DNS resolutions.\n\n        Args:\n            event (object): The event to be resolved and tagged.\n            minimal (bool, optional): If set to True, the function will perform minimal DNS\n                resolution. Defaults to False.\n\n        Returns:\n            tuple: A 4-tuple containing the following items:\n                - event_tags (set): Set of tags for the event.\n                - event_whitelisted (bool): Whether the event is whitelisted.\n                - event_blacklisted (bool): Whether the event is blacklisted.\n                - dns_children (dict): Dictionary containing child events from DNS resolutions.\n\n        Examples:\n            &gt;&gt;&gt; event = make_event(\"evilcorp.com\")\n            &gt;&gt;&gt; resolve_event(event)\n            ({'resolved', 'ns-record', 'a-record',}, False, False, {'A': {IPv4Address('1.2.3.4'), IPv4Address('1.2.3.5')}, 'NS': {'ns1.evilcorp.com'}})\n\n        Note:\n            This method does not modify the passed in `event`. Instead, it returns data\n            that can be used to modify or act upon the `event`.\n        \"\"\"\n        log.debug(f\"Resolving {event}\")\n        event_host = str(event.host)\n        event_tags = set()\n        dns_children = dict()\n        event_whitelisted = False\n        event_blacklisted = False\n\n        try:\n            if (not event.host) or (event.type in (\"IP_RANGE\",)):\n                return event_tags, event_whitelisted, event_blacklisted, dns_children\n\n            # lock to ensure resolution of the same host doesn't start while we're working here\n            async with self._event_cache_locks.lock(event_host):\n                # try to get data from cache\n                _event_tags, _event_whitelisted, _event_blacklisted, _dns_children = self.event_cache_get(event_host)\n                event_tags.update(_event_tags)\n                # if we found it, return it\n                if _event_whitelisted is not None:\n                    return event_tags, _event_whitelisted, _event_blacklisted, _dns_children\n\n                # then resolve\n                types = ()\n                if self.parent_helper.is_ip(event.host):\n                    if not minimal:\n                        types = (\"PTR\",)\n                else:\n                    if event.type == \"DNS_NAME\" and not minimal:\n                        types = self.all_rdtypes\n                    else:\n                        types = (\"A\", \"AAAA\")\n\n                if types:\n                    tasks = [self.resolve_raw(event_host, type=t, use_cache=True) for t in types]\n                    async for task in as_completed(tasks):\n                        resolved_raw, errors = await task\n                        for rdtype, e in errors:\n                            if rdtype not in resolved_raw:\n                                event_tags.add(f\"{rdtype.lower()}-error\")\n                        for rdtype, records in resolved_raw:\n                            rdtype = str(rdtype).upper()\n                            if records:\n                                event_tags.add(\"resolved\")\n                                event_tags.add(f\"{rdtype.lower()}-record\")\n\n                            # whitelisting and blacklisting of IPs\n                            for r in records:\n                                for _, t in self.extract_targets(r):\n                                    if t:\n                                        ip = self.parent_helper.make_ip_type(t)\n\n                                        if rdtype in (\"A\", \"AAAA\", \"CNAME\"):\n                                            with contextlib.suppress(ValidationError):\n                                                if self.parent_helper.is_ip(ip):\n                                                    if self.parent_helper.scan.whitelisted(ip):\n                                                        event_whitelisted = True\n                                            with contextlib.suppress(ValidationError):\n                                                if self.parent_helper.scan.blacklisted(ip):\n                                                    event_blacklisted = True\n\n                                        if self.filter_bad_ptrs and rdtype in (\"PTR\") and self.parent_helper.is_ptr(t):\n                                            self.debug(f\"Filtering out bad PTR: {t}\")\n                                            continue\n\n                                        try:\n                                            dns_children[rdtype].add(ip)\n                                        except KeyError:\n                                            dns_children[rdtype] = {ip}\n\n                    # tag with cloud providers\n                    if not self.parent_helper.in_tests:\n                        to_check = set()\n                        if event.type == \"IP_ADDRESS\":\n                            to_check.add(event.data)\n                        for rdtype, ips in dns_children.items():\n                            if rdtype in (\"A\", \"AAAA\"):\n                                for ip in ips:\n                                    to_check.add(ip)\n                        for ip in to_check:\n                            provider, provider_type, subnet = cloudcheck(ip)\n                            if provider:\n                                event_tags.add(f\"{provider_type}-{provider}\")\n\n                    # if needed, mark as unresolved\n                    if not is_ip(event_host) and \"resolved\" not in event_tags:\n                        event_tags.add(\"unresolved\")\n                    # check for private IPs\n                    for rdtype, ips in dns_children.items():\n                        for ip in ips:\n                            try:\n                                ip = ipaddress.ip_address(ip)\n                                if ip.is_private:\n                                    event_tags.add(\"private-ip\")\n                            except ValueError:\n                                continue\n\n                    self._event_cache[event_host] = (event_tags, event_whitelisted, event_blacklisted, dns_children)\n\n            return event_tags, event_whitelisted, event_blacklisted, dns_children\n\n        finally:\n            log.debug(f\"Finished resolving {event}\")\n\n    def event_cache_get(self, host):\n\"\"\"\n        Retrieves cached event data based on the given host.\n\n        Args:\n            host (str): The host for which the event data is to be retrieved.\n\n        Returns:\n            tuple: A 4-tuple containing the following items:\n                - event_tags (set): Set of tags for the event.\n                - event_whitelisted (bool or None): Whether the event is whitelisted. Returns None if not found.\n                - event_blacklisted (bool or None): Whether the event is blacklisted. Returns None if not found.\n                - dns_children (set): Set containing child events from DNS resolutions.\n\n        Examples:\n            Assuming an event with host \"www.evilcorp.com\" has been cached:\n\n            &gt;&gt;&gt; event_cache_get(\"www.evilcorp.com\")\n            ({\"resolved\", \"a-record\"}, False, False, {'1.2.3.4'})\n\n            Assuming no event with host \"www.notincache.com\" has been cached:\n\n            &gt;&gt;&gt; event_cache_get(\"www.notincache.com\")\n            (set(), None, None, set())\n        \"\"\"\n        try:\n            event_tags, event_whitelisted, event_blacklisted, dns_children = self._event_cache[host]\n            return (event_tags, event_whitelisted, event_blacklisted, dns_children)\n        except KeyError:\n            return set(), None, None, set()\n\n    async def _resolve_batch_coro_wrapper(self, q, **kwargs):\n\"\"\"\n        Helps us correlate task results back to their original arguments\n        \"\"\"\n        result = await self.resolve(q, **kwargs)\n        return (q, result)\n\n    async def resolve_batch(self, queries, **kwargs):\n\"\"\"\n        Asynchronously resolves a batch of queries in parallel and yields the results as they are completed.\n\n        This method wraps around `_resolve_batch_coro_wrapper` to resolve a list of queries in parallel.\n        It batches the queries to a manageable size and executes them asynchronously, respecting\n        global rate limits.\n\n        Args:\n            queries (list): List of queries to resolve.\n            **kwargs: Additional keyword arguments to pass to `_resolve_batch_coro_wrapper`.\n\n        Yields:\n            tuple: A tuple containing the original query and its resolved value.\n\n        Examples:\n            &gt;&gt;&gt; import asyncio\n            &gt;&gt;&gt; async def example_usage():\n            ...     async for result in resolve_batch(['www.evilcorp.com', 'evilcorp.com']):\n            ...         print(result)\n            ('www.evilcorp.com', {'1.1.1.1'})\n            ('evilcorp.com', {'2.2.2.2'})\n\n        \"\"\"\n        queries = list(queries)\n        batch_size = 250\n        for i in range(0, len(queries), batch_size):\n            batch = queries[i : i + batch_size]\n            tasks = [self._resolve_batch_coro_wrapper(q, **kwargs) for q in batch]\n            async for task in as_completed(tasks):\n                yield await task\n\n    def extract_targets(self, record):\n\"\"\"\n        Extracts hostnames or IP addresses from a given DNS record.\n\n        This method reads the DNS record's type and based on that, extracts the target\n        hostnames or IP addresses it points to. The type of DNS record\n        (e.g., \"A\", \"MX\", \"CNAME\", etc.) determines which fields are used for extraction.\n\n        Args:\n            record (dns.rdata.Rdata): The DNS record to extract information from.\n\n        Returns:\n            set: A set of tuples, each containing the DNS record type and the extracted value.\n\n        Examples:\n            &gt;&gt;&gt; from dns.rrset import from_text\n            &gt;&gt;&gt; record = from_text('www.example.com', 3600, 'IN', 'A', '192.0.2.1')\n            &gt;&gt;&gt; extract_targets(record[0])\n            {('A', '192.0.2.1')}\n\n            &gt;&gt;&gt; record = from_text('example.com', 3600, 'IN', 'MX', '10 mail.example.com.')\n            &gt;&gt;&gt; extract_targets(record[0])\n            {('MX', 'mail.example.com')}\n\n        \"\"\"\n        results = set()\n        rdtype = str(record.rdtype.name).upper()\n        if rdtype in (\"A\", \"AAAA\", \"NS\", \"CNAME\", \"PTR\"):\n            results.add((rdtype, self._clean_dns_record(record)))\n        elif rdtype == \"SOA\":\n            results.add((rdtype, self._clean_dns_record(record.mname)))\n        elif rdtype == \"MX\":\n            results.add((rdtype, self._clean_dns_record(record.exchange)))\n        elif rdtype == \"SRV\":\n            results.add((rdtype, self._clean_dns_record(record.target)))\n        elif rdtype == \"TXT\":\n            for s in record.strings:\n                s = self.parent_helper.smart_decode(s)\n                for match in dns_name_regex.finditer(s):\n                    start, end = match.span()\n                    host = s[start:end]\n                    results.add((rdtype, host))\n        elif rdtype == \"NSEC\":\n            results.add((rdtype, self._clean_dns_record(record.next)))\n        else:\n            log.warning(f'Unknown DNS record type \"{rdtype}\"')\n        return results\n\n    @staticmethod\n    def _clean_dns_record(record):\n\"\"\"\n        Cleans and formats a given DNS record for further processing.\n\n        This static method converts the DNS record to text format if it's not already a string.\n        It also removes any trailing dots and converts the record to lowercase.\n\n        Args:\n            record (str or dns.rdata.Rdata): The DNS record to clean.\n\n        Returns:\n            str: The cleaned and formatted DNS record.\n\n        Examples:\n            &gt;&gt;&gt; _clean_dns_record('www.evilcorp.com.')\n            'www.evilcorp.com'\n\n            &gt;&gt;&gt; from dns.rrset import from_text\n            &gt;&gt;&gt; record = from_text('www.evilcorp.com', 3600, 'IN', 'A', '1.2.3.4')[0]\n            &gt;&gt;&gt; _clean_dns_record(record)\n            '1.2.3.4'\n        \"\"\"\n        if not isinstance(record, str):\n            record = str(record.to_text())\n        return str(record).rstrip(\".\").lower()\n\n    async def _catch(self, callback, *args, **kwargs):\n\"\"\"\n        Asynchronously catches exceptions thrown during DNS resolution and logs them.\n\n        This method wraps around a given asynchronous callback function to handle different\n        types of DNS exceptions and general exceptions. It logs the exceptions for debugging\n        and, in some cases, re-raises them.\n\n        Args:\n            callback (callable): The asynchronous function to be executed.\n            *args: Positional arguments to pass to the callback.\n            **kwargs: Keyword arguments to pass to the callback.\n\n        Returns:\n            Any: The return value of the callback function, or an empty list if an exception is caught.\n\n        Raises:\n            dns.resolver.NoNameservers: When no nameservers could be reached.\n        \"\"\"\n        try:\n            return await callback(*args, **kwargs)\n        except dns.resolver.NoNameservers:\n            raise\n        except (dns.exception.Timeout, dns.resolver.LifetimeTimeout, TimeoutError):\n            log.debug(f\"DNS query with args={args}, kwargs={kwargs} timed out after {self.timeout} seconds\")\n            raise\n        except dns.exception.DNSException as e:\n            self.debug(f\"{e} (args={args}, kwargs={kwargs})\")\n        except Exception as e:\n            log.warning(f\"Error in {callback.__qualname__}() with args={args}, kwargs={kwargs}: {e}\")\n            log.trace(traceback.format_exc())\n        return []\n\n    async def is_wildcard(self, query, ips=None, rdtype=None):\n\"\"\"\n        Use this method to check whether a *host* is a wildcard entry\n\n        This can reliably tell the difference between a valid DNS record and a wildcard within a wildcard domain.\n\n        If you want to know whether a domain is using wildcard DNS, use `is_wildcard_domain()` instead.\n\n        Args:\n            query (str): The hostname to check for a wildcard entry.\n            ips (list, optional): List of IPs to compare against, typically obtained from a previous DNS resolution of the query.\n            rdtype (str, optional): The DNS record type (e.g., \"A\", \"AAAA\") to consider during the check.\n\n        Returns:\n            dict: A dictionary indicating if the query is a wildcard for each checked DNS record type.\n                Keys are DNS record types like \"A\", \"AAAA\", etc.\n                Values are tuples where the first element is a boolean indicating if the query is a wildcard,\n                and the second element is the wildcard parent if it's a wildcard.\n\n        Raises:\n            ValueError: If only one of `ips` or `rdtype` is specified or if no valid IPs are specified.\n\n        Examples:\n            &gt;&gt;&gt; is_wildcard(\"www.github.io\")\n            {\"A\": (True, \"github.io\"), \"AAAA\": (True, \"github.io\")}\n\n            &gt;&gt;&gt; is_wildcard(\"www.evilcorp.com\", ips=[\"93.184.216.34\"], rdtype=\"A\")\n            {\"A\": (False, \"evilcorp.com\")}\n\n        Note:\n            `is_wildcard` can be True, False, or None (indicating that wildcard detection was inconclusive)\n        \"\"\"\n        result = {}\n\n        if [ips, rdtype].count(None) == 1:\n            raise ValueError(\"Both ips and rdtype must be specified\")\n\n        if not is_dns_name(query):\n            return {}\n\n        # skip check if the query's parent domain is excluded in the config\n        for d in self.wildcard_ignore:\n            if self.parent_helper.host_in_host(query, d):\n                log.debug(f\"Skipping wildcard detection on {query} because it is excluded in the config\")\n                return {}\n\n        query = self._clean_dns_record(query)\n        # skip check if it's an IP\n        if is_ip(query) or not \".\" in query:\n            return {}\n        # skip check if the query is a domain\n        if is_domain(query):\n            return {}\n\n        parent = parent_domain(query)\n        parents = list(domain_parents(query))\n\n        rdtypes_to_check = [rdtype] if rdtype is not None else self.all_rdtypes\n\n        base_query_ips = dict()\n        # if the caller hasn't already done the work of resolving the IPs\n        if ips is None:\n            # then resolve the query for all rdtypes\n            base_query_tasks = {\n                t: asyncio.create_task(self.resolve_raw(query, type=t, use_cache=True)) for t in rdtypes_to_check\n            }\n            for _rdtype, task in base_query_tasks.items():\n                raw_results, errors = await task\n                if errors and not raw_results:\n                    self.debug(f\"Failed to resolve {query} ({_rdtype}) during wildcard detection\")\n                    result[_rdtype] = (None, parent)\n                    continue\n                for __rdtype, answers in raw_results:\n                    base_query_results = set()\n                    for answer in answers:\n                        for _, t in self.extract_targets(answer):\n                            base_query_results.add(t)\n                    if base_query_results:\n                        base_query_ips[__rdtype] = base_query_results\n        else:\n            # otherwise, we can skip all that\n            cleaned_ips = set([self._clean_dns_record(ip) for ip in ips])\n            if not cleaned_ips:\n                raise ValueError(\"Valid IPs must be specified\")\n            base_query_ips[rdtype] = cleaned_ips\n        if not base_query_ips:\n            return result\n\n        # once we've resolved the base query and have IP addresses to work with\n        # we can compare the IPs to the ones we have on file for wildcards\n\n        # for every parent domain, starting with the shortest\n        try:\n            for host in parents[::-1]:\n                # for every rdtype\n                for _rdtype in list(base_query_ips):\n                    # get the IPs from above\n                    query_ips = base_query_ips.get(_rdtype, set())\n                    # make sure we've checked that domain for wildcards\n                    await self.is_wildcard_domain(host)\n                    host_hash = hash(host)\n\n                    if host_hash in self._wildcard_cache:\n                        # then get its IPs from our wildcard cache\n                        wildcard_rdtypes = self._wildcard_cache[host_hash]\n\n                        # then check to see if our IPs match the wildcard ones\n                        if _rdtype in wildcard_rdtypes:\n                            wildcard_ips = wildcard_rdtypes[_rdtype]\n                            # if our IPs match the wildcard ones, then ladies and gentlemen we have a wildcard\n                            is_wildcard = any(r in wildcard_ips for r in query_ips)\n\n                            if is_wildcard and not result.get(_rdtype, (None, None))[0] is True:\n                                result[_rdtype] = (True, host)\n\n                    # if we've reached a point where the dns name is a complete wildcard, class can be dismissed early\n                    base_query_rdtypes = set(base_query_ips)\n                    wildcard_rdtypes_set = set([k for k, v in result.items() if v[0] is True])\n                    if base_query_rdtypes and wildcard_rdtypes_set and base_query_rdtypes == wildcard_rdtypes_set:\n                        log.debug(\n                            f\"Breaking from wildcard detection for {query} at {host} because base query rdtypes ({base_query_rdtypes}) == wildcard rdtypes ({wildcard_rdtypes_set})\"\n                        )\n                        raise DNSWildcardBreak()\n        except DNSWildcardBreak:\n            pass\n\n        return result\n\n    async def is_wildcard_domain(self, domain, log_info=False):\n\"\"\"\n        Check whether a given host or its children make use of wildcard DNS entries. Wildcard DNS can have\n        various implications, particularly in subdomain enumeration and subdomain takeovers.\n\n        Args:\n            domain (str): The domain to check for wildcard DNS entries.\n            log_info (bool, optional): Whether to log the result of the check. Defaults to False.\n\n        Returns:\n            dict: A dictionary where the keys are the parent domains that have wildcard DNS entries,\n            and the values are another dictionary of DNS record types (\"A\", \"AAAA\", etc.) mapped to\n            sets of their resolved IP addresses.\n\n        Examples:\n            &gt;&gt;&gt; is_wildcard_domain(\"github.io\")\n            {\"github.io\": {\"A\": {\"1.2.3.4\"}, \"AAAA\": {\"dead::beef\"}}}\n\n            &gt;&gt;&gt; is_wildcard_domain(\"example.com\")\n            {}\n        \"\"\"\n        wildcard_domain_results = {}\n        domain = self._clean_dns_record(domain)\n\n        if not is_dns_name(domain):\n            return {}\n\n        # skip check if the query's parent domain is excluded in the config\n        for d in self.wildcard_ignore:\n            if self.parent_helper.host_in_host(domain, d):\n                log.debug(f\"Skipping wildcard detection on {domain} because it is excluded in the config\")\n                return {}\n\n        rdtypes_to_check = set(self.all_rdtypes)\n\n        # make a list of its parents\n        parents = list(domain_parents(domain, include_self=True))\n        # and check each of them, beginning with the highest parent (i.e. the root domain)\n        for i, host in enumerate(parents[::-1]):\n            # have we checked this host before?\n            host_hash = hash(host)\n            async with self._wildcard_lock.lock(host_hash):\n                # if we've seen this host before\n                if host_hash in self._wildcard_cache:\n                    wildcard_domain_results[host] = self._wildcard_cache[host_hash]\n                    continue\n\n                # determine if this is a wildcard domain\n                wildcard_tasks = {t: [] for t in rdtypes_to_check}\n                # resolve a bunch of random subdomains of the same parent\n                for rdtype in rdtypes_to_check:\n                    # continue if a wildcard was already found for this rdtype\n                    # if rdtype in self._wildcard_cache[host_hash]:\n                    #     continue\n                    for _ in range(self.wildcard_tests):\n                        rand_query = f\"{rand_string(digits=False, length=10)}.{host}\"\n                        wildcard_tasks[rdtype].append(self.resolve(rand_query, type=rdtype, use_cache=False))\n\n                # combine the random results\n                is_wildcard = False\n                wildcard_results = dict()\n                for rdtype, tasks in wildcard_tasks.items():\n                    async for task in as_completed(tasks):\n                        results = await task\n                        if results:\n                            is_wildcard = True\n                            if not rdtype in wildcard_results:\n                                wildcard_results[rdtype] = set()\n                            wildcard_results[rdtype].update(results)\n                            # we know this rdtype is a wildcard\n                            # so we don't need to check it anymore\n                            with suppress(KeyError):\n                                rdtypes_to_check.remove(rdtype)\n\n                self._wildcard_cache.update({host_hash: wildcard_results})\n                wildcard_domain_results.update({host: wildcard_results})\n                if is_wildcard:\n                    wildcard_rdtypes_str = \",\".join(sorted([t.upper() for t, r in wildcard_results.items() if r]))\n                    log_fn = log.verbose\n                    if log_info:\n                        log_fn = log.info\n                    log_fn(f\"Encountered domain with wildcard DNS ({wildcard_rdtypes_str}): {host}\")\n\n        return wildcard_domain_results\n\n    async def _connectivity_check(self, interval=5):\n\"\"\"\n        Periodically checks for an active internet connection by attempting DNS resolution.\n\n        Args:\n            interval (int, optional): The time interval, in seconds, at which to perform the check.\n            Defaults to 5 seconds.\n\n        Returns:\n            bool: True if there is an active internet connection, False otherwise.\n\n        Examples:\n            &gt;&gt;&gt; await _connectivity_check()\n            True\n        \"\"\"\n        if self._last_dns_success is not None:\n            if time.time() - self._last_dns_success &lt; interval:\n                return True\n        dns_server_working = []\n        async with self._dns_connectivity_lock:\n            with suppress(Exception):\n                dns_server_working = await self._catch(self.resolver.resolve, \"www.google.com\", rdtype=\"A\")\n                if dns_server_working:\n                    self._last_dns_success = time.time()\n                    return True\n        if time.time() - self._last_connectivity_warning &gt; interval:\n            log.warning(f\"DNS queries are failing, please check your internet connection\")\n            self._last_connectivity_warning = time.time()\n        self._errors.clear()\n        return False\n\n    def _parse_rdtype(self, t, default=None):\n        if isinstance(t, str):\n            if t.strip().lower() in (\"any\", \"all\", \"*\"):\n                return self.all_rdtypes\n            else:\n                return [t.strip().upper()]\n        elif any([isinstance(t, x) for x in (list, tuple)]):\n            return [str(_).strip().upper() for _ in t]\n        return default\n\n    def debug(self, *args, **kwargs):\n        if self._debug:\n            log.debug(*args, **kwargs)\n\n    def _get_dummy_module(self, name):\n        try:\n            dummy_module = self._dummy_modules[name]\n        except KeyError:\n            dummy_module = self.parent_helper._make_dummy_module(name=name, _type=\"DNS\")\n            self._dummy_modules[name] = dummy_module\n        return dummy_module\n\n    def mock_dns(self, dns_dict):\n        if self._orig_resolve_raw is None:\n            self._orig_resolve_raw = self.resolve_raw\n\n        async def mock_resolve_raw(query, **kwargs):\n            results = []\n            errors = []\n            types = self._parse_rdtype(kwargs.get(\"type\", [\"A\", \"AAAA\"]))\n            for t in types:\n                with suppress(KeyError):\n                    results += self._mock_table[(query, t)]\n            return results, errors\n\n        for (query, rdtype), answers in dns_dict.items():\n            if isinstance(answers, str):\n                answers = [answers]\n            for answer in answers:\n                rdata = dns.rdata.from_text(\"IN\", rdtype, answer)\n                try:\n                    self._mock_table[(query, rdtype)].append((rdtype, rdata))\n                except KeyError:\n                    self._mock_table[(query, rdtype)] = [(rdtype, [rdata])]\n\n        self.resolve_raw = mock_resolve_raw\n</code></pre>"},{"location":"dev/helpers/dns/#bbot.core.helpers.dns.DNSHelper.resolve","title":"resolve  <code>async</code>","text":"<pre><code>resolve(query, **kwargs)\n</code></pre> <p>Resolve DNS names and IP addresses to their corresponding results.</p> <p>This is a high-level function that can translate a given domain name to its associated IP addresses or an IP address to its corresponding domain names. It's structured for ease of use within modules and will abstract away most of the complexity of DNS resolution, returning a simple set of results.</p> <p>Parameters:</p> <ul> <li> <code>query</code>             (<code>str</code>)         \u2013          <p>The domain name or IP address to resolve.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional arguments to be passed to the resolution process.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>set</code>        \u2013          <p>A set containing resolved domain names or IP addresses.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; results = await resolve(\"1.2.3.4\")\n{\"evilcorp.com\"}\n</code></pre> <pre><code>&gt;&gt;&gt; results = await resolve(\"evilcorp.com\")\n{\"1.2.3.4\", \"dead::beef\"}\n</code></pre> Source code in <code>bbot/core/helpers/dns.py</code> <pre><code>async def resolve(self, query, **kwargs):\n\"\"\"Resolve DNS names and IP addresses to their corresponding results.\n\n    This is a high-level function that can translate a given domain name to its associated IP addresses\n    or an IP address to its corresponding domain names. It's structured for ease of use within modules\n    and will abstract away most of the complexity of DNS resolution, returning a simple set of results.\n\n    Args:\n        query (str): The domain name or IP address to resolve.\n        **kwargs: Additional arguments to be passed to the resolution process.\n\n    Returns:\n        set: A set containing resolved domain names or IP addresses.\n\n    Examples:\n        &gt;&gt;&gt; results = await resolve(\"1.2.3.4\")\n        {\"evilcorp.com\"}\n\n        &gt;&gt;&gt; results = await resolve(\"evilcorp.com\")\n        {\"1.2.3.4\", \"dead::beef\"}\n    \"\"\"\n    results = set()\n    try:\n        r = await self.resolve_raw(query, **kwargs)\n        if r:\n            raw_results, errors = r\n            for rdtype, answers in raw_results:\n                for answer in answers:\n                    for _, t in self.extract_targets(answer):\n                        results.add(t)\n    except BaseException:\n        log.trace(f\"Caught exception in resolve({query}, {kwargs}):\")\n        log.trace(traceback.format_exc())\n        raise\n\n    self.debug(f\"Results for {query} with kwargs={kwargs}: {results}\")\n    return results\n</code></pre>"},{"location":"dev/helpers/dns/#bbot.core.helpers.dns.DNSHelper.resolve_batch","title":"resolve_batch  <code>async</code>","text":"<pre><code>resolve_batch(queries, **kwargs)\n</code></pre> <p>Asynchronously resolves a batch of queries in parallel and yields the results as they are completed.</p> <p>This method wraps around <code>_resolve_batch_coro_wrapper</code> to resolve a list of queries in parallel. It batches the queries to a manageable size and executes them asynchronously, respecting global rate limits.</p> <p>Parameters:</p> <ul> <li> <code>queries</code>             (<code>list</code>)         \u2013          <p>List of queries to resolve.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments to pass to <code>_resolve_batch_coro_wrapper</code>.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>tuple</code>        \u2013          <p>A tuple containing the original query and its resolved value.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; async def example_usage():\n...     async for result in resolve_batch(['www.evilcorp.com', 'evilcorp.com']):\n...         print(result)\n('www.evilcorp.com', {'1.1.1.1'})\n('evilcorp.com', {'2.2.2.2'})\n</code></pre> Source code in <code>bbot/core/helpers/dns.py</code> <pre><code>async def resolve_batch(self, queries, **kwargs):\n\"\"\"\n    Asynchronously resolves a batch of queries in parallel and yields the results as they are completed.\n\n    This method wraps around `_resolve_batch_coro_wrapper` to resolve a list of queries in parallel.\n    It batches the queries to a manageable size and executes them asynchronously, respecting\n    global rate limits.\n\n    Args:\n        queries (list): List of queries to resolve.\n        **kwargs: Additional keyword arguments to pass to `_resolve_batch_coro_wrapper`.\n\n    Yields:\n        tuple: A tuple containing the original query and its resolved value.\n\n    Examples:\n        &gt;&gt;&gt; import asyncio\n        &gt;&gt;&gt; async def example_usage():\n        ...     async for result in resolve_batch(['www.evilcorp.com', 'evilcorp.com']):\n        ...         print(result)\n        ('www.evilcorp.com', {'1.1.1.1'})\n        ('evilcorp.com', {'2.2.2.2'})\n\n    \"\"\"\n    queries = list(queries)\n    batch_size = 250\n    for i in range(0, len(queries), batch_size):\n        batch = queries[i : i + batch_size]\n        tasks = [self._resolve_batch_coro_wrapper(q, **kwargs) for q in batch]\n        async for task in as_completed(tasks):\n            yield await task\n</code></pre>"},{"location":"dev/helpers/dns/#bbot.core.helpers.dns.DNSHelper.resolve_raw","title":"resolve_raw  <code>async</code>","text":"<pre><code>resolve_raw(query, **kwargs)\n</code></pre> <p>Resolves the given query to its associated DNS records.</p> <p>This function is a foundational method for DNS resolution in this class. It understands both IP addresses and hostnames and returns their associated records in a raw format provided by the dnspython library.</p> <p>Parameters:</p> <ul> <li> <code>query</code>             (<code>str</code>)         \u2013          <p>The IP address or hostname to resolve.</p> </li> <li> <code>type</code>             (<code>str or list[str]</code>)         \u2013          <p>Specifies the DNS record type(s) to fetch. Can be a single type like 'A' or a list like ['A', 'AAAA']. If set to 'any', 'all', or '*', it fetches all supported types. If not specified, the function defaults to fetching 'A' and 'AAAA' records.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional arguments that might be passed to the resolver.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>        \u2013          <p>A tuple containing two lists: - list: A list of tuples where each tuple consists of a record type string (like 'A') and the associated   raw dnspython answer. - list: A list of tuples where each tuple consists of a record type string and the associated error if   there was an issue fetching the record.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await resolve_raw(\"8.8.8.8\")\n([('PTR', &lt;dns.resolver.Answer object at 0x7f4a47cdb1d0&gt;)], [])\n</code></pre> <pre><code>&gt;&gt;&gt; await resolve_raw(\"dns.google\")\n([('A', &lt;dns.resolver.Answer object at 0x7f4a47ce46d0&gt;), ('AAAA', &lt;dns.resolver.Answer object at 0x7f4a47ce4710&gt;)], [])\n</code></pre> Source code in <code>bbot/core/helpers/dns.py</code> <pre><code>async def resolve_raw(self, query, **kwargs):\n\"\"\"Resolves the given query to its associated DNS records.\n\n    This function is a foundational method for DNS resolution in this class. It understands both IP addresses and\n    hostnames and returns their associated records in a raw format provided by the dnspython library.\n\n    Args:\n        query (str): The IP address or hostname to resolve.\n        type (str or list[str], optional): Specifies the DNS record type(s) to fetch. Can be a single type like 'A'\n            or a list like ['A', 'AAAA']. If set to 'any', 'all', or '*', it fetches all supported types. If not\n            specified, the function defaults to fetching 'A' and 'AAAA' records.\n        **kwargs: Additional arguments that might be passed to the resolver.\n\n    Returns:\n        tuple: A tuple containing two lists:\n            - list: A list of tuples where each tuple consists of a record type string (like 'A') and the associated\n              raw dnspython answer.\n            - list: A list of tuples where each tuple consists of a record type string and the associated error if\n              there was an issue fetching the record.\n\n    Examples:\n        &gt;&gt;&gt; await resolve_raw(\"8.8.8.8\")\n        ([('PTR', &lt;dns.resolver.Answer object at 0x7f4a47cdb1d0&gt;)], [])\n\n        &gt;&gt;&gt; await resolve_raw(\"dns.google\")\n        ([('A', &lt;dns.resolver.Answer object at 0x7f4a47ce46d0&gt;), ('AAAA', &lt;dns.resolver.Answer object at 0x7f4a47ce4710&gt;)], [])\n    \"\"\"\n    # DNS over TCP is more reliable\n    # But setting this breaks DNS resolution on Ubuntu because systemd-resolve doesn't support TCP\n    # kwargs[\"tcp\"] = True\n    results = []\n    errors = []\n    try:\n        query = str(query).strip()\n        if is_ip(query):\n            kwargs.pop(\"type\", None)\n            kwargs.pop(\"rdtype\", None)\n            results, errors = await self._resolve_ip(query, **kwargs)\n            return [(\"PTR\", results)], [(\"PTR\", e) for e in errors]\n        else:\n            types = [\"A\", \"AAAA\"]\n            kwargs.pop(\"rdtype\", None)\n            if \"type\" in kwargs:\n                t = kwargs.pop(\"type\")\n                types = self._parse_rdtype(t, default=types)\n            for t in types:\n                r, e = await self._resolve_hostname(query, rdtype=t, **kwargs)\n                if r:\n                    results.append((t, r))\n                for error in e:\n                    errors.append((t, error))\n    except BaseException:\n        log.trace(f\"Caught exception in resolve_raw({query}, {kwargs}):\")\n        log.trace(traceback.format_exc())\n        raise\n\n    return (results, errors)\n</code></pre>"},{"location":"dev/helpers/dns/#bbot.core.helpers.dns.DNSHelper.is_wildcard","title":"is_wildcard  <code>async</code>","text":"<pre><code>is_wildcard(query, ips = None, rdtype = None)\n</code></pre> <p>Use this method to check whether a host is a wildcard entry</p> <p>This can reliably tell the difference between a valid DNS record and a wildcard within a wildcard domain.</p> <p>If you want to know whether a domain is using wildcard DNS, use <code>is_wildcard_domain()</code> instead.</p> <p>Parameters:</p> <ul> <li> <code>query</code>             (<code>str</code>)         \u2013          <p>The hostname to check for a wildcard entry.</p> </li> <li> <code>ips</code>             (<code>list</code>, default:                 <code>None</code> )         \u2013          <p>List of IPs to compare against, typically obtained from a previous DNS resolution of the query.</p> </li> <li> <code>rdtype</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>The DNS record type (e.g., \"A\", \"AAAA\") to consider during the check.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>        \u2013          <p>A dictionary indicating if the query is a wildcard for each checked DNS record type. Keys are DNS record types like \"A\", \"AAAA\", etc. Values are tuples where the first element is a boolean indicating if the query is a wildcard, and the second element is the wildcard parent if it's a wildcard.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If only one of <code>ips</code> or <code>rdtype</code> is specified or if no valid IPs are specified.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_wildcard(\"www.github.io\")\n{\"A\": (True, \"github.io\"), \"AAAA\": (True, \"github.io\")}\n</code></pre> <pre><code>&gt;&gt;&gt; is_wildcard(\"www.evilcorp.com\", ips=[\"93.184.216.34\"], rdtype=\"A\")\n{\"A\": (False, \"evilcorp.com\")}\n</code></pre> Note <p><code>is_wildcard</code> can be True, False, or None (indicating that wildcard detection was inconclusive)</p> Source code in <code>bbot/core/helpers/dns.py</code> <pre><code>async def is_wildcard(self, query, ips=None, rdtype=None):\n\"\"\"\n    Use this method to check whether a *host* is a wildcard entry\n\n    This can reliably tell the difference between a valid DNS record and a wildcard within a wildcard domain.\n\n    If you want to know whether a domain is using wildcard DNS, use `is_wildcard_domain()` instead.\n\n    Args:\n        query (str): The hostname to check for a wildcard entry.\n        ips (list, optional): List of IPs to compare against, typically obtained from a previous DNS resolution of the query.\n        rdtype (str, optional): The DNS record type (e.g., \"A\", \"AAAA\") to consider during the check.\n\n    Returns:\n        dict: A dictionary indicating if the query is a wildcard for each checked DNS record type.\n            Keys are DNS record types like \"A\", \"AAAA\", etc.\n            Values are tuples where the first element is a boolean indicating if the query is a wildcard,\n            and the second element is the wildcard parent if it's a wildcard.\n\n    Raises:\n        ValueError: If only one of `ips` or `rdtype` is specified or if no valid IPs are specified.\n\n    Examples:\n        &gt;&gt;&gt; is_wildcard(\"www.github.io\")\n        {\"A\": (True, \"github.io\"), \"AAAA\": (True, \"github.io\")}\n\n        &gt;&gt;&gt; is_wildcard(\"www.evilcorp.com\", ips=[\"93.184.216.34\"], rdtype=\"A\")\n        {\"A\": (False, \"evilcorp.com\")}\n\n    Note:\n        `is_wildcard` can be True, False, or None (indicating that wildcard detection was inconclusive)\n    \"\"\"\n    result = {}\n\n    if [ips, rdtype].count(None) == 1:\n        raise ValueError(\"Both ips and rdtype must be specified\")\n\n    if not is_dns_name(query):\n        return {}\n\n    # skip check if the query's parent domain is excluded in the config\n    for d in self.wildcard_ignore:\n        if self.parent_helper.host_in_host(query, d):\n            log.debug(f\"Skipping wildcard detection on {query} because it is excluded in the config\")\n            return {}\n\n    query = self._clean_dns_record(query)\n    # skip check if it's an IP\n    if is_ip(query) or not \".\" in query:\n        return {}\n    # skip check if the query is a domain\n    if is_domain(query):\n        return {}\n\n    parent = parent_domain(query)\n    parents = list(domain_parents(query))\n\n    rdtypes_to_check = [rdtype] if rdtype is not None else self.all_rdtypes\n\n    base_query_ips = dict()\n    # if the caller hasn't already done the work of resolving the IPs\n    if ips is None:\n        # then resolve the query for all rdtypes\n        base_query_tasks = {\n            t: asyncio.create_task(self.resolve_raw(query, type=t, use_cache=True)) for t in rdtypes_to_check\n        }\n        for _rdtype, task in base_query_tasks.items():\n            raw_results, errors = await task\n            if errors and not raw_results:\n                self.debug(f\"Failed to resolve {query} ({_rdtype}) during wildcard detection\")\n                result[_rdtype] = (None, parent)\n                continue\n            for __rdtype, answers in raw_results:\n                base_query_results = set()\n                for answer in answers:\n                    for _, t in self.extract_targets(answer):\n                        base_query_results.add(t)\n                if base_query_results:\n                    base_query_ips[__rdtype] = base_query_results\n    else:\n        # otherwise, we can skip all that\n        cleaned_ips = set([self._clean_dns_record(ip) for ip in ips])\n        if not cleaned_ips:\n            raise ValueError(\"Valid IPs must be specified\")\n        base_query_ips[rdtype] = cleaned_ips\n    if not base_query_ips:\n        return result\n\n    # once we've resolved the base query and have IP addresses to work with\n    # we can compare the IPs to the ones we have on file for wildcards\n\n    # for every parent domain, starting with the shortest\n    try:\n        for host in parents[::-1]:\n            # for every rdtype\n            for _rdtype in list(base_query_ips):\n                # get the IPs from above\n                query_ips = base_query_ips.get(_rdtype, set())\n                # make sure we've checked that domain for wildcards\n                await self.is_wildcard_domain(host)\n                host_hash = hash(host)\n\n                if host_hash in self._wildcard_cache:\n                    # then get its IPs from our wildcard cache\n                    wildcard_rdtypes = self._wildcard_cache[host_hash]\n\n                    # then check to see if our IPs match the wildcard ones\n                    if _rdtype in wildcard_rdtypes:\n                        wildcard_ips = wildcard_rdtypes[_rdtype]\n                        # if our IPs match the wildcard ones, then ladies and gentlemen we have a wildcard\n                        is_wildcard = any(r in wildcard_ips for r in query_ips)\n\n                        if is_wildcard and not result.get(_rdtype, (None, None))[0] is True:\n                            result[_rdtype] = (True, host)\n\n                # if we've reached a point where the dns name is a complete wildcard, class can be dismissed early\n                base_query_rdtypes = set(base_query_ips)\n                wildcard_rdtypes_set = set([k for k, v in result.items() if v[0] is True])\n                if base_query_rdtypes and wildcard_rdtypes_set and base_query_rdtypes == wildcard_rdtypes_set:\n                    log.debug(\n                        f\"Breaking from wildcard detection for {query} at {host} because base query rdtypes ({base_query_rdtypes}) == wildcard rdtypes ({wildcard_rdtypes_set})\"\n                    )\n                    raise DNSWildcardBreak()\n    except DNSWildcardBreak:\n        pass\n\n    return result\n</code></pre>"},{"location":"dev/helpers/dns/#bbot.core.helpers.dns.DNSHelper.is_wildcard_domain","title":"is_wildcard_domain  <code>async</code>","text":"<pre><code>is_wildcard_domain(domain, log_info = False)\n</code></pre> <p>Check whether a given host or its children make use of wildcard DNS entries. Wildcard DNS can have various implications, particularly in subdomain enumeration and subdomain takeovers.</p> <p>Parameters:</p> <ul> <li> <code>domain</code>             (<code>str</code>)         \u2013          <p>The domain to check for wildcard DNS entries.</p> </li> <li> <code>log_info</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to log the result of the check. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>        \u2013          <p>A dictionary where the keys are the parent domains that have wildcard DNS entries,</p> </li> <li>         \u2013          <p>and the values are another dictionary of DNS record types (\"A\", \"AAAA\", etc.) mapped to</p> </li> <li>         \u2013          <p>sets of their resolved IP addresses.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_wildcard_domain(\"github.io\")\n{\"github.io\": {\"A\": {\"1.2.3.4\"}, \"AAAA\": {\"dead::beef\"}}}\n</code></pre> <pre><code>&gt;&gt;&gt; is_wildcard_domain(\"example.com\")\n{}\n</code></pre> Source code in <code>bbot/core/helpers/dns.py</code> <pre><code>async def is_wildcard_domain(self, domain, log_info=False):\n\"\"\"\n    Check whether a given host or its children make use of wildcard DNS entries. Wildcard DNS can have\n    various implications, particularly in subdomain enumeration and subdomain takeovers.\n\n    Args:\n        domain (str): The domain to check for wildcard DNS entries.\n        log_info (bool, optional): Whether to log the result of the check. Defaults to False.\n\n    Returns:\n        dict: A dictionary where the keys are the parent domains that have wildcard DNS entries,\n        and the values are another dictionary of DNS record types (\"A\", \"AAAA\", etc.) mapped to\n        sets of their resolved IP addresses.\n\n    Examples:\n        &gt;&gt;&gt; is_wildcard_domain(\"github.io\")\n        {\"github.io\": {\"A\": {\"1.2.3.4\"}, \"AAAA\": {\"dead::beef\"}}}\n\n        &gt;&gt;&gt; is_wildcard_domain(\"example.com\")\n        {}\n    \"\"\"\n    wildcard_domain_results = {}\n    domain = self._clean_dns_record(domain)\n\n    if not is_dns_name(domain):\n        return {}\n\n    # skip check if the query's parent domain is excluded in the config\n    for d in self.wildcard_ignore:\n        if self.parent_helper.host_in_host(domain, d):\n            log.debug(f\"Skipping wildcard detection on {domain} because it is excluded in the config\")\n            return {}\n\n    rdtypes_to_check = set(self.all_rdtypes)\n\n    # make a list of its parents\n    parents = list(domain_parents(domain, include_self=True))\n    # and check each of them, beginning with the highest parent (i.e. the root domain)\n    for i, host in enumerate(parents[::-1]):\n        # have we checked this host before?\n        host_hash = hash(host)\n        async with self._wildcard_lock.lock(host_hash):\n            # if we've seen this host before\n            if host_hash in self._wildcard_cache:\n                wildcard_domain_results[host] = self._wildcard_cache[host_hash]\n                continue\n\n            # determine if this is a wildcard domain\n            wildcard_tasks = {t: [] for t in rdtypes_to_check}\n            # resolve a bunch of random subdomains of the same parent\n            for rdtype in rdtypes_to_check:\n                # continue if a wildcard was already found for this rdtype\n                # if rdtype in self._wildcard_cache[host_hash]:\n                #     continue\n                for _ in range(self.wildcard_tests):\n                    rand_query = f\"{rand_string(digits=False, length=10)}.{host}\"\n                    wildcard_tasks[rdtype].append(self.resolve(rand_query, type=rdtype, use_cache=False))\n\n            # combine the random results\n            is_wildcard = False\n            wildcard_results = dict()\n            for rdtype, tasks in wildcard_tasks.items():\n                async for task in as_completed(tasks):\n                    results = await task\n                    if results:\n                        is_wildcard = True\n                        if not rdtype in wildcard_results:\n                            wildcard_results[rdtype] = set()\n                        wildcard_results[rdtype].update(results)\n                        # we know this rdtype is a wildcard\n                        # so we don't need to check it anymore\n                        with suppress(KeyError):\n                            rdtypes_to_check.remove(rdtype)\n\n            self._wildcard_cache.update({host_hash: wildcard_results})\n            wildcard_domain_results.update({host: wildcard_results})\n            if is_wildcard:\n                wildcard_rdtypes_str = \",\".join(sorted([t.upper() for t, r in wildcard_results.items() if r]))\n                log_fn = log.verbose\n                if log_info:\n                    log_fn = log.info\n                log_fn(f\"Encountered domain with wildcard DNS ({wildcard_rdtypes_str}): {host}\")\n\n    return wildcard_domain_results\n</code></pre>"},{"location":"dev/helpers/interactsh/","title":"Interact.sh","text":"<p>A pure python implementation of ProjectDiscovery's interact.sh.</p> <p>\"Interactsh is an open-source tool for detecting out-of-band interactions. It is a tool designed to detect vulnerabilities that cause external interactions.\"</p> <ul> <li>https://app.interactsh.com</li> <li>https://github.com/projectdiscovery/interactsh</li> </ul> <p>This class facilitates interactions with the interact.sh service for out-of-band data exfiltration and vulnerability confirmation. It allows for customization by accepting server and token parameters from the configuration provided by <code>parent_helper</code>.</p> <p>Attributes:</p> <ul> <li> <code>parent_helper</code>             (<code>ConfigAwareHelper</code>)         \u2013          <p>An instance of a helper class containing configuration data.</p> </li> <li> <code>server</code>             (<code>str</code>)         \u2013          <p>The server to be used. If None (the default), a random server will be chosen from a predetermined list.</p> </li> <li> <code>correlation_id</code>             (<code>str</code>)         \u2013          <p>An identifier to correlate requests and responses. Default is None.</p> </li> <li> <code>custom_server</code>             (<code>str</code>)         \u2013          <p>Optional. A custom interact.sh server. Loaded from configuration.</p> </li> <li> <code>token</code>             (<code>str</code>)         \u2013          <p>Optional. A token for interact.sh API. Loaded from configuration.</p> </li> <li> <code>_poll_task</code>             (<code>AsyncTask</code>)         \u2013          <p>The task responsible for polling the interact.sh server.</p> </li> </ul> <p>Examples:</p> <pre><code># instantiate interact.sh client (no requests are sent yet)\n&gt;&gt;&gt; interactsh_client = self.helpers.interactsh()\n# register with an interact.sh server\n&gt;&gt;&gt; interactsh_domain = await interactsh_client.register()\n[INFO] Registering with interact.sh server: oast.me\n[INFO] Successfully registered to interactsh server oast.me with correlation_id rg99x2f860h5466ou3so [rg99x2f860h5466ou3so86i07n1m3013k.oast.me]\n# simulate an out-of-band interaction\n&gt;&gt;&gt; await self.helpers.request(f\"https://{interactsh_domain}/test\")\n# wait for out-of-band interaction to be registered\n&gt;&gt;&gt; await asyncio.sleep(10)\n&gt;&gt;&gt; data_list = await interactsh_client.poll()\n&gt;&gt;&gt; print(data_list)\n[\n    {\n        \"protocol\": \"dns\",\n        \"unique-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n        \"full-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n        \"q-type\": \"A\",\n        \"raw-request\": \"...\",\n        \"remote-address\": \"1.2.3.4\",\n        \"timestamp\": \"2023-09-15T21:09:23.187226851Z\"\n    },\n    {\n        \"protocol\": \"http\",\n        \"unique-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n        \"full-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n        \"raw-request\": \"GET /test HTTP/1.1 ...\",\n        \"remote-address\": \"1.2.3.4\",\n        \"timestamp\": \"2023-09-15T21:09:24.155677967Z\"\n    }\n]\n# finally, shut down the client\n&gt;&gt;&gt; await interactsh_client.deregister()\n</code></pre> Source code in <code>bbot/core/helpers/interactsh.py</code> <pre><code>class Interactsh:\n\"\"\"\n    A pure python implementation of ProjectDiscovery's interact.sh.\n\n    *\"Interactsh is an open-source tool for detecting out-of-band interactions. It is a tool designed to detect vulnerabilities that cause external interactions.\"*\n\n    - https://app.interactsh.com\n    - https://github.com/projectdiscovery/interactsh\n\n    This class facilitates interactions with the interact.sh service for\n    out-of-band data exfiltration and vulnerability confirmation. It allows\n    for customization by accepting server and token parameters from the\n    configuration provided by `parent_helper`.\n\n    Attributes:\n        parent_helper (ConfigAwareHelper): An instance of a helper class containing configuration data.\n        server (str): The server to be used. If None (the default), a random server will be chosen from a predetermined list.\n        correlation_id (str): An identifier to correlate requests and responses. Default is None.\n        custom_server (str): Optional. A custom interact.sh server. Loaded from configuration.\n        token (str): Optional. A token for interact.sh API. Loaded from configuration.\n        _poll_task (AsyncTask): The task responsible for polling the interact.sh server.\n\n    Examples:\n        ```python\n        # instantiate interact.sh client (no requests are sent yet)\n        &gt;&gt;&gt; interactsh_client = self.helpers.interactsh()\n        # register with an interact.sh server\n        &gt;&gt;&gt; interactsh_domain = await interactsh_client.register()\n        [INFO] Registering with interact.sh server: oast.me\n        [INFO] Successfully registered to interactsh server oast.me with correlation_id rg99x2f860h5466ou3so [rg99x2f860h5466ou3so86i07n1m3013k.oast.me]\n        # simulate an out-of-band interaction\n        &gt;&gt;&gt; await self.helpers.request(f\"https://{interactsh_domain}/test\")\n        # wait for out-of-band interaction to be registered\n        &gt;&gt;&gt; await asyncio.sleep(10)\n        &gt;&gt;&gt; data_list = await interactsh_client.poll()\n        &gt;&gt;&gt; print(data_list)\n        [\n            {\n                \"protocol\": \"dns\",\n                \"unique-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n                \"full-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n                \"q-type\": \"A\",\n                \"raw-request\": \"...\",\n                \"remote-address\": \"1.2.3.4\",\n                \"timestamp\": \"2023-09-15T21:09:23.187226851Z\"\n            },\n            {\n                \"protocol\": \"http\",\n                \"unique-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n                \"full-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n                \"raw-request\": \"GET /test HTTP/1.1 ...\",\n                \"remote-address\": \"1.2.3.4\",\n                \"timestamp\": \"2023-09-15T21:09:24.155677967Z\"\n            }\n        ]\n        # finally, shut down the client\n        &gt;&gt;&gt; await interactsh_client.deregister()\n        ```\n    \"\"\"\n\n    def __init__(self, parent_helper):\n        self.parent_helper = parent_helper\n        self.server = None\n        self.correlation_id = None\n        self.custom_server = self.parent_helper.config.get(\"interactsh_server\", None)\n        self.token = self.parent_helper.config.get(\"interactsh_token\", None)\n        self._poll_task = None\n\n    async def register(self, callback=None):\n\"\"\"\n        Registers the instance with an interact.sh server and sets up polling.\n\n        Generates RSA keys for secure communication, builds a correlation ID,\n        and sends a POST request to an interact.sh server to register. Optionally,\n        starts an asynchronous polling task to listen for interactions.\n\n        Args:\n            callback (callable, optional): A function to be called each time new interactions are received.\n\n        Returns:\n            str: The registered domain for out-of-band interactions.\n\n        Raises:\n            InteractshError: If registration with an interact.sh server fails.\n\n        Examples:\n            &gt;&gt;&gt; interactsh_client = self.helpers.interactsh()\n            &gt;&gt;&gt; registered_domain = await interactsh_client.register()\n            [INFO] Registering with interact.sh server: oast.me\n            [INFO] Successfully registered to interactsh server oast.me with correlation_id rg99x2f860h5466ou3so [rg99x2f860h5466ou3so86i07n1m3013k.oast.me]\n        \"\"\"\n        rsa = RSA.generate(1024)\n\n        self.public_key = rsa.publickey().exportKey()\n        self.private_key = rsa.exportKey()\n\n        encoded_public_key = base64.b64encode(self.public_key).decode(\"utf8\")\n\n        uuid = uuid4().hex.ljust(33, \"a\")\n        guid = \"\".join(i if i.isdigit() else chr(ord(i) + random.randint(0, 20)) for i in uuid)\n\n        self.correlation_id = guid[:20]\n        self.secret = str(uuid4())\n        headers = {}\n\n        if self.custom_server:\n            if not self.token:\n                log.verbose(\"Interact.sh token is not set\")\n            headers[\"Authorization\"] = self.token\n            self.server_list = [self.custom_server]\n        else:\n            self.server_list = random.sample(server_list, k=len(server_list))\n        for server in self.server_list:\n            log.info(f\"Registering with interact.sh server: {server}\")\n            data = {\n                \"public-key\": encoded_public_key,\n                \"secret-key\": self.secret,\n                \"correlation-id\": self.correlation_id,\n            }\n            r = await self.parent_helper.request(\n                f\"https://{server}/register\", headers=headers, json=data, method=\"POST\"\n            )\n            if r is None:\n                continue\n            try:\n                msg = r.json().get(\"message\", \"\")\n                assert \"registration successful\" in msg\n            except Exception:\n                log.debug(f\"Failed to register with interactsh server {self.server}\")\n                continue\n            self.server = server\n            self.domain = f\"{guid}.{self.server}\"\n            break\n\n        if not self.server:\n            raise InteractshError(f\"Failed to register with an interactsh server\")\n\n        log.info(\n            f\"Successfully registered to interactsh server {self.server} with correlation_id {self.correlation_id} [{self.domain}]\"\n        )\n\n        if callable(callback):\n            self._poll_task = asyncio.create_task(self.poll_loop(callback))\n\n        return self.domain\n\n    async def deregister(self):\n\"\"\"\n        Deregisters the instance from the interact.sh server and cancels the polling task.\n\n        Sends a POST request to the server to deregister, using the correlation ID\n        and secret key generated during registration. Optionally, if a polling\n        task was started, it is cancelled.\n\n        Raises:\n            InteractshError: If required information is missing or if deregistration fails.\n\n        Examples:\n            &gt;&gt;&gt; await interactsh_client.deregister()\n        \"\"\"\n        if not self.server or not self.correlation_id or not self.secret:\n            raise InteractshError(f\"Missing required information to deregister\")\n\n        headers = {}\n        if self.token:\n            headers[\"Authorization\"] = self.token\n\n        data = {\"secret-key\": self.secret, \"correlation-id\": self.correlation_id}\n\n        r = await self.parent_helper.request(\n            f\"https://{self.server}/deregister\", headers=headers, json=data, method=\"POST\"\n        )\n\n        if self._poll_task is not None:\n            self._poll_task.cancel()\n\n        if \"success\" not in getattr(r, \"text\", \"\"):\n            raise InteractshError(f\"Failed to de-register with interactsh server {self.server}\")\n\n    async def poll(self):\n\"\"\"\n        Polls the interact.sh server for interactions tied to the current instance.\n\n        Sends a GET request to the server to fetch interactions associated with the\n        current correlation_id and secret key. Returned interactions are decrypted\n        using an AES key provided by the server response.\n\n        Raises:\n            InteractshError: If required information for polling is missing.\n\n        Returns:\n            list: A list of decrypted interaction data dictionaries.\n\n        Examples:\n            &gt;&gt;&gt; data_list = await interactsh_client.poll()\n            &gt;&gt;&gt; print(data_list)\n            [\n                {\n                    \"protocol\": \"dns\",\n                    \"unique-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n                    ...\n                },\n                ...\n            ]\n        \"\"\"\n        if not self.server or not self.correlation_id or not self.secret:\n            raise InteractshError(f\"Missing required information to poll\")\n\n        headers = {}\n        if self.token:\n            headers[\"Authorization\"] = self.token\n\n        r = await self.parent_helper.request(\n            f\"https://{self.server}/poll?id={self.correlation_id}&amp;secret={self.secret}\", headers=headers\n        )\n\n        ret = []\n        data_list = r.json().get(\"data\", None)\n        if data_list:\n            aes_key = r.json()[\"aes_key\"]\n\n            for data in data_list:\n                decrypted_data = self._decrypt(aes_key, data)\n                ret.append(decrypted_data)\n        return ret\n\n    async def poll_loop(self, callback):\n\"\"\"\n        Starts a polling loop to continuously check for interactions with the interact.sh server.\n\n        Continuously polls the interact.sh server for interactions tied to the current instance,\n        using the `poll` method. When interactions are received, it executes the given callback\n        function with each interaction data.\n\n        Parameters:\n            callback (callable): The function to be called for every interaction received from the server.\n\n        Returns:\n            awaitable: An awaitable object that executes the internal `_poll_loop` method.\n\n        Examples:\n            &gt;&gt;&gt; await interactsh_client.poll_loop(my_callback)\n        \"\"\"\n        async with self.parent_helper.scan._acatch(context=self._poll_loop):\n            return await self._poll_loop(callback)\n\n    async def _poll_loop(self, callback):\n        while 1:\n            if self.parent_helper.scan.stopping:\n                await asyncio.sleep(1)\n                continue\n            data_list = []\n            try:\n                data_list = await self.poll()\n            except InteractshError as e:\n                log.warning(e)\n                log.trace(traceback.format_exc())\n            if not data_list:\n                await asyncio.sleep(10)\n                continue\n            for data in data_list:\n                if data:\n                    await self.parent_helper.execute_sync_or_async(callback, data)\n\n    def _decrypt(self, aes_key, data):\n\"\"\"\n        Decrypts and returns the data received from the interact.sh server.\n\n        Uses RSA and AES for decrypting the data. RSA with PKCS1_OAEP and SHA256 is used to decrypt the AES key,\n        and then AES (CFB mode) is used to decrypt the actual data payload.\n\n        Parameters:\n            aes_key (str): The AES key for decryption, encrypted with RSA and base64 encoded.\n            data (str): The data payload to decrypt, which is base64 encoded and AES encrypted.\n\n        Returns:\n            dict: The decrypted data, loaded as a JSON object.\n\n        Examples:\n            &gt;&gt;&gt; decrypted_data = self._decrypt(aes_key, data)\n        \"\"\"\n        private_key = RSA.importKey(self.private_key)\n        cipher = PKCS1_OAEP.new(private_key, hashAlgo=SHA256)\n        aes_plain_key = cipher.decrypt(base64.b64decode(aes_key))\n        decode = base64.b64decode(data)\n        bs = AES.block_size\n        iv = decode[:bs]\n        cryptor = AES.new(key=aes_plain_key, mode=AES.MODE_CFB, IV=iv, segment_size=128)\n        plain_text = cryptor.decrypt(decode)\n        return json.loads(plain_text[16:])\n</code></pre>"},{"location":"dev/helpers/interactsh/#bbot.core.helpers.interactsh.Interactsh.deregister","title":"deregister  <code>async</code>","text":"<pre><code>deregister()\n</code></pre> <p>Deregisters the instance from the interact.sh server and cancels the polling task.</p> <p>Sends a POST request to the server to deregister, using the correlation ID and secret key generated during registration. Optionally, if a polling task was started, it is cancelled.</p> <p>Raises:</p> <ul> <li> <code>InteractshError</code>           \u2013          <p>If required information is missing or if deregistration fails.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await interactsh_client.deregister()\n</code></pre> Source code in <code>bbot/core/helpers/interactsh.py</code> <pre><code>async def deregister(self):\n\"\"\"\n    Deregisters the instance from the interact.sh server and cancels the polling task.\n\n    Sends a POST request to the server to deregister, using the correlation ID\n    and secret key generated during registration. Optionally, if a polling\n    task was started, it is cancelled.\n\n    Raises:\n        InteractshError: If required information is missing or if deregistration fails.\n\n    Examples:\n        &gt;&gt;&gt; await interactsh_client.deregister()\n    \"\"\"\n    if not self.server or not self.correlation_id or not self.secret:\n        raise InteractshError(f\"Missing required information to deregister\")\n\n    headers = {}\n    if self.token:\n        headers[\"Authorization\"] = self.token\n\n    data = {\"secret-key\": self.secret, \"correlation-id\": self.correlation_id}\n\n    r = await self.parent_helper.request(\n        f\"https://{self.server}/deregister\", headers=headers, json=data, method=\"POST\"\n    )\n\n    if self._poll_task is not None:\n        self._poll_task.cancel()\n\n    if \"success\" not in getattr(r, \"text\", \"\"):\n        raise InteractshError(f\"Failed to de-register with interactsh server {self.server}\")\n</code></pre>"},{"location":"dev/helpers/interactsh/#bbot.core.helpers.interactsh.Interactsh.poll","title":"poll  <code>async</code>","text":"<pre><code>poll()\n</code></pre> <p>Polls the interact.sh server for interactions tied to the current instance.</p> <p>Sends a GET request to the server to fetch interactions associated with the current correlation_id and secret key. Returned interactions are decrypted using an AES key provided by the server response.</p> <p>Raises:</p> <ul> <li> <code>InteractshError</code>           \u2013          <p>If required information for polling is missing.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>        \u2013          <p>A list of decrypted interaction data dictionaries.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data_list = await interactsh_client.poll()\n&gt;&gt;&gt; print(data_list)\n[\n    {\n        \"protocol\": \"dns\",\n        \"unique-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n        ...\n    },\n    ...\n]\n</code></pre> Source code in <code>bbot/core/helpers/interactsh.py</code> <pre><code>async def poll(self):\n\"\"\"\n    Polls the interact.sh server for interactions tied to the current instance.\n\n    Sends a GET request to the server to fetch interactions associated with the\n    current correlation_id and secret key. Returned interactions are decrypted\n    using an AES key provided by the server response.\n\n    Raises:\n        InteractshError: If required information for polling is missing.\n\n    Returns:\n        list: A list of decrypted interaction data dictionaries.\n\n    Examples:\n        &gt;&gt;&gt; data_list = await interactsh_client.poll()\n        &gt;&gt;&gt; print(data_list)\n        [\n            {\n                \"protocol\": \"dns\",\n                \"unique-id\": \"rg99x2f860h5466ou3so86i07n1m3013k\",\n                ...\n            },\n            ...\n        ]\n    \"\"\"\n    if not self.server or not self.correlation_id or not self.secret:\n        raise InteractshError(f\"Missing required information to poll\")\n\n    headers = {}\n    if self.token:\n        headers[\"Authorization\"] = self.token\n\n    r = await self.parent_helper.request(\n        f\"https://{self.server}/poll?id={self.correlation_id}&amp;secret={self.secret}\", headers=headers\n    )\n\n    ret = []\n    data_list = r.json().get(\"data\", None)\n    if data_list:\n        aes_key = r.json()[\"aes_key\"]\n\n        for data in data_list:\n            decrypted_data = self._decrypt(aes_key, data)\n            ret.append(decrypted_data)\n    return ret\n</code></pre>"},{"location":"dev/helpers/interactsh/#bbot.core.helpers.interactsh.Interactsh.poll_loop","title":"poll_loop  <code>async</code>","text":"<pre><code>poll_loop(callback)\n</code></pre> <p>Starts a polling loop to continuously check for interactions with the interact.sh server.</p> <p>Continuously polls the interact.sh server for interactions tied to the current instance, using the <code>poll</code> method. When interactions are received, it executes the given callback function with each interaction data.</p> <p>Parameters:</p> <ul> <li> <code>callback</code>             (<code>callable</code>)         \u2013          <p>The function to be called for every interaction received from the server.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>awaitable</code>        \u2013          <p>An awaitable object that executes the internal <code>_poll_loop</code> method.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await interactsh_client.poll_loop(my_callback)\n</code></pre> Source code in <code>bbot/core/helpers/interactsh.py</code> <pre><code>async def poll_loop(self, callback):\n\"\"\"\n    Starts a polling loop to continuously check for interactions with the interact.sh server.\n\n    Continuously polls the interact.sh server for interactions tied to the current instance,\n    using the `poll` method. When interactions are received, it executes the given callback\n    function with each interaction data.\n\n    Parameters:\n        callback (callable): The function to be called for every interaction received from the server.\n\n    Returns:\n        awaitable: An awaitable object that executes the internal `_poll_loop` method.\n\n    Examples:\n        &gt;&gt;&gt; await interactsh_client.poll_loop(my_callback)\n    \"\"\"\n    async with self.parent_helper.scan._acatch(context=self._poll_loop):\n        return await self._poll_loop(callback)\n</code></pre>"},{"location":"dev/helpers/interactsh/#bbot.core.helpers.interactsh.Interactsh.register","title":"register  <code>async</code>","text":"<pre><code>register(callback = None)\n</code></pre> <p>Registers the instance with an interact.sh server and sets up polling.</p> <p>Generates RSA keys for secure communication, builds a correlation ID, and sends a POST request to an interact.sh server to register. Optionally, starts an asynchronous polling task to listen for interactions.</p> <p>Parameters:</p> <ul> <li> <code>callback</code>             (<code>callable</code>, default:                 <code>None</code> )         \u2013          <p>A function to be called each time new interactions are received.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>The registered domain for out-of-band interactions.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>InteractshError</code>           \u2013          <p>If registration with an interact.sh server fails.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; interactsh_client = self.helpers.interactsh()\n&gt;&gt;&gt; registered_domain = await interactsh_client.register()\n[INFO] Registering with interact.sh server: oast.me\n[INFO] Successfully registered to interactsh server oast.me with correlation_id rg99x2f860h5466ou3so [rg99x2f860h5466ou3so86i07n1m3013k.oast.me]\n</code></pre> Source code in <code>bbot/core/helpers/interactsh.py</code> <pre><code>async def register(self, callback=None):\n\"\"\"\n    Registers the instance with an interact.sh server and sets up polling.\n\n    Generates RSA keys for secure communication, builds a correlation ID,\n    and sends a POST request to an interact.sh server to register. Optionally,\n    starts an asynchronous polling task to listen for interactions.\n\n    Args:\n        callback (callable, optional): A function to be called each time new interactions are received.\n\n    Returns:\n        str: The registered domain for out-of-band interactions.\n\n    Raises:\n        InteractshError: If registration with an interact.sh server fails.\n\n    Examples:\n        &gt;&gt;&gt; interactsh_client = self.helpers.interactsh()\n        &gt;&gt;&gt; registered_domain = await interactsh_client.register()\n        [INFO] Registering with interact.sh server: oast.me\n        [INFO] Successfully registered to interactsh server oast.me with correlation_id rg99x2f860h5466ou3so [rg99x2f860h5466ou3so86i07n1m3013k.oast.me]\n    \"\"\"\n    rsa = RSA.generate(1024)\n\n    self.public_key = rsa.publickey().exportKey()\n    self.private_key = rsa.exportKey()\n\n    encoded_public_key = base64.b64encode(self.public_key).decode(\"utf8\")\n\n    uuid = uuid4().hex.ljust(33, \"a\")\n    guid = \"\".join(i if i.isdigit() else chr(ord(i) + random.randint(0, 20)) for i in uuid)\n\n    self.correlation_id = guid[:20]\n    self.secret = str(uuid4())\n    headers = {}\n\n    if self.custom_server:\n        if not self.token:\n            log.verbose(\"Interact.sh token is not set\")\n        headers[\"Authorization\"] = self.token\n        self.server_list = [self.custom_server]\n    else:\n        self.server_list = random.sample(server_list, k=len(server_list))\n    for server in self.server_list:\n        log.info(f\"Registering with interact.sh server: {server}\")\n        data = {\n            \"public-key\": encoded_public_key,\n            \"secret-key\": self.secret,\n            \"correlation-id\": self.correlation_id,\n        }\n        r = await self.parent_helper.request(\n            f\"https://{server}/register\", headers=headers, json=data, method=\"POST\"\n        )\n        if r is None:\n            continue\n        try:\n            msg = r.json().get(\"message\", \"\")\n            assert \"registration successful\" in msg\n        except Exception:\n            log.debug(f\"Failed to register with interactsh server {self.server}\")\n            continue\n        self.server = server\n        self.domain = f\"{guid}.{self.server}\"\n        break\n\n    if not self.server:\n        raise InteractshError(f\"Failed to register with an interactsh server\")\n\n    log.info(\n        f\"Successfully registered to interactsh server {self.server} with correlation_id {self.correlation_id} [{self.domain}]\"\n    )\n\n    if callable(callback):\n        self._poll_task = asyncio.create_task(self.poll_loop(callback))\n\n    return self.domain\n</code></pre>"},{"location":"dev/helpers/misc/","title":"Misc Helpers","text":"<p>These are miscellaneous helpers, used throughout BBOT and its modules for simple tasks such as parsing domains, ports, urls, etc.</p>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.as_completed","title":"as_completed  <code>async</code>","text":"<pre><code>as_completed(coros)\n</code></pre> <p>Async generator that yields completed Tasks as they are completed.</p> <p>Parameters:</p> <ul> <li> <code>coros</code>             (<code>iterable</code>)         \u2013          <p>An iterable of coroutine objects or asyncio Tasks.</p> </li> </ul> <p>Yields:</p> <ul> <li>         \u2013          <p>asyncio.Task: A Task object that has completed its execution.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; async def main():\n...     async for task in as_completed([coro1(), coro2(), coro3()]):\n...         result = task.result()\n...         print(f'Task completed with result: {result}')\n</code></pre> <pre><code>&gt;&gt;&gt; asyncio.run(main())\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>async def as_completed(coros):\n\"\"\"\n    Async generator that yields completed Tasks as they are completed.\n\n    Args:\n        coros (iterable): An iterable of coroutine objects or asyncio Tasks.\n\n    Yields:\n        asyncio.Task: A Task object that has completed its execution.\n\n    Examples:\n        &gt;&gt;&gt; async def main():\n        ...     async for task in as_completed([coro1(), coro2(), coro3()]):\n        ...         result = task.result()\n        ...         print(f'Task completed with result: {result}')\n\n        &gt;&gt;&gt; asyncio.run(main())\n    \"\"\"\n    tasks = {coro if isinstance(coro, asyncio.Task) else asyncio.create_task(coro): coro for coro in coros}\n    while tasks:\n        done, _ = await asyncio.wait(tasks.keys(), return_when=asyncio.FIRST_COMPLETED)\n        for task in done:\n            tasks.pop(task)\n            yield task\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.backup_file","title":"backup_file","text":"<pre><code>backup_file(filename, max_backups = 10)\n</code></pre> <p>Renames a file by appending an iteration number as a backup. Recursively renames files up to a specified maximum number of backups.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>             (<code>str or Path</code>)         \u2013          <p>The file to backup.</p> </li> <li> <code>max_backups</code>             (<code>int</code>, default:                 <code>10</code> )         \u2013          <p>The maximum number of backups to keep. Defaults to 10.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>pathlib.Path: The new backup filepath.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; backup_file(\"/tmp/test.txt\")\nPosixPath(\"/tmp/test.0.txt\")\n&gt;&gt;&gt; backup_file(\"/tmp/test.0.txt\")\nPosixPath(\"/tmp/test.1.txt\")\n&gt;&gt;&gt; backup_file(\"/tmp/test.1.txt\")\nPosixPath(\"/tmp/test.2.txt\")\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def backup_file(filename, max_backups=10):\n\"\"\"\n    Renames a file by appending an iteration number as a backup. Recursively renames\n    files up to a specified maximum number of backups.\n\n    Args:\n        filename (str or pathlib.Path): The file to backup.\n        max_backups (int, optional): The maximum number of backups to keep. Defaults to 10.\n\n    Returns:\n        pathlib.Path: The new backup filepath.\n\n    Examples:\n        &gt;&gt;&gt; backup_file(\"/tmp/test.txt\")\n        PosixPath(\"/tmp/test.0.txt\")\n        &gt;&gt;&gt; backup_file(\"/tmp/test.0.txt\")\n        PosixPath(\"/tmp/test.1.txt\")\n        &gt;&gt;&gt; backup_file(\"/tmp/test.1.txt\")\n        PosixPath(\"/tmp/test.2.txt\")\n    \"\"\"\n    filename = Path(filename).resolve()\n    suffixes = [s.strip(\".\") for s in filename.suffixes]\n    iteration = 1\n    with suppress(Exception):\n        iteration = min(max_backups - 1, max(0, int(suffixes[0]))) + 1\n        suffixes = suffixes[1:]\n    stem = filename.stem.split(\".\")[0]\n    destination = filename.parent / f\"{stem}.{iteration}.{'.'.join(suffixes)}\"\n    if destination.exists() and iteration &lt; max_backups:\n        backup_file(destination)\n    if filename.exists():\n        filename.rename(destination)\n    return destination\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.bytes_to_human","title":"bytes_to_human","text":"<pre><code>bytes_to_human(_bytes)\n</code></pre> <p>Convert a bytes size to a human-readable string.</p> <p>This function converts a numeric bytes value into a human-readable string format, complete with the appropriate unit symbol (B, KB, MB, GB, etc.).</p> <p>Parameters:</p> <ul> <li> <code>_bytes</code>             (<code>int</code>)         \u2013          <p>The number of bytes to convert.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>A string representing the number of bytes in a more readable format, rounded to two  decimal places.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bytes_to_human(1234129384)\n'1.15GB'\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def bytes_to_human(_bytes):\n\"\"\"Convert a bytes size to a human-readable string.\n\n    This function converts a numeric bytes value into a human-readable string format, complete\n    with the appropriate unit symbol (B, KB, MB, GB, etc.).\n\n    Args:\n        _bytes (int): The number of bytes to convert.\n\n    Returns:\n        str: A string representing the number of bytes in a more readable format, rounded to two\n             decimal places.\n\n    Examples:\n        &gt;&gt;&gt; bytes_to_human(1234129384)\n        '1.15GB'\n    \"\"\"\n    sizes = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\"]\n    units = {}\n    for count, size in enumerate(sizes):\n        units[size] = pow(1024, count)\n    for size in sizes:\n        if abs(_bytes) &lt; 1024.0:\n            if size == sizes[0]:\n                _bytes = str(int(_bytes))\n            else:\n                _bytes = f\"{_bytes:.2f}\"\n            return f\"{_bytes}{size}\"\n        _bytes /= 1024\n    raise ValueError(f'Unable to convert \"{_bytes}\" to human filesize')\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.can_sudo_without_password","title":"can_sudo_without_password","text":"<pre><code>can_sudo_without_password()\n</code></pre> <p>Check if the current user has passwordless sudo access.</p> <p>This function checks whether the current user can use sudo without entering a password. It runs a command with sudo and checks the return code to determine this.</p> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the current user can use sudo without a password, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; can_sudo_without_password()\nTrue\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def can_sudo_without_password():\n\"\"\"Check if the current user has passwordless sudo access.\n\n    This function checks whether the current user can use sudo without entering a password.\n    It runs a command with sudo and checks the return code to determine this.\n\n    Returns:\n        bool: True if the current user can use sudo without a password, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; can_sudo_without_password()\n        True\n    \"\"\"\n    if os.geteuid() != 0:\n        env = dict(os.environ)\n        env[\"SUDO_ASKPASS\"] = \"/bin/false\"\n        try:\n            sp.run([\"sudo\", \"-K\"], stderr=sp.DEVNULL, stdout=sp.DEVNULL, check=True, env=env)\n            sp.run([\"sudo\", \"-An\", \"/bin/true\"], stderr=sp.DEVNULL, stdout=sp.DEVNULL, check=True, env=env)\n        except sp.CalledProcessError:\n            return False\n    return True\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.cancel_tasks","title":"cancel_tasks  <code>async</code>","text":"<pre><code>cancel_tasks(tasks, ignore_errors = True)\n</code></pre> <p>Asynchronously cancels a list of asyncio tasks.</p> <p>Parameters:</p> <ul> <li> <code>tasks</code>             (<code>list[Task]</code>)         \u2013          <p>A list of asyncio Task objects to cancel.</p> </li> <li> <code>ignore_errors</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to ignore errors other than asyncio.CancelledError. Defaults to True.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; async def main():\n...     task1 = asyncio.create_task(async_function1())\n...     task2 = asyncio.create_task(async_function2())\n...     await cancel_tasks([task1, task2])\n...\n&gt;&gt;&gt; asyncio.run(main())\n</code></pre> Note <p>This function will not cancel the current task that it is called from.</p> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>async def cancel_tasks(tasks, ignore_errors=True):\n\"\"\"\n    Asynchronously cancels a list of asyncio tasks.\n\n    Args:\n        tasks (list[Task]): A list of asyncio Task objects to cancel.\n        ignore_errors (bool, optional): Whether to ignore errors other than asyncio.CancelledError. Defaults to True.\n\n    Examples:\n        &gt;&gt;&gt; async def main():\n        ...     task1 = asyncio.create_task(async_function1())\n        ...     task2 = asyncio.create_task(async_function2())\n        ...     await cancel_tasks([task1, task2])\n        ...\n        &gt;&gt;&gt; asyncio.run(main())\n\n    Note:\n        This function will not cancel the current task that it is called from.\n    \"\"\"\n    current_task = asyncio.current_task()\n    tasks = [t for t in tasks if t != current_task]\n    for task in tasks:\n        log.debug(f\"Cancelling task: {task}\")\n        task.cancel()\n    if ignore_errors:\n        for task in tasks:\n            try:\n                await task\n            except BaseException as e:\n                if not isinstance(e, asyncio.CancelledError):\n                    log.trace(traceback.format_exc())\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.cancel_tasks_sync","title":"cancel_tasks_sync","text":"<pre><code>cancel_tasks_sync(tasks)\n</code></pre> <p>Synchronously cancels a list of asyncio tasks.</p> <p>Parameters:</p> <ul> <li> <code>tasks</code>             (<code>list[Task]</code>)         \u2013          <p>A list of asyncio Task objects to cancel.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; loop = asyncio.get_event_loop()\n&gt;&gt;&gt; task1 = loop.create_task(some_async_function1())\n&gt;&gt;&gt; task2 = loop.create_task(some_async_function2())\n&gt;&gt;&gt; cancel_tasks_sync([task1, task2])\n</code></pre> Note <p>This function will not cancel the current task from which it is called.</p> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def cancel_tasks_sync(tasks):\n\"\"\"\n    Synchronously cancels a list of asyncio tasks.\n\n    Args:\n        tasks (list[Task]): A list of asyncio Task objects to cancel.\n\n    Examples:\n        &gt;&gt;&gt; loop = asyncio.get_event_loop()\n        &gt;&gt;&gt; task1 = loop.create_task(some_async_function1())\n        &gt;&gt;&gt; task2 = loop.create_task(some_async_function2())\n        &gt;&gt;&gt; cancel_tasks_sync([task1, task2])\n\n    Note:\n        This function will not cancel the current task from which it is called.\n    \"\"\"\n    current_task = asyncio.current_task()\n    for task in tasks:\n        if task != current_task:\n            log.debug(f\"Cancelling task: {task}\")\n            task.cancel()\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.chain_lists","title":"chain_lists","text":"<pre><code>chain_lists(l, try_files = False, msg = None, remove_blank = True)\n</code></pre> <p>Chains together list elements, allowing for entries separated by commas.</p> <p>This function takes a list <code>l</code> and flattens it by splitting its entries on commas. It also allows you to optionally open entries as files and add their contents to the list.</p> <p>Parameters:</p> <ul> <li> <code>l</code>             (<code>list</code>)         \u2013          <p>The list of strings to chain together.</p> </li> <li> <code>try_files</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to try to open entries as files. Defaults to False.</p> </li> <li> <code>msg</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>An optional message to log when reading from a file. Defaults to None.</p> </li> <li> <code>remove_blank</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to remove blank entries from the list. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>        \u2013          <p>The list of chained elements.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; chain_lists([\"a\", \"b,c,d\"])\n['a', 'b', 'c', 'd']\n</code></pre> <pre><code>&gt;&gt;&gt; chain_lists([\"a,file.txt\", \"c,d\"], try_files=True)\n['a', 'f_line1', 'f_line2', 'f_line3', 'c', 'd']\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def chain_lists(l, try_files=False, msg=None, remove_blank=True):\n\"\"\"Chains together list elements, allowing for entries separated by commas.\n\n    This function takes a list `l` and flattens it by splitting its entries on commas.\n    It also allows you to optionally open entries as files and add their contents to the list.\n\n    Args:\n        l (list): The list of strings to chain together.\n        try_files (bool, optional): Whether to try to open entries as files. Defaults to False.\n        msg (str, optional): An optional message to log when reading from a file. Defaults to None.\n        remove_blank (bool, optional): Whether to remove blank entries from the list. Defaults to True.\n\n    Returns:\n        list: The list of chained elements.\n\n    Examples:\n        &gt;&gt;&gt; chain_lists([\"a\", \"b,c,d\"])\n        ['a', 'b', 'c', 'd']\n\n        &gt;&gt;&gt; chain_lists([\"a,file.txt\", \"c,d\"], try_files=True)\n        ['a', 'f_line1', 'f_line2', 'f_line3', 'c', 'd']\n    \"\"\"\n    final_list = dict()\n    for entry in l:\n        for s in entry.split(\",\"):\n            f = s.strip()\n            f_path = Path(f).resolve()\n            if try_files and f_path.is_file():\n                if msg is not None:\n                    new_msg = str(msg).format(filename=f_path)\n                    log.info(new_msg)\n                for line in str_or_file(f):\n                    final_list[line] = None\n            else:\n                final_list[f] = None\n\n    ret = list(final_list)\n    if remove_blank:\n        ret = [r for r in ret if r]\n    return ret\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.clean_dict","title":"clean_dict","text":"<pre><code>clean_dict(d, *key_names, fuzzy = False, exclude_keys = None, _prev_key = None)\n</code></pre> <p>Recursively clean unwanted keys from a dictionary. Useful for removing secrets from a config.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>dict</code>)         \u2013          <p>The input dictionary.</p> </li> <li> <code>*key_names</code>         \u2013          <p>Names of keys to remove.</p> </li> <li> <code>fuzzy</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to perform fuzzy matching on keys.</p> </li> <li> <code>exclude_keys</code>             (<code>(list, None)</code>, default:                 <code>None</code> )         \u2013          <p>List of keys to be excluded from removal.</p> </li> <li> <code>_prev_key</code>             (<code>(str, None)</code>, default:                 <code>None</code> )         \u2013          <p>For internal recursive use; the previous key in the hierarchy.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>        \u2013          <p>A dictionary cleaned of the keys specified in key_names.</p> </li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def clean_dict(d, *key_names, fuzzy=False, exclude_keys=None, _prev_key=None):\n\"\"\"\n    Recursively clean unwanted keys from a dictionary.\n    Useful for removing secrets from a config.\n\n    Args:\n        d (dict): The input dictionary.\n        *key_names: Names of keys to remove.\n        fuzzy (bool): Whether to perform fuzzy matching on keys.\n        exclude_keys (list, None): List of keys to be excluded from removal.\n        _prev_key (str, None): For internal recursive use; the previous key in the hierarchy.\n\n    Returns:\n        dict: A dictionary cleaned of the keys specified in key_names.\n\n    \"\"\"\n    if exclude_keys is None:\n        exclude_keys = []\n    if isinstance(exclude_keys, str):\n        exclude_keys = [exclude_keys]\n    d = copy.deepcopy(d)\n    if isinstance(d, dict):\n        for key, val in list(d.items()):\n            if key in key_names or (fuzzy and any(k in key for k in key_names)):\n                if _prev_key not in exclude_keys:\n                    d.pop(key)\n            else:\n                d[key] = clean_dict(val, *key_names, fuzzy=fuzzy, _prev_key=key, exclude_keys=exclude_keys)\n    return d\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.clean_old","title":"clean_old","text":"<pre><code>clean_old(d, keep = 10, filter = lambda : True, key = latest_mtime, reverse = True, raise_error = False)\n</code></pre> <p>Clean up old files and directories within a given directory based on various filtering and sorting options.</p> <p>This function removes the oldest files and directories in the provided directory 'd' that exceed a specified threshold ('keep'). The items to be deleted can be filtered using a lambda function 'filter', and they are sorted by a key function, defaulting to latest modification time.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>str or Path</code>)         \u2013          <p>The directory path to clean up.</p> </li> <li> <code>keep</code>             (<code>int</code>, default:                 <code>10</code> )         \u2013          <p>The number of items to keep. Ones beyond this count will be removed.</p> </li> <li> <code>filter</code>             (<code>Callable</code>, default:                 <code>lambda : True</code> )         \u2013          <p>A lambda function for filtering which files or directories to consider.                Defaults to a lambda function that returns True for all.</p> </li> <li> <code>key</code>             (<code>Callable</code>, default:                 <code>latest_mtime</code> )         \u2013          <p>A function to sort the files and directories. Defaults to latest modification time.</p> </li> <li> <code>reverse</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to reverse the order of sorted items before removing. Defaults to True.</p> </li> <li> <code>raise_error</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to raise an error if directory deletion fails. Defaults to False.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; clean_old(\"~/.bbot/scans\", filter=lambda x: x.is_dir() and scan_name_regex.match(x.name))\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def clean_old(d, keep=10, filter=lambda x: True, key=latest_mtime, reverse=True, raise_error=False):\n\"\"\"Clean up old files and directories within a given directory based on various filtering and sorting options.\n\n    This function removes the oldest files and directories in the provided directory 'd' that exceed a specified\n    threshold ('keep'). The items to be deleted can be filtered using a lambda function 'filter', and they are\n    sorted by a key function, defaulting to latest modification time.\n\n    Args:\n        d (str or Path): The directory path to clean up.\n        keep (int): The number of items to keep. Ones beyond this count will be removed.\n        filter (Callable): A lambda function for filtering which files or directories to consider.\n                           Defaults to a lambda function that returns True for all.\n        key (Callable): A function to sort the files and directories. Defaults to latest modification time.\n        reverse (bool): Whether to reverse the order of sorted items before removing. Defaults to True.\n        raise_error (bool): Whether to raise an error if directory deletion fails. Defaults to False.\n\n    Examples:\n        &gt;&gt;&gt; clean_old(\"~/.bbot/scans\", filter=lambda x: x.is_dir() and scan_name_regex.match(x.name))\n    \"\"\"\n    d = Path(d)\n    if not d.is_dir():\n        return\n    paths = [x for x in d.iterdir() if filter(x)]\n    paths.sort(key=key, reverse=reverse)\n    for path in paths[keep:]:\n        try:\n            log.debug(f\"Removing {path}\")\n            shutil.rmtree(path)\n        except Exception as e:\n            msg = f\"Failed to delete directory: {path}, {e}\"\n            if raise_error:\n                raise errors.DirectoryDeletionError()\n            log.warning(msg)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.closest_match","title":"closest_match","text":"<pre><code>closest_match(s, choices, n = 1, cutoff = 0.0)\n</code></pre> <p>Finds the closest matching strings from a list of choices based on a given string.</p> <p>This function uses the difflib library to find the closest matches to a given string <code>s</code> from a list of <code>choices</code>. It can return either the single best match or a list of the top <code>n</code> best matches.</p> <p>Parameters:</p> <ul> <li> <code>s</code>             (<code>str</code>)         \u2013          <p>The string for which to find the closest match.</p> </li> <li> <code>choices</code>             (<code>list</code>)         \u2013          <p>A list of strings to compare against.</p> </li> <li> <code>n</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>The number of best matches to return. Defaults to 1.</p> </li> <li> <code>cutoff</code>             (<code>float</code>, default:                 <code>0.0</code> )         \u2013          <p>A float value that defines the similarity threshold. Strings with similarity below this value are not considered. Defaults to 0.0.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>str or list: Either the closest matching string or a list of the <code>n</code> closest matching strings.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; closest_match(\"asdf\", [\"asd\", \"fds\"])\n'asd'\n&gt;&gt;&gt; closest_match(\"asdf\", [\"asd\", \"fds\", \"asdff\"], n=3)\n['asdff', 'asd', 'fds']\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def closest_match(s, choices, n=1, cutoff=0.0):\n\"\"\"Finds the closest matching strings from a list of choices based on a given string.\n\n    This function uses the difflib library to find the closest matches to a given string `s` from a list of `choices`.\n    It can return either the single best match or a list of the top `n` best matches.\n\n    Args:\n        s (str): The string for which to find the closest match.\n        choices (list): A list of strings to compare against.\n        n (int, optional): The number of best matches to return. Defaults to 1.\n        cutoff (float, optional): A float value that defines the similarity threshold. Strings with similarity below this value are not considered. Defaults to 0.0.\n\n    Returns:\n        str or list: Either the closest matching string or a list of the `n` closest matching strings.\n\n    Examples:\n        &gt;&gt;&gt; closest_match(\"asdf\", [\"asd\", \"fds\"])\n        'asd'\n        &gt;&gt;&gt; closest_match(\"asdf\", [\"asd\", \"fds\", \"asdff\"], n=3)\n        ['asdff', 'asd', 'fds']\n    \"\"\"\n    matches = difflib.get_close_matches(s, choices, n=n, cutoff=cutoff)\n    if not choices or not matches:\n        return\n    if n == 1:\n        return matches[0]\n    return matches\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.cloudcheck","title":"cloudcheck","text":"<pre><code>cloudcheck(ip)\n</code></pre> <p>Check whether an IP address belongs to a cloud provider and returns the provider name, type, and subnet.</p> <p>Parameters:</p> <ul> <li> <code>ip</code>             (<code>str</code>)         \u2013          <p>The IP address to check.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>        \u2013          <p>A tuple containing provider name (str), provider type (str), and subnet (IPv4Network).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cloudcheck(\"168.62.20.37\")\n('Azure', 'cloud', IPv4Network('168.62.0.0/19'))\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def cloudcheck(ip):\n\"\"\"\n    Check whether an IP address belongs to a cloud provider and returns the provider name, type, and subnet.\n\n    Args:\n        ip (str): The IP address to check.\n\n    Returns:\n        tuple: A tuple containing provider name (str), provider type (str), and subnet (IPv4Network).\n\n    Examples:\n        &gt;&gt;&gt; cloudcheck(\"168.62.20.37\")\n        ('Azure', 'cloud', IPv4Network('168.62.0.0/19'))\n    \"\"\"\n    provider, provider_type, subnet = _cloudcheck.check(ip)\n    if provider:\n        with suppress(KeyError):\n            provider = provider_map[provider.lower()]\n    return provider, provider_type, subnet\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.cpu_architecture","title":"cpu_architecture","text":"<pre><code>cpu_architecture()\n</code></pre> <p>Return the CPU architecture of the current system.</p> <p>This function fetches and returns the architecture type of the CPU where the code is being executed. It maps common identifiers like \"x86_64\" to more general types like \"amd64\".</p> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>A string representing the CPU architecture, such as \"amd64\", \"armv7\", or \"arm64\".</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cpu_architecture()\n'amd64'\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def cpu_architecture():\n\"\"\"Return the CPU architecture of the current system.\n\n    This function fetches and returns the architecture type of the CPU where the code is being executed.\n    It maps common identifiers like \"x86_64\" to more general types like \"amd64\".\n\n    Returns:\n        str: A string representing the CPU architecture, such as \"amd64\", \"armv7\", or \"arm64\".\n\n    Examples:\n        &gt;&gt;&gt; cpu_architecture()\n        'amd64'\n    \"\"\"\n    uname = platform.uname()\n    arch = uname.machine.lower()\n    if arch.startswith(\"aarch\"):\n        return \"arm64\"\n    elif arch == \"x86_64\":\n        return \"amd64\"\n    return arch\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.delete_file","title":"delete_file","text":"<pre><code>delete_file(path)\n</code></pre> <p>Deletes a file at the given path.</p> <p>Parameters:</p> <ul> <li> <code>path</code>             (<code>str or Path</code>)         \u2013          <p>The path to the file to be deleted.</p> </li> </ul> Note <p>This function suppresses all exceptions to ensure that the program continues running even if the file could not be deleted.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; delete_file(\"/tmp/test/file1.txt\")\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def delete_file(path):\n\"\"\"Deletes a file at the given path.\n\n    Args:\n        path (str or Path): The path to the file to be deleted.\n\n    Note:\n        This function suppresses all exceptions to ensure that the program continues running even if the file could not be deleted.\n\n    Examples:\n        &gt;&gt;&gt; delete_file(\"/tmp/test/file1.txt\")\n    \"\"\"\n    with suppress(Exception):\n        Path(path).unlink(missing_ok=True)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.domain_parents","title":"domain_parents","text":"<pre><code>domain_parents(d, include_self = False)\n</code></pre> <p>Generate a list of parent domains for a given domain string.</p> <p>This function takes an input string <code>d</code> and generates a list of parent domains in decreasing order of specificity. If <code>include_self</code> is set to True, the list will also include the input domain if it is not a top-level domain.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>str</code>)         \u2013          <p>The input string representing a domain or subdomain.</p> </li> <li> <code>include_self</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to include the input domain itself. Defaults to False.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>str</code>        \u2013          <p>Parent domains of the input string in decreasing order of specificity.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; list(domain_parents(\"test.www.evilcorp.co.uk\"))\n[\"www.evilcorp.co.uk\", \"evilcorp.co.uk\"]\n</code></pre> Notes <ul> <li>Port, if present in input, is preserved in the output.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def domain_parents(d, include_self=False):\n\"\"\"\n    Generate a list of parent domains for a given domain string.\n\n    This function takes an input string `d` and generates a list of parent domains in decreasing order of specificity.\n    If `include_self` is set to True, the list will also include the input domain if it is not a top-level domain.\n\n    Args:\n        d (str): The input string representing a domain or subdomain.\n        include_self (bool, optional): Whether to include the input domain itself. Defaults to False.\n\n    Yields:\n        str: Parent domains of the input string in decreasing order of specificity.\n\n    Examples:\n        &gt;&gt;&gt; list(domain_parents(\"test.www.evilcorp.co.uk\"))\n        [\"www.evilcorp.co.uk\", \"evilcorp.co.uk\"]\n\n    Notes:\n        - Port, if present in input, is preserved in the output.\n    \"\"\"\n\n    parent = str(d)\n    if include_self and not is_domain(parent):\n        yield parent\n    while 1:\n        parent = parent_domain(parent)\n        if is_subdomain(parent):\n            yield parent\n            continue\n        elif is_domain(parent):\n            yield parent\n        break\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.domain_stem","title":"domain_stem","text":"<pre><code>domain_stem(domain)\n</code></pre> <p>Returns an abbreviated representation of the hostname by removing the TLD (Top-Level Domain).</p> <p>Parameters:</p> <ul> <li> <code>domain</code>             (<code>str</code>)         \u2013          <p>The full domain name to be abbreviated.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>An abbreviated domain string without the TLD.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; domain_stem(\"www.evilcorp.com\")\n\"www.evilcorp\"\n</code></pre> Notes <ul> <li>Utilizes the <code>tldextract</code> function for domain parsing.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def domain_stem(domain):\n\"\"\"\n    Returns an abbreviated representation of the hostname by removing the TLD (Top-Level Domain).\n\n    Args:\n        domain (str): The full domain name to be abbreviated.\n\n    Returns:\n        str: An abbreviated domain string without the TLD.\n\n    Examples:\n        &gt;&gt;&gt; domain_stem(\"www.evilcorp.com\")\n        \"www.evilcorp\"\n\n    Notes:\n        - Utilizes the `tldextract` function for domain parsing.\n    \"\"\"\n    parsed = tldextract(str(domain))\n    return f\".\".join(parsed.subdomain.split(\".\") + parsed.domain.split(\".\")).strip(\".\")\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.execute_sync_or_async","title":"execute_sync_or_async  <code>async</code>","text":"<pre><code>execute_sync_or_async(callback, *args, **kwargs)\n</code></pre> <p>Execute a function or coroutine, handling either synchronous or asynchronous invocation.</p> <p>Parameters:</p> <ul> <li> <code>callback</code>             (<code>Union[Callable, Coroutine]</code>)         \u2013          <p>The function or coroutine to execute.</p> </li> <li> <code>*args</code>         \u2013          <p>Variable-length argument list to pass to the callback.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments to pass to the callback.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>        \u2013          <p>The return value from the executed function or coroutine.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; async def foo_async(x):\n...     return x + 1\n&gt;&gt;&gt; def foo_sync(x):\n...     return x + 1\n</code></pre> <pre><code>&gt;&gt;&gt; asyncio.run(execute_sync_or_async(foo_async, 1))\n2\n</code></pre> <pre><code>&gt;&gt;&gt; asyncio.run(execute_sync_or_async(foo_sync, 1))\n2\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>async def execute_sync_or_async(callback, *args, **kwargs):\n\"\"\"\n    Execute a function or coroutine, handling either synchronous or asynchronous invocation.\n\n    Args:\n        callback (Union[Callable, Coroutine]): The function or coroutine to execute.\n        *args: Variable-length argument list to pass to the callback.\n        **kwargs: Arbitrary keyword arguments to pass to the callback.\n\n    Returns:\n        Any: The return value from the executed function or coroutine.\n\n    Examples:\n        &gt;&gt;&gt; async def foo_async(x):\n        ...     return x + 1\n        &gt;&gt;&gt; def foo_sync(x):\n        ...     return x + 1\n\n        &gt;&gt;&gt; asyncio.run(execute_sync_or_async(foo_async, 1))\n        2\n\n        &gt;&gt;&gt; asyncio.run(execute_sync_or_async(foo_sync, 1))\n        2\n    \"\"\"\n    if is_async_function(callback):\n        return await callback(*args, **kwargs)\n    else:\n        return callback(*args, **kwargs)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.extract_emails","title":"extract_emails","text":"<pre><code>extract_emails(s)\n</code></pre> <p>Extract email addresses from a body of text</p> <p>This function takes in a string and yields all email addresses found in it. The emails are converted to lower case before yielding. It utilizes regular expressions for email pattern matching.</p> <p>Parameters:</p> <ul> <li> <code>s</code>             (<code>str</code>)         \u2013          <p>The input string from which to extract email addresses.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>str</code>        \u2013          <p>Yields email addresses found in the input string, in lower case.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; list(extract_emails(\"Contact us at info@evilcorp.com and support@evilcorp.com\"))\n['info@evilcorp.com', 'support@evilcorp.com']\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def extract_emails(s):\n\"\"\"\n    Extract email addresses from a body of text\n\n    This function takes in a string and yields all email addresses found in it.\n    The emails are converted to lower case before yielding. It utilizes\n    regular expressions for email pattern matching.\n\n    Args:\n        s (str): The input string from which to extract email addresses.\n\n    Yields:\n        str: Yields email addresses found in the input string, in lower case.\n\n    Examples:\n        &gt;&gt;&gt; list(extract_emails(\"Contact us at info@evilcorp.com and support@evilcorp.com\"))\n        ['info@evilcorp.com', 'support@evilcorp.com']\n    \"\"\"\n    for email in bbot_regexes.email_regex.findall(smart_decode(s)):\n        yield email.lower()\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.extract_host","title":"extract_host","text":"<pre><code>extract_host(s)\n</code></pre> <p>Attempts to find and extract the host portion of a string.</p> <p>Parameters:</p> <ul> <li> <code>s</code>             (<code>str</code>)         \u2013          <p>The string from which to extract the host.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>        \u2013          <p>A tuple containing three strings:    (hostname (None if not found), string_before_hostname, string_after_hostname).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; extract_host(\"evilcorp.com:80\")\n(\"evilcorp.com\", \"\", \":80\")\n</code></pre> <pre><code>&gt;&gt;&gt; extract_host(\"http://evilcorp.com:80/asdf.php?a=b\")\n(\"evilcorp.com\", \"http://\", \":80/asdf.php?a=b\")\n</code></pre> <pre><code>&gt;&gt;&gt; extract_host(\"bob@evilcorp.com\")\n(\"evilcorp.com\", \"bob@\", \"\")\n</code></pre> <pre><code>&gt;&gt;&gt; extract_host(\"[dead::beef]:22\")\n(\"dead::beef\", \"[\", \"]:22\")\n</code></pre> <pre><code>&gt;&gt;&gt; extract_host(\"ftp://username:password@my-ftp.com/my-file.csv\")\n(\n    \"my-ftp.com\",\n    \"ftp://username:password@\",\n    \"/my-file.csv\",\n)\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def extract_host(s):\n\"\"\"\n    Attempts to find and extract the host portion of a string.\n\n    Args:\n        s (str): The string from which to extract the host.\n\n    Returns:\n        tuple: A tuple containing three strings:\n               (hostname (None if not found), string_before_hostname, string_after_hostname).\n\n    Examples:\n        &gt;&gt;&gt; extract_host(\"evilcorp.com:80\")\n        (\"evilcorp.com\", \"\", \":80\")\n\n        &gt;&gt;&gt; extract_host(\"http://evilcorp.com:80/asdf.php?a=b\")\n        (\"evilcorp.com\", \"http://\", \":80/asdf.php?a=b\")\n\n        &gt;&gt;&gt; extract_host(\"bob@evilcorp.com\")\n        (\"evilcorp.com\", \"bob@\", \"\")\n\n        &gt;&gt;&gt; extract_host(\"[dead::beef]:22\")\n        (\"dead::beef\", \"[\", \"]:22\")\n\n        &gt;&gt;&gt; extract_host(\"ftp://username:password@my-ftp.com/my-file.csv\")\n        (\n            \"my-ftp.com\",\n            \"ftp://username:password@\",\n            \"/my-file.csv\",\n        )\n    \"\"\"\n    s = smart_decode(s)\n    match = bbot_regexes.extract_host_regex.search(s)\n\n    if match:\n        hostname = match.group(1)\n        before = s[: match.start(1)]\n        after = s[match.end(1) :]\n        host, port = split_host_port(hostname)\n        netloc = make_netloc(host, port)\n        if netloc != hostname:\n            # invalid host / port\n            return (None, s, \"\")\n        if host is not None:\n            if port is not None:\n                after = f\":{port}{after}\"\n            if is_ip(host, version=6) and hostname.startswith(\"[\"):\n                before = f\"{before}[\"\n                after = f\"]{after}\"\n            hostname = str(host)\n        return (hostname, before, after)\n\n    return (None, s, \"\")\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.extract_params_html","title":"extract_params_html","text":"<pre><code>extract_params_html(html_data)\n</code></pre> <p>Extracts parameters from an HTML object, yielding them one at a time.</p> <p>Parameters:</p> <ul> <li> <code>html_data</code>             (<code>str</code>)         \u2013          <p>HTML-formatted string.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>str</code>        \u2013          <p>A string containing the parameter found in HTML object.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; html_data = '''\n... &lt;html&gt;\n...     &lt;body&gt;\n...         &lt;input name=\"user\"&gt;\n...         &lt;a href=\"/page?param3=value3\"&gt;Click Me&lt;/a&gt;\n...         &lt;script&gt;\n...             $.get(\"/test\", {param1: \"value1\"});\n...             $.post(\"/test\", {param2: \"value2\"});\n...         &lt;/script&gt;\n...     &lt;/body&gt;\n... &lt;/html&gt;\n... '''\n&gt;&gt;&gt; list(extract_params_html(html_data))\n['user', 'param2', 'param3']\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def extract_params_html(html_data):\n\"\"\"\n    Extracts parameters from an HTML object, yielding them one at a time.\n\n    Args:\n        html_data (str): HTML-formatted string.\n\n    Yields:\n        str: A string containing the parameter found in HTML object.\n\n    Examples:\n        &gt;&gt;&gt; html_data = '''\n        ... &lt;html&gt;\n        ...     &lt;body&gt;\n        ...         &lt;input name=\"user\"&gt;\n        ...         &lt;a href=\"/page?param3=value3\"&gt;Click Me&lt;/a&gt;\n        ...         &lt;script&gt;\n        ...             $.get(\"/test\", {param1: \"value1\"});\n        ...             $.post(\"/test\", {param2: \"value2\"});\n        ...         &lt;/script&gt;\n        ...     &lt;/body&gt;\n        ... &lt;/html&gt;\n        ... '''\n        &gt;&gt;&gt; list(extract_params_html(html_data))\n        ['user', 'param2', 'param3']\n    \"\"\"\n    input_tag = bbot_regexes.input_tag_regex.findall(html_data)\n\n    for i in input_tag:\n        log.debug(f\"FOUND PARAM ({i}) IN INPUT TAGS\")\n        yield i\n\n    # check for jquery get parameters\n    jquery_get = bbot_regexes.jquery_get_regex.findall(html_data)\n\n    for i in jquery_get:\n        log.debug(f\"FOUND PARAM ({i}) IN JQUERY GET PARAMS\")\n        yield i\n\n    # check for jquery post parameters\n    jquery_post = bbot_regexes.jquery_post_regex.findall(html_data)\n    if jquery_post:\n        for i in jquery_post:\n            for x in i.split(\",\"):\n                s = x.split(\":\")[0].rstrip()\n                log.debug(f\"FOUND PARAM ({s}) IN A JQUERY POST PARAMS\")\n                yield s\n\n    a_tag = bbot_regexes.a_tag_regex.findall(html_data)\n    for s in a_tag:\n        log.debug(f\"FOUND PARAM ({s}) IN A TAG GET PARAMS\")\n        yield s\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.extract_params_json","title":"extract_params_json","text":"<pre><code>extract_params_json(json_data)\n</code></pre> <p>Extracts keys from a JSON object and returns them as a set. Used by the <code>paramminer_headers</code> module.</p> <p>Parameters:</p> <ul> <li> <code>json_data</code>             (<code>str</code>)         \u2013          <p>JSON-formatted string containing key-value pairs.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>set</code>        \u2013          <p>A set containing the keys present in the JSON object.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; extract_params_json('{\"a\": 1, \"b\": {\"c\": 2}}')\n{'a', 'b', 'c'}\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def extract_params_json(json_data):\n\"\"\"\n    Extracts keys from a JSON object and returns them as a set. Used by the `paramminer_headers` module.\n\n    Args:\n        json_data (str): JSON-formatted string containing key-value pairs.\n\n    Returns:\n        set: A set containing the keys present in the JSON object.\n\n    Raises:\n        Logs a message if JSONDecodeError occurs.\n\n    Examples:\n        &gt;&gt;&gt; extract_params_json('{\"a\": 1, \"b\": {\"c\": 2}}')\n        {'a', 'b', 'c'}\n    \"\"\"\n    try:\n        data = json.loads(json_data)\n    except json.JSONDecodeError:\n        log.debug(\"Invalid JSON supplied. Returning empty list.\")\n        return set()\n\n    keys = set()\n    stack = [data]\n\n    while stack:\n        current_data = stack.pop()\n        if isinstance(current_data, dict):\n            for key, value in current_data.items():\n                keys.add(key)\n                if isinstance(value, (dict, list)):\n                    stack.append(value)\n        elif isinstance(current_data, list):\n            for item in current_data:\n                if isinstance(item, (dict, list)):\n                    stack.append(item)\n\n    return keys\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.extract_params_xml","title":"extract_params_xml","text":"<pre><code>extract_params_xml(xml_data)\n</code></pre> <p>Extracts tags from an XML object and returns them as a set.</p> <p>Parameters:</p> <ul> <li> <code>xml_data</code>             (<code>str</code>)         \u2013          <p>XML-formatted string containing elements.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>set</code>        \u2013          <p>A set containing the tags present in the XML object.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; extract_params_xml('&lt;root&gt;&lt;child1&gt;&lt;child2/&gt;&lt;/child1&gt;&lt;/root&gt;')\n{'child1', 'child2', 'root'}\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def extract_params_xml(xml_data):\n\"\"\"\n    Extracts tags from an XML object and returns them as a set.\n\n    Args:\n        xml_data (str): XML-formatted string containing elements.\n\n    Returns:\n        set: A set containing the tags present in the XML object.\n\n    Raises:\n        Logs a message if ParseError occurs.\n\n    Examples:\n        &gt;&gt;&gt; extract_params_xml('&lt;root&gt;&lt;child1&gt;&lt;child2/&gt;&lt;/child1&gt;&lt;/root&gt;')\n        {'child1', 'child2', 'root'}\n    \"\"\"\n    try:\n        root = ET.fromstring(xml_data)\n    except ET.ParseError:\n        log.debug(\"Invalid XML supplied. Returning empty list.\")\n        return set()\n\n    tags = set()\n    stack = [root]\n\n    while stack:\n        current_element = stack.pop()\n        tags.add(current_element.tag)\n        for child in current_element:\n            stack.append(child)\n    return tags\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.extract_words","title":"extract_words","text":"<pre><code>extract_words(data, acronyms = True, wordninja = True, model = None, max_length = 100, word_regexes = None)\n</code></pre> <p>Intelligently extracts words from given data.</p> <p>This function uses regular expressions and optionally wordninja to extract words from a given text string. Thanks to wordninja it can handle concatenated words intelligently.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>str</code>)         \u2013          <p>The data from which words are to be extracted.</p> </li> <li> <code>acronyms</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to include acronyms. Defaults to True.</p> </li> <li> <code>wordninja</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to use the wordninja library to split concatenated words. Defaults to True.</p> </li> <li> <code>model</code>             (<code>object</code>, default:                 <code>None</code> )         \u2013          <p>A custom wordninja model for special types of data such as DNS names.</p> </li> <li> <code>max_length</code>             (<code>int</code>, default:                 <code>100</code> )         \u2013          <p>Maximum length for a word to be included. Defaults to 100.</p> </li> <li> <code>word_regexes</code>             (<code>list</code>, default:                 <code>None</code> )         \u2013          <p>A list of compiled regular expression objects for word extraction. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>set</code>        \u2013          <p>A set of extracted words.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; extract_words('blacklanternsecurity')\n{'black', 'lantern', 'security', 'bls', 'blacklanternsecurity'}\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def extract_words(data, acronyms=True, wordninja=True, model=None, max_length=100, word_regexes=None):\n\"\"\"Intelligently extracts words from given data.\n\n    This function uses regular expressions and optionally wordninja to extract words\n    from a given text string. Thanks to wordninja it can handle concatenated words intelligently.\n\n    Args:\n        data (str): The data from which words are to be extracted.\n        acronyms (bool, optional): Whether to include acronyms. Defaults to True.\n        wordninja (bool, optional): Whether to use the wordninja library to split concatenated words. Defaults to True.\n        model (object, optional): A custom wordninja model for special types of data such as DNS names.\n        max_length (int, optional): Maximum length for a word to be included. Defaults to 100.\n        word_regexes (list, optional): A list of compiled regular expression objects for word extraction. Defaults to None.\n\n    Returns:\n        set: A set of extracted words.\n\n    Examples:\n        &gt;&gt;&gt; extract_words('blacklanternsecurity')\n        {'black', 'lantern', 'security', 'bls', 'blacklanternsecurity'}\n    \"\"\"\n\n    if word_regexes is None:\n        word_regexes = bbot_regexes.word_regexes\n    words = set()\n    data = smart_decode(data)\n    for r in word_regexes:\n        for word in set(r.findall(data)):\n            # blacklanternsecurity\n            if len(word) &lt;= max_length:\n                words.add(word)\n\n    # blacklanternsecurity --&gt; ['black', 'lantern', 'security']\n    # max_slice_length = 3\n    for word in list(words):\n        if wordninja:\n            if model is None:\n                model = _wordninja\n            subwords = model.split(word)\n            for subword in subwords:\n                words.add(subword)\n        # this section generates compound words\n        # it is interesting but currently disabled the quality of its output doesn't quite justify its quantity\n        # blacklanternsecurity --&gt; ['black', 'lantern', 'security', 'blacklantern', 'lanternsecurity']\n        # for s, e in combinations(range(len(subwords) + 1), 2):\n        #    if e - s &lt;= max_slice_length:\n        #        subword_slice = \"\".join(subwords[s:e])\n        #        words.add(subword_slice)\n        # blacklanternsecurity --&gt; bls\n        if acronyms:\n            if len(subwords) &gt; 1:\n                words.add(\"\".join([c[0] for c in subwords if len(c) &gt; 0]))\n\n    return words\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.filesize","title":"filesize","text":"<pre><code>filesize(f)\n</code></pre> <p>Get the file size of a given file.</p> <p>This function takes a file path as an argument and returns its size in bytes. If the path does not point to a file, the function returns 0.</p> <p>Parameters:</p> <ul> <li> <code>f</code>             (<code>str or Path</code>)         \u2013          <p>The file path for which to get the size.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>        \u2013          <p>The size of the file in bytes, or 0 if the path does not point to a file.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; filesize(\"/path/to/file.txt\")\n1024\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def filesize(f):\n\"\"\"Get the file size of a given file.\n\n    This function takes a file path as an argument and returns its size in bytes. If the path\n    does not point to a file, the function returns 0.\n\n    Args:\n        f (str or Path): The file path for which to get the size.\n\n    Returns:\n        int: The size of the file in bytes, or 0 if the path does not point to a file.\n\n    Examples:\n        &gt;&gt;&gt; filesize(\"/path/to/file.txt\")\n        1024\n    \"\"\"\n    f = Path(f)\n    if f.is_file():\n        return f.stat().st_size\n    return 0\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.filter_dict","title":"filter_dict","text":"<pre><code>filter_dict(d, *key_names, fuzzy = False, exclude_keys = None, _prev_key = None)\n</code></pre> <p>Recursively filter a dictionary based on key names.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>dict</code>)         \u2013          <p>The input dictionary.</p> </li> <li> <code>*key_names</code>         \u2013          <p>Names of keys to filter for.</p> </li> <li> <code>fuzzy</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to perform fuzzy matching on keys.</p> </li> <li> <code>exclude_keys</code>             (<code>(list, None)</code>, default:                 <code>None</code> )         \u2013          <p>List of keys to be excluded from the final dict.</p> </li> <li> <code>_prev_key</code>             (<code>(str, None)</code>, default:                 <code>None</code> )         \u2013          <p>For internal recursive use; the previous key in the hierarchy.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>        \u2013          <p>A dictionary containing only the keys specified in key_names.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; filter_dict({\"key1\": \"test\", \"key2\": \"asdf\"}, \"key2\")\n{\"key2\": \"asdf\"}\n&gt;&gt;&gt; filter_dict({\"key1\": \"test\", \"key2\": {\"key3\": \"asdf\"}}, \"key1\", \"key3\", exclude_keys=\"key2\")\n{'key1': 'test'}\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def filter_dict(d, *key_names, fuzzy=False, exclude_keys=None, _prev_key=None):\n\"\"\"\n    Recursively filter a dictionary based on key names.\n\n    Args:\n        d (dict): The input dictionary.\n        *key_names: Names of keys to filter for.\n        fuzzy (bool): Whether to perform fuzzy matching on keys.\n        exclude_keys (list, None): List of keys to be excluded from the final dict.\n        _prev_key (str, None): For internal recursive use; the previous key in the hierarchy.\n\n    Returns:\n        dict: A dictionary containing only the keys specified in key_names.\n\n    Examples:\n        &gt;&gt;&gt; filter_dict({\"key1\": \"test\", \"key2\": \"asdf\"}, \"key2\")\n        {\"key2\": \"asdf\"}\n        &gt;&gt;&gt; filter_dict({\"key1\": \"test\", \"key2\": {\"key3\": \"asdf\"}}, \"key1\", \"key3\", exclude_keys=\"key2\")\n        {'key1': 'test'}\n    \"\"\"\n    if exclude_keys is None:\n        exclude_keys = []\n    if isinstance(exclude_keys, str):\n        exclude_keys = [exclude_keys]\n    ret = {}\n    if isinstance(d, dict):\n        for key in d:\n            if key in key_names or (fuzzy and any(k in key for k in key_names)):\n                if not any(k in exclude_keys for k in [key, _prev_key]):\n                    ret[key] = copy.deepcopy(d[key])\n            elif isinstance(d[key], list) or isinstance(d[key], dict):\n                child = filter_dict(d[key], *key_names, fuzzy=fuzzy, _prev_key=key, exclude_keys=exclude_keys)\n                if child:\n                    ret[key] = child\n    return ret\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.gen_numbers","title":"gen_numbers","text":"<pre><code>gen_numbers(n, padding = 2)\n</code></pre> <p>Generates numbers with variable padding and returns them as a set of strings.</p> <p>Parameters:</p> <ul> <li> <code>n</code>             (<code>int</code>)         \u2013          <p>The upper limit of numbers to generate, exclusive.</p> </li> <li> <code>padding</code>             (<code>int</code>, default:                 <code>2</code> )         \u2013          <p>The maximum number of digits to pad the numbers with. Defaults to 2.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>set</code>        \u2013          <p>A set of string representations of numbers with varying degrees of padding.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gen_numbers(5)\n{'0', '00', '01', '02', '03', '04', '1', '2', '3', '4'}\n</code></pre> <pre><code>&gt;&gt;&gt; gen_numbers(3, padding=3)\n{'0', '00', '000', '001', '002', '01', '02', '1', '2'}\n</code></pre> <pre><code>&gt;&gt;&gt; gen_numbers(5, padding=1)\n{'0', '1', '2', '3', '4'}\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def gen_numbers(n, padding=2):\n\"\"\"Generates numbers with variable padding and returns them as a set of strings.\n\n    Args:\n        n (int): The upper limit of numbers to generate, exclusive.\n        padding (int, optional): The maximum number of digits to pad the numbers with. Defaults to 2.\n\n    Returns:\n        set: A set of string representations of numbers with varying degrees of padding.\n\n    Examples:\n        &gt;&gt;&gt; gen_numbers(5)\n        {'0', '00', '01', '02', '03', '04', '1', '2', '3', '4'}\n\n        &gt;&gt;&gt; gen_numbers(3, padding=3)\n        {'0', '00', '000', '001', '002', '01', '02', '1', '2'}\n\n        &gt;&gt;&gt; gen_numbers(5, padding=1)\n        {'0', '1', '2', '3', '4'}\n    \"\"\"\n    results = set()\n    for i in range(n):\n        for p in range(1, padding + 1):\n            results.add(str(i).zfill(p))\n    return results\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.get_exception_chain","title":"get_exception_chain","text":"<pre><code>get_exception_chain(e)\n</code></pre> <p>Retrieves the full chain of exceptions leading to the given exception.</p> <p>Parameters:</p> <ul> <li> <code>e</code>             (<code>BaseException</code>)         \u2013          <p>The exception for which to get the chain.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>list[BaseException]: List of exceptions in the chain, from the given exception back to the root cause.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; try:\n...     raise ValueError(\"This is a value error\")\n... except ValueError as e:\n...     exc_chain = get_exception_chain(e)\n...     for exc in exc_chain:\n...         print(exc)\nThis is a value error\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def get_exception_chain(e):\n\"\"\"\n    Retrieves the full chain of exceptions leading to the given exception.\n\n    Args:\n        e (BaseException): The exception for which to get the chain.\n\n    Returns:\n        list[BaseException]: List of exceptions in the chain, from the given exception back to the root cause.\n\n    Examples:\n        &gt;&gt;&gt; try:\n        ...     raise ValueError(\"This is a value error\")\n        ... except ValueError as e:\n        ...     exc_chain = get_exception_chain(e)\n        ...     for exc in exc_chain:\n        ...         print(exc)\n        This is a value error\n    \"\"\"\n    exception_chain = []\n    current_exception = e\n    while current_exception is not None:\n        exception_chain.append(current_exception)\n        current_exception = getattr(current_exception, \"__context__\", None)\n    return exception_chain\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.get_file_extension","title":"get_file_extension","text":"<pre><code>get_file_extension(s)\n</code></pre> <p>Extracts the file extension from a given string representing a URL or file path.</p> <p>Parameters:</p> <ul> <li> <code>s</code>             (<code>str</code>)         \u2013          <p>The string from which to extract the file extension.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>The file extension, or an empty string if no extension is found.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_file_extension(\"https://evilcorp.com/api/test.php\")\n\"php\"\n&gt;&gt;&gt; get_file_extension(\"/etc/test.conf\")\n\"conf\"\n&gt;&gt;&gt; get_file_extension(\"/etc/passwd\")\n\"\"\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def get_file_extension(s):\n\"\"\"\n    Extracts the file extension from a given string representing a URL or file path.\n\n    Args:\n        s (str): The string from which to extract the file extension.\n\n    Returns:\n        str: The file extension, or an empty string if no extension is found.\n\n    Examples:\n        &gt;&gt;&gt; get_file_extension(\"https://evilcorp.com/api/test.php\")\n        \"php\"\n        &gt;&gt;&gt; get_file_extension(\"/etc/test.conf\")\n        \"conf\"\n        &gt;&gt;&gt; get_file_extension(\"/etc/passwd\")\n        \"\"\n    \"\"\"\n    s = str(s).lower().strip()\n    rightmost_section = s.rsplit(\"/\", 1)[-1]\n    if \".\" in rightmost_section:\n        extension = rightmost_section.rsplit(\".\", 1)[-1]\n        return extension\n    return \"\"\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.get_size","title":"get_size","text":"<pre><code>get_size(obj, max_depth = 5, seen = None)\n</code></pre> <p>Roughly estimate the memory footprint of a Python object using recursion.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>any</code>)         \u2013          <p>The object whose size is to be determined.</p> </li> <li> <code>max_depth</code>             (<code>int</code>, default:                 <code>5</code> )         \u2013          <p>Maximum depth to which nested objects will be inspected. Defaults to 5.</p> </li> <li> <code>seen</code>             (<code>set</code>, default:                 <code>None</code> )         \u2013          <p>Objects that have already been accounted for, to avoid loops.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>        \u2013          <p>Approximate memory footprint of the object in bytes.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_size(my_list)\n4200\n</code></pre> <pre><code>&gt;&gt;&gt; get_size(my_dict, max_depth=3)\n8400\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def get_size(obj, max_depth=5, seen=None):\n\"\"\"\n    Roughly estimate the memory footprint of a Python object using recursion.\n\n    Parameters:\n        obj (any): The object whose size is to be determined.\n        max_depth (int, optional): Maximum depth to which nested objects will be inspected. Defaults to 5.\n        seen (set, optional): Objects that have already been accounted for, to avoid loops.\n\n    Returns:\n        int: Approximate memory footprint of the object in bytes.\n\n    Examples:\n        &gt;&gt;&gt; get_size(my_list)\n        4200\n\n        &gt;&gt;&gt; get_size(my_dict, max_depth=3)\n        8400\n    \"\"\"\n    # If seen is not provided, initialize an empty set\n    if seen is None:\n        seen = set()\n    # Get the id of the object\n    obj_id = id(obj)\n    # Decrease the maximum depth for the next recursion\n    new_max_depth = max_depth - 1\n    # If the object has already been seen or we've reached the maximum recursion depth, return 0\n    if obj_id in seen or new_max_depth &lt;= 0:\n        return 0\n    # Get the size of the object\n    size = sys.getsizeof(obj)\n    # Add the object's id to the set of seen objects\n    seen.add(obj_id)\n    # If the object has a __dict__ attribute, we want to measure its size\n    if hasattr(obj, \"__dict__\"):\n        # Iterate over the Method Resolution Order (MRO) of the class of the object\n        for cls in obj.__class__.__mro__:\n            # If the class's __dict__ contains a __dict__ key\n            if \"__dict__\" in cls.__dict__:\n                for k, v in obj.__dict__.items():\n                    size += get_size(k, new_max_depth, seen)\n                    size += get_size(v, new_max_depth, seen)\n                break\n    # If the object is a mapping (like a dictionary), we want to measure the size of its items\n    if isinstance(obj, Mapping):\n        with suppress(StopIteration):\n            k, v = next(iter(obj.items()))\n            size += (get_size(k, new_max_depth, seen) + get_size(v, new_max_depth, seen)) * len(obj)\n    # If the object is a container (like a list or tuple) but not a string or bytes-like object\n    elif isinstance(obj, (list, tuple, set)):\n        with suppress(StopIteration):\n            size += get_size(next(iter(obj)), new_max_depth, seen) * len(obj)\n    # If the object has __slots__, we want to measure the size of the attributes in __slots__\n    if hasattr(obj, \"__slots__\"):\n        size += sum(get_size(getattr(obj, s), new_max_depth, seen) for s in obj.__slots__ if hasattr(obj, s))\n    return size\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.get_traceback_details","title":"get_traceback_details","text":"<pre><code>get_traceback_details(e)\n</code></pre> <p>Retrieves detailed information from the traceback of an exception.</p> <p>Parameters:</p> <ul> <li> <code>e</code>             (<code>BaseException</code>)         \u2013          <p>The exception for which to get traceback details.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>        \u2013          <p>A tuple containing filename (str), line number (int), and function name (str) where the exception was raised.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; try:\n...     raise ValueError(\"This is a value error\")\n... except ValueError as e:\n...     filename, lineno, funcname = get_traceback_details(e)\n...     print(f\"File: {filename}, Line: {lineno}, Function: {funcname}\")\nFile: &lt;stdin&gt;, Line: 2, Function: &lt;module&gt;\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def get_traceback_details(e):\n\"\"\"\n    Retrieves detailed information from the traceback of an exception.\n\n    Args:\n        e (BaseException): The exception for which to get traceback details.\n\n    Returns:\n        tuple: A tuple containing filename (str), line number (int), and function name (str) where the exception was raised.\n\n    Examples:\n        &gt;&gt;&gt; try:\n        ...     raise ValueError(\"This is a value error\")\n        ... except ValueError as e:\n        ...     filename, lineno, funcname = get_traceback_details(e)\n        ...     print(f\"File: {filename}, Line: {lineno}, Function: {funcname}\")\n        File: &lt;stdin&gt;, Line: 2, Function: &lt;module&gt;\n    \"\"\"\n    tb = traceback.extract_tb(e.__traceback__)\n    last_frame = tb[-1]  # Get the last frame in the traceback (the one where the exception was raised)\n    filename = last_frame.filename\n    lineno = last_frame.lineno\n    funcname = last_frame.name\n    return filename, lineno, funcname\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.grouper","title":"grouper","text":"<pre><code>grouper(iterable, n)\n</code></pre> <p>Grouper groups an iterable into chunks of a given size.</p> <p>Parameters:</p> <ul> <li> <code>iterable</code>             (<code>iterable</code>)         \u2013          <p>The iterable to be chunked.</p> </li> <li> <code>n</code>             (<code>int</code>)         \u2013          <p>The size of each chunk.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>iterator</code>        \u2013          <p>An iterator that produces lists of elements from the original iterable, each of length <code>n</code> or less.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; list(grouper('ABCDEFG', 3))\n[['A', 'B', 'C'], ['D', 'E', 'F'], ['G']]\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def grouper(iterable, n):\n\"\"\"\n    Grouper groups an iterable into chunks of a given size.\n\n    Args:\n        iterable (iterable): The iterable to be chunked.\n        n (int): The size of each chunk.\n\n    Returns:\n        iterator: An iterator that produces lists of elements from the original iterable, each of length `n` or less.\n\n    Examples:\n        &gt;&gt;&gt; list(grouper('ABCDEFG', 3))\n        [['A', 'B', 'C'], ['D', 'E', 'F'], ['G']]\n    \"\"\"\n\n    iterable = iter(iterable)\n    return iter(lambda: list(islice(iterable, n)), [])\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.host_in_host","title":"host_in_host","text":"<pre><code>host_in_host(host1, host2)\n</code></pre> <p>Checks if host1 is included within host2, either as a subdomain, IP, or IP network. Used for scope calculations/decisions within BBOT.</p> <p>Parameters:</p> <ul> <li> <code>host1</code>             (<code>str or IPv4Address or IPv6Address or IPv4Network or IPv6Network</code>)         \u2013          <p>The host to check for inclusion within host2.</p> </li> <li> <code>host2</code>             (<code>str or IPv4Address or IPv6Address or IPv4Network or IPv6Network</code>)         \u2013          <p>The host within which to check for the inclusion of host1.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if host1 is included in host2, otherwise False.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; host_in_host(\"www.evilcorp.com\", \"evilcorp.com\")\nTrue\n&gt;&gt;&gt; host_in_host(\"evilcorp.com\", \"www.evilcorp.com\")\nFalse\n&gt;&gt;&gt; host_in_host(ipaddress.IPv6Address('dead::beef'), ipaddress.IPv6Network('dead::/64'))\nTrue\n&gt;&gt;&gt; host_in_host(ipaddress.IPv4Address('192.168.1.1'), ipaddress.IPv4Network('10.0.0.0/8'))\nFalse\n</code></pre> Notes <ul> <li>If checking an IP address/network, you MUST FIRST convert your IP into an ipaddress object (e.g. via <code>make_ip_type()</code>) before passing it to this function.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def host_in_host(host1, host2):\n\"\"\"\n    Checks if host1 is included within host2, either as a subdomain, IP, or IP network.\n    Used for scope calculations/decisions within BBOT.\n\n    Args:\n        host1 (str or ipaddress.IPv4Address or ipaddress.IPv6Address or ipaddress.IPv4Network or ipaddress.IPv6Network):\n            The host to check for inclusion within host2.\n        host2 (str or ipaddress.IPv4Address or ipaddress.IPv6Address or ipaddress.IPv4Network or ipaddress.IPv6Network):\n            The host within which to check for the inclusion of host1.\n\n    Returns:\n        bool: True if host1 is included in host2, otherwise False.\n\n    Examples:\n        &gt;&gt;&gt; host_in_host(\"www.evilcorp.com\", \"evilcorp.com\")\n        True\n        &gt;&gt;&gt; host_in_host(\"evilcorp.com\", \"www.evilcorp.com\")\n        False\n        &gt;&gt;&gt; host_in_host(ipaddress.IPv6Address('dead::beef'), ipaddress.IPv6Network('dead::/64'))\n        True\n        &gt;&gt;&gt; host_in_host(ipaddress.IPv4Address('192.168.1.1'), ipaddress.IPv4Network('10.0.0.0/8'))\n        False\n\n    Notes:\n        - If checking an IP address/network, you MUST FIRST convert your IP into an ipaddress object (e.g. via `make_ip_type()`) before passing it to this function.\n    \"\"\"\n\n\"\"\"\n    Is host1 included in host2?\n        \"www.evilcorp.com\" in \"evilcorp.com\"? --&gt; True\n        \"evilcorp.com\" in \"www.evilcorp.com\"? --&gt; False\n        IPv6Address('dead::beef') in IPv6Network('dead::/64')? --&gt; True\n        IPv4Address('192.168.1.1') in IPv4Network('10.0.0.0/8')? --&gt; False\n\n    Very important! Used throughout BBOT for scope calculations/decisions.\n\n    Works with hostnames, IPs, and IP networks.\n    \"\"\"\n\n    if not host1 or not host2:\n        return False\n\n    # check if hosts are IP types\n    host1_ip_type = is_ip_type(host1)\n    host2_ip_type = is_ip_type(host2)\n    # if both hosts are IP types\n    if host1_ip_type and host2_ip_type:\n        if not host1.version == host2.version:\n            return False\n        host1_net = ipaddress.ip_network(host1)\n        host2_net = ipaddress.ip_network(host2)\n        return host1_net.subnet_of(host2_net)\n\n    # else hostnames\n    elif not (host1_ip_type or host2_ip_type):\n        host2_len = len(host2.split(\".\"))\n        host1_truncated = \".\".join(host1.split(\".\")[-host2_len:])\n        return host1_truncated == host2\n\n    return False\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.human_timedelta","title":"human_timedelta","text":"<pre><code>human_timedelta(d)\n</code></pre> <p>Convert a TimeDelta object into a human-readable string.</p> <p>This function takes a datetime.timedelta object and converts it into a string format that is easier to read and understand.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>timedelta</code>)         \u2013          <p>The TimeDelta object to convert.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>A string representation of the TimeDelta object in human-readable form.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt;\n&gt;&gt;&gt; start_time = datetime.now()\n&gt;&gt;&gt; end_time = datetime.now()\n&gt;&gt;&gt; elapsed_time = end_time - start_time\n&gt;&gt;&gt; human_timedelta(elapsed_time)\n'2 hours, 30 minutes, 15 seconds'\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def human_timedelta(d):\n\"\"\"Convert a TimeDelta object into a human-readable string.\n\n    This function takes a datetime.timedelta object and converts it into a string format that\n    is easier to read and understand.\n\n    Args:\n        d (datetime.timedelta): The TimeDelta object to convert.\n\n    Returns:\n        str: A string representation of the TimeDelta object in human-readable form.\n\n    Examples:\n        &gt;&gt;&gt; from datetime import datetime\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; start_time = datetime.now()\n        &gt;&gt;&gt; end_time = datetime.now()\n        &gt;&gt;&gt; elapsed_time = end_time - start_time\n        &gt;&gt;&gt; human_timedelta(elapsed_time)\n        '2 hours, 30 minutes, 15 seconds'\n    \"\"\"\n    hours, remainder = divmod(d.seconds, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    result = []\n    if hours:\n        result.append(f\"{hours:,} hour\" + (\"s\" if hours &gt; 1 else \"\"))\n    if minutes:\n        result.append(f\"{minutes:,} minute\" + (\"s\" if minutes &gt; 1 else \"\"))\n    if seconds:\n        result.append(f\"{seconds:,} second\" + (\"s\" if seconds &gt; 1 else \"\"))\n    ret = \", \".join(result)\n    if not ret:\n        ret = \"0 seconds\"\n    return ret\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.human_to_bytes","title":"human_to_bytes","text":"<pre><code>human_to_bytes(filesize)\n</code></pre> <p>Convert a human-readable file size string to its bytes equivalent.</p> <p>This function takes a human-readable file size string, such as \"2.5GB\", and converts it to its equivalent number of bytes.</p> <p>Parameters:</p> <ul> <li> <code>filesize</code>             (<code>str or int</code>)         \u2013          <p>The human-readable file size string or integer bytes value to convert.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>        \u2013          <p>The number of bytes equivalent to the input human-readable file size.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If the input string cannot be converted to bytes.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; human_to_bytes(\"23.23gb\")\n24943022571\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def human_to_bytes(filesize):\n\"\"\"Convert a human-readable file size string to its bytes equivalent.\n\n    This function takes a human-readable file size string, such as \"2.5GB\", and converts it\n    to its equivalent number of bytes.\n\n    Args:\n        filesize (str or int): The human-readable file size string or integer bytes value to convert.\n\n    Returns:\n        int: The number of bytes equivalent to the input human-readable file size.\n\n    Raises:\n        ValueError: If the input string cannot be converted to bytes.\n\n    Examples:\n        &gt;&gt;&gt; human_to_bytes(\"23.23gb\")\n        24943022571\n    \"\"\"\n    if isinstance(filesize, int):\n        return filesize\n    sizes = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\"]\n    units = {}\n    for count, size in enumerate(sizes):\n        size_increment = pow(1024, count)\n        units[size] = size_increment\n        if len(size) == 2:\n            units[size[0]] = size_increment\n    match = filesize_regex.match(filesize)\n    try:\n        if match:\n            num, size = match.groups()\n            size = size.upper()\n            size_increment = units[size]\n            return int(float(num) * size_increment)\n    except KeyError:\n        pass\n    raise ValueError(f'Unable to convert filesize \"{filesize}\" to bytes')\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.ip_network_parents","title":"ip_network_parents","text":"<pre><code>ip_network_parents(i, include_self = False)\n</code></pre> <p>Generates all parent IP networks for a given IP address or network, optionally including the network itself.</p> <p>Parameters:</p> <ul> <li> <code>i</code>             (<code>str or IPv4Network / IPv6Network</code>)         \u2013          <p>The IP address or network to find parents for.</p> </li> <li> <code>include_self</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to include the network itself in the result. Default is False.</p> </li> </ul> <p>Yields:</p> <ul> <li>         \u2013          <p>ipaddress.IPv4Network or ipaddress.IPv6Network: Parent IP networks in descending order of prefix length.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; list(ip_network_parents(\"192.168.1.1\"))\n[ipaddress.IPv4Network('192.168.1.0/31'), ipaddress.IPv4Network('192.168.1.0/30'), ... , ipaddress.IPv4Network('0.0.0.0/0')]\n</code></pre> Notes <ul> <li>Utilizes Python's built-in <code>ipaddress</code> module for network operations.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def ip_network_parents(i, include_self=False):\n\"\"\"\n    Generates all parent IP networks for a given IP address or network, optionally including the network itself.\n\n    Args:\n        i (str or ipaddress.IPv4Network/ipaddress.IPv6Network): The IP address or network to find parents for.\n        include_self (bool, optional): Whether to include the network itself in the result. Default is False.\n\n    Yields:\n        ipaddress.IPv4Network or ipaddress.IPv6Network: Parent IP networks in descending order of prefix length.\n\n    Examples:\n        &gt;&gt;&gt; list(ip_network_parents(\"192.168.1.1\"))\n        [ipaddress.IPv4Network('192.168.1.0/31'), ipaddress.IPv4Network('192.168.1.0/30'), ... , ipaddress.IPv4Network('0.0.0.0/0')]\n\n    Notes:\n        - Utilizes Python's built-in `ipaddress` module for network operations.\n    \"\"\"\n    net = ipaddress.ip_network(i, strict=False)\n    for i in range(net.prefixlen - (0 if include_self else 1), -1, -1):\n        yield ipaddress.ip_network(f\"{net.network_address}/{i}\", strict=False)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_async_function","title":"is_async_function","text":"<pre><code>is_async_function(f)\n</code></pre> <p>Check if a given function is an asynchronous function.</p> <p>Parameters:</p> <ul> <li> <code>f</code>             (<code>function</code>)         \u2013          <p>The function to check.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the function is asynchronous, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; async def foo():\n...     pass\n&gt;&gt;&gt; is_async_function(foo)\nTrue\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_async_function(f):\n\"\"\"\n    Check if a given function is an asynchronous function.\n\n    Args:\n        f (function): The function to check.\n\n    Returns:\n        bool: True if the function is asynchronous, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; async def foo():\n        ...     pass\n        &gt;&gt;&gt; is_async_function(foo)\n        True\n    \"\"\"\n    return inspect.iscoroutinefunction(f)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_dns_name","title":"is_dns_name","text":"<pre><code>is_dns_name(d)\n</code></pre> <p>Determines if the given string is a valid DNS name.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>str</code>)         \u2013          <p>The string to be checked.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the string is a valid DNS name, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_dns_name('www.example.com')\nTrue\n&gt;&gt;&gt; is_dns_name('localhost')\nTrue\n&gt;&gt;&gt; is_dns_name('192.168.1.1')\nFalse\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_dns_name(d):\n\"\"\"\n    Determines if the given string is a valid DNS name.\n\n    Args:\n        d (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a valid DNS name, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; is_dns_name('www.example.com')\n        True\n        &gt;&gt;&gt; is_dns_name('localhost')\n        True\n        &gt;&gt;&gt; is_dns_name('192.168.1.1')\n        False\n    \"\"\"\n    if is_ip(d):\n        return False\n    d = smart_decode(d)\n    if bbot_regexes.hostname_regex.match(d):\n        return True\n    if bbot_regexes.dns_name_regex.match(d):\n        return True\n    return False\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_domain","title":"is_domain","text":"<pre><code>is_domain(d)\n</code></pre> <p>Check if the given input represents a domain without subdomains.</p> <p>This function takes an input string <code>d</code> and returns True if it represents a domain without any subdomains. Otherwise, it returns False.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>str</code>)         \u2013          <p>The input string containing the domain.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the input is a domain without subdomains, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_domain(\"evilcorp.co.uk\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; is_domain(\"www.evilcorp.co.uk\")\nFalse\n</code></pre> Notes <ul> <li>Port, if present in input, is ignored.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_domain(d):\n\"\"\"\n    Check if the given input represents a domain without subdomains.\n\n    This function takes an input string `d` and returns True if it represents a domain without any subdomains.\n    Otherwise, it returns False.\n\n    Args:\n        d (str): The input string containing the domain.\n\n    Returns:\n        bool: True if the input is a domain without subdomains, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; is_domain(\"evilcorp.co.uk\")\n        True\n\n        &gt;&gt;&gt; is_domain(\"www.evilcorp.co.uk\")\n        False\n\n    Notes:\n        - Port, if present in input, is ignored.\n    \"\"\"\n    d, _ = split_host_port(d)\n    extracted = tldextract(d)\n    if extracted.domain and not extracted.subdomain:\n        return True\n    return False\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_file","title":"is_file","text":"<pre><code>is_file(f)\n</code></pre> <p>Check if a path points to a file.</p> <p>Parameters:</p> <ul> <li> <code>f</code>             (<code>str</code>)         \u2013          <p>Path to the file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the path is a file, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_file(\"/etc/passwd\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; is_file(\"/nonexistent\")\nFalse\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_file(f):\n\"\"\"\n    Check if a path points to a file.\n\n    Parameters:\n        f (str): Path to the file.\n\n    Returns:\n        bool: True if the path is a file, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; is_file(\"/etc/passwd\")\n        True\n\n        &gt;&gt;&gt; is_file(\"/nonexistent\")\n        False\n    \"\"\"\n    with suppress(Exception):\n        return Path(f).is_file()\n    return False\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_ip","title":"is_ip","text":"<pre><code>is_ip(d, version = None)\n</code></pre> <p>Checks if the given string or object represents a valid IP address.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>str or IPvXAddress</code>)         \u2013          <p>The IP address to check.</p> </li> <li> <code>version</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>The IP version to validate (4 or 6). Default is None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the string or object is a valid IP address, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_ip('192.168.1.1')\nTrue\n&gt;&gt;&gt; is_ip('bad::c0de', version=6)\nTrue\n&gt;&gt;&gt; is_ip('bad::c0de', version=4)\nFalse\n&gt;&gt;&gt; is_ip('evilcorp.com')\nFalse\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_ip(d, version=None):\n\"\"\"\n    Checks if the given string or object represents a valid IP address.\n\n    Args:\n        d (str or ipaddress.IPvXAddress): The IP address to check.\n        version (int, optional): The IP version to validate (4 or 6). Default is None.\n\n    Returns:\n        bool: True if the string or object is a valid IP address, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; is_ip('192.168.1.1')\n        True\n        &gt;&gt;&gt; is_ip('bad::c0de', version=6)\n        True\n        &gt;&gt;&gt; is_ip('bad::c0de', version=4)\n        False\n        &gt;&gt;&gt; is_ip('evilcorp.com')\n        False\n    \"\"\"\n    if isinstance(d, (ipaddress.IPv4Address, ipaddress.IPv6Address)):\n        if version is None or version == d.version:\n            return True\n    try:\n        ip = ipaddress.ip_address(d)\n        if version is None or ip.version == version:\n            return True\n    except Exception:\n        pass\n    return False\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_ip_type","title":"is_ip_type","text":"<pre><code>is_ip_type(i)\n</code></pre> <p>Checks if the given object is an instance of an IPv4 or IPv6 type from the ipaddress module.</p> <p>Parameters:</p> <ul> <li> <code>i</code>             (<code>_BaseV4 or _BaseV6</code>)         \u2013          <p>The IP object to check.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the object is an instance of ipaddress._BaseV4 or ipaddress._BaseV6, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_ip_type(ipaddress.IPv6Address('dead::beef'))\nTrue\n&gt;&gt;&gt; is_ip_type(ipaddress.IPv4Network('192.168.1.0/24'))\nTrue\n&gt;&gt;&gt; is_ip_type(\"192.168.1.0/24\")\nFalse\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_ip_type(i):\n\"\"\"\n    Checks if the given object is an instance of an IPv4 or IPv6 type from the ipaddress module.\n\n    Args:\n        i (ipaddress._BaseV4 or ipaddress._BaseV6): The IP object to check.\n\n    Returns:\n        bool: True if the object is an instance of ipaddress._BaseV4 or ipaddress._BaseV6, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; is_ip_type(ipaddress.IPv6Address('dead::beef'))\n        True\n        &gt;&gt;&gt; is_ip_type(ipaddress.IPv4Network('192.168.1.0/24'))\n        True\n        &gt;&gt;&gt; is_ip_type(\"192.168.1.0/24\")\n        False\n    \"\"\"\n    return isinstance(i, ipaddress._BaseV4) or isinstance(i, ipaddress._BaseV6)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_port","title":"is_port","text":"<pre><code>is_port(p)\n</code></pre> <p>Checks if the given string represents a valid port number.</p> <p>Parameters:</p> <ul> <li> <code>p</code>             (<code>str or int</code>)         \u2013          <p>The port number to check.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the port number is valid, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_port('80')\nTrue\n&gt;&gt;&gt; is_port('70000')\nFalse\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_port(p):\n\"\"\"\n    Checks if the given string represents a valid port number.\n\n    Args:\n        p (str or int): The port number to check.\n\n    Returns:\n        bool: True if the port number is valid, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; is_port('80')\n        True\n        &gt;&gt;&gt; is_port('70000')\n        False\n    \"\"\"\n\n    p = str(p)\n    return p and p.isdigit() and 0 &lt;= int(p) &lt;= 65535\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_ptr","title":"is_ptr","text":"<pre><code>is_ptr(d)\n</code></pre> <p>Check if the given input represents a PTR record domain.</p> <p>This function takes an input string <code>d</code> and returns True if it matches the PTR record format. Otherwise, it returns False.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>str</code>)         \u2013          <p>The input string potentially representing a PTR record domain.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the input matches PTR record format, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_ptr(\"wsc-11-22-33-44.evilcorp.com\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; is_ptr(\"www2.evilcorp.com\")\nFalse\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_ptr(d):\n\"\"\"\n    Check if the given input represents a PTR record domain.\n\n    This function takes an input string `d` and returns True if it matches the PTR record format.\n    Otherwise, it returns False.\n\n    Args:\n        d (str): The input string potentially representing a PTR record domain.\n\n    Returns:\n        bool: True if the input matches PTR record format, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; is_ptr(\"wsc-11-22-33-44.evilcorp.com\")\n        True\n\n        &gt;&gt;&gt; is_ptr(\"www2.evilcorp.com\")\n        False\n    \"\"\"\n    return bool(bbot_regexes.ptr_regex.search(str(d)))\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_subdomain","title":"is_subdomain","text":"<pre><code>is_subdomain(d)\n</code></pre> <p>Check if the given input represents a subdomain.</p> <p>This function takes an input string <code>d</code> and returns True if it represents a subdomain. Otherwise, it returns False.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>str</code>)         \u2013          <p>The input string containing the domain or subdomain.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the input is a subdomain, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_subdomain(\"www.evilcorp.co.uk\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; is_subdomain(\"evilcorp.co.uk\")\nFalse\n</code></pre> Notes <ul> <li>Port, if present in input, is ignored.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_subdomain(d):\n\"\"\"\n    Check if the given input represents a subdomain.\n\n    This function takes an input string `d` and returns True if it represents a subdomain.\n    Otherwise, it returns False.\n\n    Args:\n        d (str): The input string containing the domain or subdomain.\n\n    Returns:\n        bool: True if the input is a subdomain, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; is_subdomain(\"www.evilcorp.co.uk\")\n        True\n\n        &gt;&gt;&gt; is_subdomain(\"evilcorp.co.uk\")\n        False\n\n    Notes:\n        - Port, if present in input, is ignored.\n    \"\"\"\n    d, _ = split_host_port(d)\n    extracted = tldextract(d)\n    if extracted.domain and extracted.subdomain:\n        return True\n    return False\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_uri","title":"is_uri","text":"<pre><code>is_uri(u, return_scheme = False)\n</code></pre> <p>Check if the given input represents a URI and optionally return its scheme.</p> <p>This function takes an input string <code>u</code> and returns True if it matches a URI format. When <code>return_scheme</code> is True, it returns the URI scheme instead of a boolean.</p> <p>Parameters:</p> <ul> <li> <code>u</code>             (<code>str</code>)         \u2013          <p>The input string potentially representing a URI.</p> </li> <li> <code>return_scheme</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to return the URI scheme. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>Union[bool, str]: True if the input matches a URI format; the URI scheme if <code>return_scheme</code> is True.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_uri(\"http://evilcorp.com\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; is_uri(\"ftp://evilcorp.com\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; is_uri(\"evilcorp.com\")\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; is_uri(\"ftp://evilcorp.com\", return_scheme=True)\n\"ftp\"\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_uri(u, return_scheme=False):\n\"\"\"\n    Check if the given input represents a URI and optionally return its scheme.\n\n    This function takes an input string `u` and returns True if it matches a URI format.\n    When `return_scheme` is True, it returns the URI scheme instead of a boolean.\n\n    Args:\n        u (str): The input string potentially representing a URI.\n        return_scheme (bool, optional): Whether to return the URI scheme. Defaults to False.\n\n    Returns:\n        Union[bool, str]: True if the input matches a URI format; the URI scheme if `return_scheme` is True.\n\n    Examples:\n        &gt;&gt;&gt; is_uri(\"http://evilcorp.com\")\n        True\n\n        &gt;&gt;&gt; is_uri(\"ftp://evilcorp.com\")\n        True\n\n        &gt;&gt;&gt; is_uri(\"evilcorp.com\")\n        False\n\n        &gt;&gt;&gt; is_uri(\"ftp://evilcorp.com\", return_scheme=True)\n        \"ftp\"\n    \"\"\"\n    match = uri_regex.match(u)\n    if return_scheme:\n        if match:\n            return match.groups()[0].lower()\n        return \"\"\n    return bool(match)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.is_url","title":"is_url","text":"<pre><code>is_url(u)\n</code></pre> <p>Check if the given input represents a valid URL.</p> <p>This function takes an input string <code>u</code> and returns True if it matches any of the predefined URL formats. Otherwise, it returns False.</p> <p>Parameters:</p> <ul> <li> <code>u</code>             (<code>str</code>)         \u2013          <p>The input string potentially representing a URL.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the input matches a valid URL format, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_url(\"https://evilcorp.com\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; is_url(\"not-a-url\")\nFalse\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def is_url(u):\n\"\"\"\n    Check if the given input represents a valid URL.\n\n    This function takes an input string `u` and returns True if it matches any of the predefined URL formats.\n    Otherwise, it returns False.\n\n    Args:\n        u (str): The input string potentially representing a URL.\n\n    Returns:\n        bool: True if the input matches a valid URL format, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; is_url(\"https://evilcorp.com\")\n        True\n\n        &gt;&gt;&gt; is_url(\"not-a-url\")\n        False\n    \"\"\"\n    u = str(u)\n    for r in bbot_regexes.event_type_regexes[\"URL\"]:\n        if r.match(u):\n            return True\n    return False\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.kill_children","title":"kill_children","text":"<pre><code>kill_children(parent_pid = None, sig = signal.SIGTERM)\n</code></pre> <p>Forgive me father for I have sinned</p> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def kill_children(parent_pid=None, sig=signal.SIGTERM):\n\"\"\"\n    Forgive me father for I have sinned\n    \"\"\"\n    try:\n        parent = psutil.Process(parent_pid)\n    except psutil.NoSuchProcess:\n        log.debug(f\"No such PID: {parent_pid}\")\n    log.debug(f\"Killing children of process ID {parent.pid}\")\n    children = parent.children(recursive=True)\n    for child in children:\n        log.debug(f\"Killing child with PID {child.pid}\")\n        if child.name != \"python\":\n            try:\n                child.send_signal(sig)\n            except psutil.NoSuchProcess:\n                log.debug(f\"No such PID: {child.pid}\")\n            except psutil.AccessDenied:\n                log.debug(f\"Error killing PID: {child.pid} - access denied\")\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.latest_mtime","title":"latest_mtime","text":"<pre><code>latest_mtime(d)\n</code></pre> <p>Get the latest modified time of any file or sub-directory in a given directory.</p> <p>This function takes a directory path as an argument and returns the latest modified time of any contained file or directory, recursively. It's useful for sorting directories by modified time for cleanup or other purposes.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>str or Path</code>)         \u2013          <p>The directory path to search for the latest modified time.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>        \u2013          <p>The latest modified time in Unix timestamp format.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; latest_mtime(\"~/.bbot/scans/mushy_susan\")\n1659016928.2848816\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def latest_mtime(d):\n\"\"\"Get the latest modified time of any file or sub-directory in a given directory.\n\n    This function takes a directory path as an argument and returns the latest modified time\n    of any contained file or directory, recursively. It's useful for sorting directories by\n    modified time for cleanup or other purposes.\n\n    Args:\n        d (str or Path): The directory path to search for the latest modified time.\n\n    Returns:\n        float: The latest modified time in Unix timestamp format.\n\n    Examples:\n        &gt;&gt;&gt; latest_mtime(\"~/.bbot/scans/mushy_susan\")\n        1659016928.2848816\n    \"\"\"\n    d = Path(d).resolve()\n    mtimes = [d.lstat().st_mtime]\n    if d.is_dir():\n        to_list = d.glob(\"**/*\")\n    else:\n        to_list = [d]\n    for e in to_list:\n        mtimes.append(e.lstat().st_mtime)\n    return max(mtimes)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.list_files","title":"list_files","text":"<pre><code>list_files(directory, filter = lambda : True)\n</code></pre> <p>Lists files in a given directory that meet a specified filter condition.</p> <p>Parameters:</p> <ul> <li> <code>directory</code>             (<code>str</code>)         \u2013          <p>The directory where to list files.</p> </li> <li> <code>filter</code>             (<code>callable</code>, default:                 <code>lambda : True</code> )         \u2013          <p>A function to filter the files. Defaults to a lambda function that returns True for all files.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>Path</code>        \u2013          <p>A Path object for each file that meets the filter condition.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; list(list_files(\"/tmp/test\"))\n[Path('/tmp/test/file1.py'), Path('/tmp/test/file2.txt')]\n</code></pre> <pre><code>&gt;&gt;&gt; list(list_files(\"/tmp/test\"), filter=lambda f: f.suffix == \".py\")\n[Path('/tmp/test/file1.py')]\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def list_files(directory, filter=lambda x: True):\n\"\"\"Lists files in a given directory that meet a specified filter condition.\n\n    Args:\n        directory (str): The directory where to list files.\n        filter (callable, optional): A function to filter the files. Defaults to a lambda function that returns True for all files.\n\n    Yields:\n        Path: A Path object for each file that meets the filter condition.\n\n    Examples:\n        &gt;&gt;&gt; list(list_files(\"/tmp/test\"))\n        [Path('/tmp/test/file1.py'), Path('/tmp/test/file2.txt')]\n\n        &gt;&gt;&gt; list(list_files(\"/tmp/test\"), filter=lambda f: f.suffix == \".py\")\n        [Path('/tmp/test/file1.py')]\n    \"\"\"\n    directory = Path(directory).resolve()\n    if directory.is_dir():\n        for file in directory.iterdir():\n            if file.is_file() and filter(file):\n                yield file\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.make_date","title":"make_date","text":"<pre><code>make_date(d = None, microseconds = False)\n</code></pre> <p>Generates a string representation of the current date and time, with optional microsecond precision.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>datetime</code>, default:                 <code>None</code> )         \u2013          <p>A datetime object to convert. Defaults to the current date and time.</p> </li> <li> <code>microseconds</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether to include microseconds. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>A string representation of the date and time, formatted as YYYYMMDD_HHMM_SS or YYYYMMDD_HHMM_SSFFFFFF if microseconds are included.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; make_date()\n\"20220707_1325_50\"\n&gt;&gt;&gt; make_date(microseconds=True)\n\"20220707_1330_35167617\"\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def make_date(d=None, microseconds=False):\n\"\"\"\n    Generates a string representation of the current date and time, with optional microsecond precision.\n\n    Args:\n        d (datetime, optional): A datetime object to convert. Defaults to the current date and time.\n        microseconds (bool, optional): Whether to include microseconds. Defaults to False.\n\n    Returns:\n        str: A string representation of the date and time, formatted as YYYYMMDD_HHMM_SS or YYYYMMDD_HHMM_SSFFFFFF if microseconds are included.\n\n    Examples:\n        &gt;&gt;&gt; make_date()\n        \"20220707_1325_50\"\n        &gt;&gt;&gt; make_date(microseconds=True)\n        \"20220707_1330_35167617\"\n    \"\"\"\n    f = \"%Y%m%d_%H%M_%S\"\n    if microseconds:\n        f += \"%f\"\n    if d is None:\n        d = datetime.now()\n    return d.strftime(f)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.make_ip_type","title":"make_ip_type","text":"<pre><code>make_ip_type(s)\n</code></pre> <p>Convert a string to its corresponding IP address or network type.</p> <p>This function attempts to convert the input string <code>s</code> into either an IPv4 or IPv6 address object, or an IPv4 or IPv6 network object. If none of these conversions are possible, the original string is returned.</p> <p>Parameters:</p> <ul> <li> <code>s</code>             (<code>str</code>)         \u2013          <p>The input string to be converted.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>Union[IPv4Address, IPv6Address, IPv4Network, IPv6Network, str]: The converted object or original string.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; make_ip_type(\"dead::beef\")\nIPv6Address('dead::beef')\n</code></pre> <pre><code>&gt;&gt;&gt; make_ip_type(\"192.168.1.0/24\")\nIPv4Network('192.168.1.0/24')\n</code></pre> <pre><code>&gt;&gt;&gt; make_ip_type(\"evilcorp.com\")\n'evilcorp.com'\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def make_ip_type(s):\n\"\"\"\n    Convert a string to its corresponding IP address or network type.\n\n    This function attempts to convert the input string `s` into either an IPv4 or IPv6 address object,\n    or an IPv4 or IPv6 network object. If none of these conversions are possible, the original string is returned.\n\n    Args:\n        s (str): The input string to be converted.\n\n    Returns:\n        Union[IPv4Address, IPv6Address, IPv4Network, IPv6Network, str]: The converted object or original string.\n\n    Examples:\n        &gt;&gt;&gt; make_ip_type(\"dead::beef\")\n        IPv6Address('dead::beef')\n\n        &gt;&gt;&gt; make_ip_type(\"192.168.1.0/24\")\n        IPv4Network('192.168.1.0/24')\n\n        &gt;&gt;&gt; make_ip_type(\"evilcorp.com\")\n        'evilcorp.com'\n    \"\"\"\n    # IP address\n    with suppress(Exception):\n        return ipaddress.ip_address(str(s).strip())\n    # IP network\n    with suppress(Exception):\n        return ipaddress.ip_network(str(s).strip(), strict=False)\n    return s\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.make_netloc","title":"make_netloc","text":"<pre><code>make_netloc(host, port)\n</code></pre> <p>Constructs a network location string from a given host and port.</p> <p>Parameters:</p> <ul> <li> <code>host</code>             (<code>str</code>)         \u2013          <p>The hostname or IP address.</p> </li> <li> <code>port</code>             (<code>int</code>)         \u2013          <p>The port number. If None, the port is omitted.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>A network location string in the form 'host' or 'host:port'.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; make_netloc(\"192.168.1.1\", None)\n\"192.168.1.1\"\n</code></pre> <pre><code>&gt;&gt;&gt; make_netloc(\"192.168.1.1\", 443)\n\"192.168.1.1:443\"\n</code></pre> <pre><code>&gt;&gt;&gt; make_netloc(\"evilcorp.com\", 80)\n\"evilcorp.com:80\"\n</code></pre> <pre><code>&gt;&gt;&gt; make_netloc(\"dead::beef\", None)\n\"[dead::beef]\"\n</code></pre> <pre><code>&gt;&gt;&gt; make_netloc(\"dead::beef\", 443)\n\"[dead::beef]:443\"\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def make_netloc(host, port):\n\"\"\"Constructs a network location string from a given host and port.\n\n    Args:\n        host (str): The hostname or IP address.\n        port (int, optional): The port number. If None, the port is omitted.\n\n    Returns:\n        str: A network location string in the form 'host' or 'host:port'.\n\n    Examples:\n        &gt;&gt;&gt; make_netloc(\"192.168.1.1\", None)\n        \"192.168.1.1\"\n\n        &gt;&gt;&gt; make_netloc(\"192.168.1.1\", 443)\n        \"192.168.1.1:443\"\n\n        &gt;&gt;&gt; make_netloc(\"evilcorp.com\", 80)\n        \"evilcorp.com:80\"\n\n        &gt;&gt;&gt; make_netloc(\"dead::beef\", None)\n        \"[dead::beef]\"\n\n        &gt;&gt;&gt; make_netloc(\"dead::beef\", 443)\n        \"[dead::beef]:443\"\n    \"\"\"\n    if is_ip(host, version=6):\n        host = f\"[{host}]\"\n    if port is None:\n        return host\n    return f\"{host}:{port}\"\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.make_table","title":"make_table","text":"<pre><code>make_table(*args, **kwargs)\n</code></pre> <p>Generate a formatted table from the given rows and headers.</p> <p>This function uses the <code>tabulate</code> package to generate a table with formatting options. It can accept various input formats and table styles, which can be customized using optional arguments.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Positional arguments to be passed to <code>tabulate.tabulate</code>.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Keyword arguments to customize table formatting. - tablefmt (str, optional): Table format. Default is 'grid'. - disable_numparse (bool, optional): Disable automatic number parsing. Default is True. - maxcolwidths (int, optional): Maximum column width. Default is 40.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>A string representing the formatted table.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; print(make_table([[\"row1\", \"row1\"], [\"row2\", \"row2\"]], [\"header1\", \"header2\"]))\n+-----------+-----------+\n| header1   | header2   |\n+===========+===========+\n| row1      | row1      |\n+-----------+-----------+\n| row2      | row2      |\n+-----------+-----------+\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def make_table(*args, **kwargs):\n\"\"\"Generate a formatted table from the given rows and headers.\n\n    This function uses the `tabulate` package to generate a table with formatting options.\n    It can accept various input formats and table styles, which can be customized using optional arguments.\n\n    Args:\n        *args: Positional arguments to be passed to `tabulate.tabulate`.\n        **kwargs: Keyword arguments to customize table formatting.\n            - tablefmt (str, optional): Table format. Default is 'grid'.\n            - disable_numparse (bool, optional): Disable automatic number parsing. Default is True.\n            - maxcolwidths (int, optional): Maximum column width. Default is 40.\n\n    Returns:\n        str: A string representing the formatted table.\n\n    Examples:\n        &gt;&gt;&gt; print(make_table([[\"row1\", \"row1\"], [\"row2\", \"row2\"]], [\"header1\", \"header2\"]))\n        +-----------+-----------+\n        | header1   | header2   |\n        +===========+===========+\n        | row1      | row1      |\n        +-----------+-----------+\n        | row2      | row2      |\n        +-----------+-----------+\n    \"\"\"\n    # fix IndexError: list index out of range\n    if args and not args[0]:\n        args = ([[]],) + args[1:]\n    tablefmt = os.environ.get(\"BBOT_TABLE_FORMAT\", None)\n    defaults = {\"tablefmt\": \"grid\", \"disable_numparse\": True, \"maxcolwidths\": None}\n    if tablefmt is None:\n        defaults.update({\"maxcolwidths\": 40})\n    else:\n        defaults.update({\"tablefmt\": tablefmt})\n    for k, v in defaults.items():\n        if k not in kwargs:\n            kwargs[k] = v\n    # don't wrap columns in markdown\n    if tablefmt in (\"github\", \"markdown\"):\n        kwargs.pop(\"maxcolwidths\")\n    return tabulate(*args, **kwargs)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.match_and_exit","title":"match_and_exit","text":"<pre><code>match_and_exit(s, choices, msg = None, loglevel = 'HUGEWARNING', exitcode = 2)\n</code></pre> <p>Finds the closest match from a list of choices for a given string, logs a warning, and exits the program.</p> <p>This function is particularly useful for CLI applications where you want to validate flags or modules.</p> <p>Parameters:</p> <ul> <li> <code>s</code>             (<code>str</code>)         \u2013          <p>The string for which to find the closest match.</p> </li> <li> <code>choices</code>             (<code>list</code>)         \u2013          <p>A list of strings to compare against.</p> </li> <li> <code>msg</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>Additional message to prepend in the warning message. Defaults to None.</p> </li> <li> <code>loglevel</code>             (<code>str</code>, default:                 <code>'HUGEWARNING'</code> )         \u2013          <p>The log level to use for the warning message. Defaults to \"HUGEWARNING\".</p> </li> <li> <code>exitcode</code>             (<code>int</code>, default:                 <code>2</code> )         \u2013          <p>The exit code to use when exiting the program. Defaults to 2.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; match_and_exit(\"some_module\", [\"some_mod\", \"some_other_mod\"], msg=\"module\")\n# Output: Could not find module \"some_module\". Did you mean \"some_mod\"?\n# Exits with code 2\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def match_and_exit(s, choices, msg=None, loglevel=\"HUGEWARNING\", exitcode=2):\n\"\"\"Finds the closest match from a list of choices for a given string, logs a warning, and exits the program.\n\n    This function is particularly useful for CLI applications where you want to validate flags or modules.\n\n    Args:\n        s (str): The string for which to find the closest match.\n        choices (list): A list of strings to compare against.\n        msg (str, optional): Additional message to prepend in the warning message. Defaults to None.\n        loglevel (str, optional): The log level to use for the warning message. Defaults to \"HUGEWARNING\".\n        exitcode (int, optional): The exit code to use when exiting the program. Defaults to 2.\n\n    Examples:\n        &gt;&gt;&gt; match_and_exit(\"some_module\", [\"some_mod\", \"some_other_mod\"], msg=\"module\")\n        # Output: Could not find module \"some_module\". Did you mean \"some_mod\"?\n        # Exits with code 2\n    \"\"\"\n    if msg is None:\n        msg = \"\"\n    else:\n        msg += \" \"\n    closest = closest_match(s, choices)\n    log_to_stderr(f'Could not find {msg}\"{s}\". Did you mean \"{closest}\"?', level=\"HUGEWARNING\")\n    sys.exit(2)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.memory_status","title":"memory_status","text":"<pre><code>memory_status()\n</code></pre> <p>Return statistics on system memory consumption.</p> <p>The function returns a <code>psutil</code> named tuple that contains statistics on system virtual memory usage, such as total memory, used memory, available memory, and more.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>psutil._pslinux.svmem: A named tuple representing various statistics about system virtual memory usage.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mem = memory_status()\n&gt;&gt;&gt; mem.available\n13195399168\n</code></pre> <pre><code>&gt;&gt;&gt; mem = memory_status()\n&gt;&gt;&gt; mem.percent\n79.0\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def memory_status():\n\"\"\"Return statistics on system memory consumption.\n\n    The function returns a `psutil` named tuple that contains statistics on\n    system virtual memory usage, such as total memory, used memory, available\n    memory, and more.\n\n    Returns:\n        psutil._pslinux.svmem: A named tuple representing various statistics\n            about system virtual memory usage.\n\n    Examples:\n        &gt;&gt;&gt; mem = memory_status()\n        &gt;&gt;&gt; mem.available\n        13195399168\n\n        &gt;&gt;&gt; mem = memory_status()\n        &gt;&gt;&gt; mem.percent\n        79.0\n    \"\"\"\n    return psutil.virtual_memory()\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.mkdir","title":"mkdir","text":"<pre><code>mkdir(path, check_writable = True, raise_error = True)\n</code></pre> <p>Creates a directory and optionally checks if it's writable.</p> <p>Parameters:</p> <ul> <li> <code>path</code>             (<code>str or Path</code>)         \u2013          <p>The directory to create.</p> </li> <li> <code>check_writable</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to check if the directory is writable. Default is True.</p> </li> <li> <code>raise_error</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to raise an error if the directory creation fails. Default is True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the directory is successfully created (and writable, if check_writable=True); otherwise False.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>DirectoryCreationError</code>           \u2013          <p>Raised if the directory cannot be created and <code>raise_error=True</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mkdir(\"/tmp/new_dir\")\nTrue\n&gt;&gt;&gt; mkdir(\"/restricted_dir\", check_writable=False, raise_error=False)\nFalse\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def mkdir(path, check_writable=True, raise_error=True):\n\"\"\"\n    Creates a directory and optionally checks if it's writable.\n\n    Args:\n        path (str or Path): The directory to create.\n        check_writable (bool, optional): Whether to check if the directory is writable. Default is True.\n        raise_error (bool, optional): Whether to raise an error if the directory creation fails. Default is True.\n\n    Returns:\n        bool: True if the directory is successfully created (and writable, if check_writable=True); otherwise False.\n\n    Raises:\n        DirectoryCreationError: Raised if the directory cannot be created and `raise_error=True`.\n\n    Examples:\n        &gt;&gt;&gt; mkdir(\"/tmp/new_dir\")\n        True\n        &gt;&gt;&gt; mkdir(\"/restricted_dir\", check_writable=False, raise_error=False)\n        False\n    \"\"\"\n    path = Path(path).resolve()\n    touchfile = path / f\".{rand_string()}\"\n    try:\n        path.mkdir(exist_ok=True, parents=True)\n        touchfile.touch()\n        return True\n    except Exception as e:\n        if raise_error:\n            raise errors.DirectoryCreationError(f\"Failed to create directory at {path}: {e}\")\n    finally:\n        with suppress(Exception):\n            touchfile.unlink()\n    return False\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.os_platform","title":"os_platform","text":"<pre><code>os_platform()\n</code></pre> <p>Return the OS platform of the current system.</p> <p>This function fetches and returns the OS type where the code is being executed. It converts the platform identifier to lowercase.</p> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>A string representing the OS platform, such as \"linux\", \"darwin\", or \"windows\".</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; os_platform()\n'linux'\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def os_platform():\n\"\"\"Return the OS platform of the current system.\n\n    This function fetches and returns the OS type where the code is being executed.\n    It converts the platform identifier to lowercase.\n\n    Returns:\n        str: A string representing the OS platform, such as \"linux\", \"darwin\", or \"windows\".\n\n    Examples:\n        &gt;&gt;&gt; os_platform()\n        'linux'\n    \"\"\"\n    return platform.system().lower()\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.os_platform_friendly","title":"os_platform_friendly","text":"<pre><code>os_platform_friendly()\n</code></pre> <p>Return a human-friendly OS platform string, suitable for golang release binaries.</p> <p>This function fetches the OS platform and modifies it to a more human-readable format if necessary. Specifically, it changes \"darwin\" to \"macOS\".</p> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>A string representing the human-friendly OS platform, such as \"macOS\", \"linux\", or \"windows\".</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; os_platform_friendly()\n'macOS'\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def os_platform_friendly():\n\"\"\"Return a human-friendly OS platform string, suitable for golang release binaries.\n\n    This function fetches the OS platform and modifies it to a more human-readable format if necessary.\n    Specifically, it changes \"darwin\" to \"macOS\".\n\n    Returns:\n        str: A string representing the human-friendly OS platform, such as \"macOS\", \"linux\", or \"windows\".\n\n    Examples:\n        &gt;&gt;&gt; os_platform_friendly()\n        'macOS'\n    \"\"\"\n    p = os_platform()\n    if p == \"darwin\":\n        return \"macOS\"\n    return p\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.parent_domain","title":"parent_domain","text":"<pre><code>parent_domain(d)\n</code></pre> <p>Retrieve the parent domain of a given subdomain string.</p> <p>This function takes an input string <code>d</code> representing a subdomain and returns its parent domain. If the input does not represent a subdomain, it returns the input as is.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>str</code>)         \u2013          <p>The input string representing a subdomain or domain.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>The parent domain of the subdomain, or the original input if it is not a subdomain.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; parent_domain(\"www.internal.evilcorp.co.uk\")\n\"internal.evilcorp.co.uk\"\n</code></pre> <pre><code>&gt;&gt;&gt; parent_domain(\"www.internal.evilcorp.co.uk:8080\")\n\"internal.evilcorp.co.uk:8080\"\n</code></pre> <pre><code>&gt;&gt;&gt; parent_domain(\"www.evilcorp.co.uk\")\n\"evilcorp.co.uk\"\n</code></pre> <pre><code>&gt;&gt;&gt; parent_domain(\"evilcorp.co.uk\")\n\"evilcorp.co.uk\"\n</code></pre> Notes <ul> <li>Port, if present in input, is preserved in the output.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def parent_domain(d):\n\"\"\"\n    Retrieve the parent domain of a given subdomain string.\n\n    This function takes an input string `d` representing a subdomain and returns its parent domain.\n    If the input does not represent a subdomain, it returns the input as is.\n\n    Args:\n        d (str): The input string representing a subdomain or domain.\n\n    Returns:\n        str: The parent domain of the subdomain, or the original input if it is not a subdomain.\n\n    Examples:\n        &gt;&gt;&gt; parent_domain(\"www.internal.evilcorp.co.uk\")\n        \"internal.evilcorp.co.uk\"\n\n        &gt;&gt;&gt; parent_domain(\"www.internal.evilcorp.co.uk:8080\")\n        \"internal.evilcorp.co.uk:8080\"\n\n        &gt;&gt;&gt; parent_domain(\"www.evilcorp.co.uk\")\n        \"evilcorp.co.uk\"\n\n        &gt;&gt;&gt; parent_domain(\"evilcorp.co.uk\")\n        \"evilcorp.co.uk\"\n\n    Notes:\n        - Port, if present in input, is preserved in the output.\n    \"\"\"\n    host, port = split_host_port(d)\n    if is_subdomain(d):\n        return make_netloc(\".\".join(str(host).split(\".\")[1:]), port)\n    return d\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.parent_url","title":"parent_url","text":"<pre><code>parent_url(u)\n</code></pre> <p>Retrieve the parent URL of a given URL.</p> <p>This function takes an input string <code>u</code> representing a URL and returns its parent URL. If the input URL does not have a parent (i.e., it's already the top-level), it returns None.</p> <p>Parameters:</p> <ul> <li> <code>u</code>             (<code>str</code>)         \u2013          <p>The input string representing a URL.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>Union[str, None]: The parent URL of the input URL, or None if it has no parent.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; parent_url(\"https://evilcorp.com/sub/path/\")\n\"https://evilcorp.com/sub/\"\n</code></pre> <pre><code>&gt;&gt;&gt; parent_url(\"https://evilcorp.com/\")\nNone\n</code></pre> Notes <ul> <li>Only the path component of the URL is modified.</li> <li>All other components like scheme, netloc, query, and fragment are preserved.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def parent_url(u):\n\"\"\"\n    Retrieve the parent URL of a given URL.\n\n    This function takes an input string `u` representing a URL and returns its parent URL.\n    If the input URL does not have a parent (i.e., it's already the top-level), it returns None.\n\n    Args:\n        u (str): The input string representing a URL.\n\n    Returns:\n        Union[str, None]: The parent URL of the input URL, or None if it has no parent.\n\n    Examples:\n        &gt;&gt;&gt; parent_url(\"https://evilcorp.com/sub/path/\")\n        \"https://evilcorp.com/sub/\"\n\n        &gt;&gt;&gt; parent_url(\"https://evilcorp.com/\")\n        None\n\n    Notes:\n        - Only the path component of the URL is modified.\n        - All other components like scheme, netloc, query, and fragment are preserved.\n    \"\"\"\n    parsed = urlparse(u)\n    path = Path(parsed.path)\n    if path.parent == path:\n        return None\n    else:\n        return urlunparse(parsed._replace(path=str(path.parent)))\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.parse_list_string","title":"parse_list_string","text":"<pre><code>parse_list_string(list_string)\n</code></pre> <p>Parses a comma-separated string into a list, removing invalid characters.</p> <p>Parameters:</p> <ul> <li> <code>list_string</code>             (<code>str</code>)         \u2013          <p>The string containing elements separated by commas.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>        \u2013          <p>A list of individual elements parsed from the input string.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If the input string contains invalid characters.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; parse_list_string(\"html,js,css\")\n['html', 'js', 'css']\n</code></pre> <pre><code>&gt;&gt;&gt; parse_list_string(\"png,jpg,gif\")\n['png', 'jpg', 'gif']\n</code></pre> <pre><code>&gt;&gt;&gt; parse_list_string(\"invalid&lt;&gt;char\")\nValueError: Invalid character in string: invalid&lt;&gt;char\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def parse_list_string(list_string):\n\"\"\"\n    Parses a comma-separated string into a list, removing invalid characters.\n\n    Args:\n        list_string (str): The string containing elements separated by commas.\n\n    Returns:\n        list: A list of individual elements parsed from the input string.\n\n    Raises:\n        ValueError: If the input string contains invalid characters.\n\n    Examples:\n        &gt;&gt;&gt; parse_list_string(\"html,js,css\")\n        ['html', 'js', 'css']\n\n        &gt;&gt;&gt; parse_list_string(\"png,jpg,gif\")\n        ['png', 'jpg', 'gif']\n\n        &gt;&gt;&gt; parse_list_string(\"invalid&lt;&gt;char\")\n        ValueError: Invalid character in string: invalid&lt;&gt;char\n    \"\"\"\n    elements = list_string.split(\",\")\n    result = []\n\n    for element in elements:\n        if any((c in '&lt;&gt;:\"/\\\\|?*') or (ord(c) &lt; 32 and c != \" \") for c in element):\n            raise ValueError(f\"Invalid character in string: {element}\")\n        result.append(element)\n    return result\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.parse_port_string","title":"parse_port_string","text":"<pre><code>parse_port_string(port_string)\n</code></pre> <p>Parses a string containing ports and port ranges into a list of individual ports.</p> <p>Parameters:</p> <ul> <li> <code>port_string</code>             (<code>str</code>)         \u2013          <p>The string containing individual ports and port ranges separated by commas.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>        \u2013          <p>A list of individual ports parsed from the input string.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If the input string contains invalid ports or port ranges.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; parse_port_string(\"22,80,1000-1002\")\n[22, 80, 1000, 1001, 1002]\n</code></pre> <pre><code>&gt;&gt;&gt; parse_port_string(\"1-2,3-5\")\n[1, 2, 3, 4, 5]\n</code></pre> <pre><code>&gt;&gt;&gt; parse_port_string(\"invalid\")\nValueError: Invalid port or port range: invalid\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def parse_port_string(port_string):\n\"\"\"\n    Parses a string containing ports and port ranges into a list of individual ports.\n\n    Args:\n        port_string (str): The string containing individual ports and port ranges separated by commas.\n\n    Returns:\n        list: A list of individual ports parsed from the input string.\n\n    Raises:\n        ValueError: If the input string contains invalid ports or port ranges.\n\n    Examples:\n        &gt;&gt;&gt; parse_port_string(\"22,80,1000-1002\")\n        [22, 80, 1000, 1001, 1002]\n\n        &gt;&gt;&gt; parse_port_string(\"1-2,3-5\")\n        [1, 2, 3, 4, 5]\n\n        &gt;&gt;&gt; parse_port_string(\"invalid\")\n        ValueError: Invalid port or port range: invalid\n    \"\"\"\n    elements = port_string.split(\",\")\n    ports = []\n\n    for element in elements:\n        if element.isdigit():\n            port = int(element)\n            if 1 &lt;= port &lt;= 65535:\n                ports.append(port)\n            else:\n                raise ValueError(f\"Invalid port: {element}\")\n        elif \"-\" in element:\n            range_parts = element.split(\"-\")\n            if len(range_parts) != 2 or not all(part.isdigit() for part in range_parts):\n                raise ValueError(f\"Invalid port or port range: {element}\")\n            start, end = map(int, range_parts)\n            if not (1 &lt;= start &lt; end &lt;= 65535):\n                raise ValueError(f\"Invalid port range: {element}\")\n            ports.extend(range(start, end + 1))\n        else:\n            raise ValueError(f\"Invalid port or port range: {element}\")\n\n    return ports\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.rand_string","title":"rand_string","text":"<pre><code>rand_string(length = 10, digits = True)\n</code></pre> <p>Generates a random string of specified length.</p> <p>Parameters:</p> <ul> <li> <code>length</code>             (<code>int</code>, default:                 <code>10</code> )         \u2013          <p>The length of the random string. Defaults to 10.</p> </li> <li> <code>digits</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to include digits in the string. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>A random string of the specified length.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; rand_string()\n'c4hp4i9jzx'\n&gt;&gt;&gt; rand_string(20)\n'ap4rsdtg5iw7ey7y3oa5'\n&gt;&gt;&gt; rand_string(30, digits=False)\n'xdmyxtglqfzqktngkesyulwbfrihva'\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def rand_string(length=10, digits=True):\n\"\"\"\n    Generates a random string of specified length.\n\n    Args:\n        length (int, optional): The length of the random string. Defaults to 10.\n        digits (bool, optional): Whether to include digits in the string. Defaults to True.\n\n    Returns:\n        str: A random string of the specified length.\n\n    Examples:\n        &gt;&gt;&gt; rand_string()\n        'c4hp4i9jzx'\n        &gt;&gt;&gt; rand_string(20)\n        'ap4rsdtg5iw7ey7y3oa5'\n        &gt;&gt;&gt; rand_string(30, digits=False)\n        'xdmyxtglqfzqktngkesyulwbfrihva'\n    \"\"\"\n    pool = rand_pool\n    if digits:\n        pool = rand_pool_digits\n    return \"\".join([random.choice(pool) for _ in range(int(length))])\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.read_file","title":"read_file","text":"<pre><code>read_file(filename)\n</code></pre> <p>Reads a file line by line and yields each line without line breaks.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>             (<code>str or Path</code>)         \u2013          <p>The path to the file to read.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>str</code>        \u2013          <p>A line from the file without the trailing line break.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; for line in read_file(\"/tmp/file.txt\"):\n...     print(line)\nfile_line1\nfile_line2\nfile_line3\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def read_file(filename):\n\"\"\"Reads a file line by line and yields each line without line breaks.\n\n    Args:\n        filename (str or Path): The path to the file to read.\n\n    Yields:\n        str: A line from the file without the trailing line break.\n\n    Examples:\n        &gt;&gt;&gt; for line in read_file(\"/tmp/file.txt\"):\n        ...     print(line)\n        file_line1\n        file_line2\n        file_line3\n    \"\"\"\n    with open(filename, errors=\"ignore\") as f:\n        for line in f:\n            yield line.rstrip(\"\\r\\n\")\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.recursive_decode","title":"recursive_decode","text":"<pre><code>recursive_decode(data, max_depth = 5)\n</code></pre> <p>Recursively decodes doubly or triply-encoded strings to their original form.</p> <p>Supports both URL-encoding and backslash-escapes (including unicode)</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>str</code>)         \u2013          <p>The data to decode.</p> </li> <li> <code>max_depth</code>             (<code>int</code>, default:                 <code>5</code> )         \u2013          <p>Maximum recursion depth for decoding. Defaults to 5.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>The decoded string.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; recursive_decode(\"Hello%20world%21\")\n\"Hello world!\"\n&gt;&gt;&gt; recursive_decode(\"Hello%20%5Cu041f%5Cu0440%5Cu0438%5Cu0432%5Cu0435%5Cu0442\")\n\"Hello \u041f\u0440\u0438\u0432\u0435\u0442\"\n&gt;&gt;&gt; recursive_dcode(\"%5Cu0020%5Cu041f%5Cu0440%5Cu0438%5Cu0432%5Cu0435%5Cu0442%5Cu0021\")\n\" \u041f\u0440\u0438\u0432\u0435\u0442!\"\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def recursive_decode(data, max_depth=5):\n\"\"\"\n    Recursively decodes doubly or triply-encoded strings to their original form.\n\n    Supports both URL-encoding and backslash-escapes (including unicode)\n\n    Args:\n        data (str): The data to decode.\n        max_depth (int, optional): Maximum recursion depth for decoding. Defaults to 5.\n\n    Returns:\n        str: The decoded string.\n\n    Examples:\n        &gt;&gt;&gt; recursive_decode(\"Hello%20world%21\")\n        \"Hello world!\"\n        &gt;&gt;&gt; recursive_decode(\"Hello%20%5Cu041f%5Cu0440%5Cu0438%5Cu0432%5Cu0435%5Cu0442\")\n        \"Hello \u041f\u0440\u0438\u0432\u0435\u0442\"\n        &gt;&gt;&gt; recursive_dcode(\"%5Cu0020%5Cu041f%5Cu0440%5Cu0438%5Cu0432%5Cu0435%5Cu0442%5Cu0021\")\n        \" \u041f\u0440\u0438\u0432\u0435\u0442!\"\n    \"\"\"\n    # Decode newline and tab escapes\n    data = backslash_regex.sub(\n        lambda match: {\"n\": \"\\n\", \"t\": \"\\t\", \"r\": \"\\r\", \"b\": \"\\b\", \"v\": \"\\v\"}.get(match.group(\"char\")), data\n    )\n    data = smart_decode(data)\n    if max_depth == 0:\n        return data\n    # Decode URL encoding\n    data = unquote(data, errors=\"ignore\")\n    # Decode Unicode escapes\n    with suppress(UnicodeEncodeError):\n        data = codecs.decode(data, \"unicode_escape\", errors=\"ignore\")\n    # Check if there's still URL-encoded or Unicode-escaped content\n    if encoded_regex.search(data):\n        # If yes, continue decoding\n        return recursive_decode(data, max_depth=max_depth - 1)\n\n    return data\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.rm_at_exit","title":"rm_at_exit","text":"<pre><code>rm_at_exit(path)\n</code></pre> <p>Registers a file to be automatically deleted when the program exits.</p> <p>Parameters:</p> <ul> <li> <code>path</code>             (<code>str or Path</code>)         \u2013          <p>The path to the file to be deleted upon program exit.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; rm_at_exit(\"/tmp/test/file1.txt\")\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def rm_at_exit(path):\n\"\"\"Registers a file to be automatically deleted when the program exits.\n\n    Args:\n        path (str or Path): The path to the file to be deleted upon program exit.\n\n    Examples:\n        &gt;&gt;&gt; rm_at_exit(\"/tmp/test/file1.txt\")\n    \"\"\"\n    atexit.register(delete_file, path)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.search_dict_by_key","title":"search_dict_by_key","text":"<pre><code>search_dict_by_key(key, d)\n</code></pre> <p>Search a nested dictionary or list of dictionaries by a key and yield all matching values.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>The key to search for.</p> </li> <li> <code>d</code>             (<code>Union[dict, list]</code>)         \u2013          <p>The dictionary or list of dictionaries to search.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>Any</code>        \u2013          <p>Yields all values that match the provided key.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; d = {'a': 1, 'b': {'c': 2, 'a': 3}, 'd': [{'a': 4}, {'e': 5}]}\n&gt;&gt;&gt; list(search_dict_by_key('a', d))\n[1, 3, 4]\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def search_dict_by_key(key, d):\n\"\"\"Search a nested dictionary or list of dictionaries by a key and yield all matching values.\n\n    Args:\n        key (str): The key to search for.\n        d (Union[dict, list]): The dictionary or list of dictionaries to search.\n\n    Yields:\n        Any: Yields all values that match the provided key.\n\n    Examples:\n        &gt;&gt;&gt; d = {'a': 1, 'b': {'c': 2, 'a': 3}, 'd': [{'a': 4}, {'e': 5}]}\n        &gt;&gt;&gt; list(search_dict_by_key('a', d))\n        [1, 3, 4]\n    \"\"\"\n    if isinstance(d, dict):\n        if key in d:\n            yield d[key]\n        for k, v in d.items():\n            yield from search_dict_by_key(key, v)\n    elif isinstance(d, list):\n        for v in d:\n            yield from search_dict_by_key(key, v)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.search_dict_values","title":"search_dict_values","text":"<pre><code>search_dict_values(d, *regexes)\n</code></pre> <p>Recursively search a dictionary's values based on provided regex patterns.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>Union[dict, list, str]</code>)         \u2013          <p>The dictionary, list, or string to search.</p> </li> <li> <code>*regexes</code>         \u2013          <p>Arbitrary number of compiled regex patterns.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Generator</code>        \u2013          <p>Yields matching values based on the provided regex patterns.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dict_to_search = {\n...     \"key1\": {\n...         \"key2\": [\n...             {\n...                 \"key3\": \"A URL: https://www.evilcorp.com\"\n...             }\n...         ]\n...     }\n... }\n&gt;&gt;&gt; url_regexes = re.compile(r'https?://[^\\s&lt;&gt;\"]+|www\\.[^\\s&lt;&gt;\"]+')\n&gt;&gt;&gt; list(search_dict_values(dict_to_search, url_regexes))\n[\"https://www.evilcorp.com\"]\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def search_dict_values(d, *regexes):\n\"\"\"Recursively search a dictionary's values based on provided regex patterns.\n\n    Args:\n        d (Union[dict, list, str]): The dictionary, list, or string to search.\n        *regexes: Arbitrary number of compiled regex patterns.\n\n    Returns:\n        Generator: Yields matching values based on the provided regex patterns.\n\n    Examples:\n        &gt;&gt;&gt; dict_to_search = {\n        ...     \"key1\": {\n        ...         \"key2\": [\n        ...             {\n        ...                 \"key3\": \"A URL: https://www.evilcorp.com\"\n        ...             }\n        ...         ]\n        ...     }\n        ... }\n        &gt;&gt;&gt; url_regexes = re.compile(r'https?://[^\\s&lt;&gt;\"]+|www\\.[^\\s&lt;&gt;\"]+')\n        &gt;&gt;&gt; list(search_dict_values(dict_to_search, url_regexes))\n        [\"https://www.evilcorp.com\"]\n    \"\"\"\n\n    results = set()\n    if isinstance(d, str):\n        for r in regexes:\n            for match in r.finditer(d):\n                result = match.group()\n                h = hash(result)\n                if h not in results:\n                    results.add(h)\n                    yield result\n    elif isinstance(d, dict):\n        for _, v in d.items():\n            yield from search_dict_values(v, *regexes)\n    elif isinstance(d, list):\n        for v in d:\n            yield from search_dict_values(v, *regexes)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.search_format_dict","title":"search_format_dict","text":"<pre><code>search_format_dict(d, **kwargs)\n</code></pre> <p>Recursively format string values in a dictionary or list using the provided keyword arguments.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>Union[dict, list, str]</code>)         \u2013          <p>The dictionary, list, or string to format.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments used for string formatting.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>Union[dict, list, str]: The formatted dictionary, list, or string.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; search_format_dict({\"test\": \"#{name} is awesome\"}, name=\"keanu\")\n{\"test\": \"keanu is awesome\"}\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def search_format_dict(d, **kwargs):\n\"\"\"Recursively format string values in a dictionary or list using the provided keyword arguments.\n\n    Args:\n        d (Union[dict, list, str]): The dictionary, list, or string to format.\n        **kwargs: Arbitrary keyword arguments used for string formatting.\n\n    Returns:\n        Union[dict, list, str]: The formatted dictionary, list, or string.\n\n    Examples:\n        &gt;&gt;&gt; search_format_dict({\"test\": \"#{name} is awesome\"}, name=\"keanu\")\n        {\"test\": \"keanu is awesome\"}\n    \"\"\"\n    if isinstance(d, dict):\n        return {k: search_format_dict(v, **kwargs) for k, v in d.items()}\n    elif isinstance(d, list):\n        return [search_format_dict(v, **kwargs) for v in d]\n    elif isinstance(d, str):\n        for find, replace in kwargs.items():\n            find = \"#{\" + str(find) + \"}\"\n            d = d.replace(find, replace)\n    return d\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.sha1","title":"sha1","text":"<pre><code>sha1(data)\n</code></pre> <p>Computes the SHA-1 hash of the given data.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>str or dict</code>)         \u2013          <p>The data to hash. If a dictionary, it is first converted to a JSON string with sorted keys.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>hashlib.Hash: SHA-1 hash object of the input data.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sha1(\"asdf\").hexdigest()\n'3da541559918a808c2402bba5012f6c60b27661c'\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def sha1(data):\n\"\"\"\n    Computes the SHA-1 hash of the given data.\n\n    Args:\n        data (str or dict): The data to hash. If a dictionary, it is first converted to a JSON string with sorted keys.\n\n    Returns:\n        hashlib.Hash: SHA-1 hash object of the input data.\n\n    Examples:\n        &gt;&gt;&gt; sha1(\"asdf\").hexdigest()\n        '3da541559918a808c2402bba5012f6c60b27661c'\n    \"\"\"\n    if isinstance(data, dict):\n        data = json.dumps(data, sort_keys=True)\n    return hashlib_sha1(smart_encode(data))\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.smart_decode","title":"smart_decode","text":"<pre><code>smart_decode(data)\n</code></pre> <p>Decodes the input data to a UTF-8 string, silently ignoring errors.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>str or bytes</code>)         \u2013          <p>The data to decode.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>The decoded string.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; smart_decode(b\"asdf\")\n\"asdf\"\n&gt;&gt;&gt; smart_decode(\"asdf\")\n\"asdf\"\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def smart_decode(data):\n\"\"\"\n    Decodes the input data to a UTF-8 string, silently ignoring errors.\n\n    Args:\n        data (str or bytes): The data to decode.\n\n    Returns:\n        str: The decoded string.\n\n    Examples:\n        &gt;&gt;&gt; smart_decode(b\"asdf\")\n        \"asdf\"\n        &gt;&gt;&gt; smart_decode(\"asdf\")\n        \"asdf\"\n    \"\"\"\n    if isinstance(data, bytes):\n        return data.decode(\"utf-8\", errors=\"ignore\")\n    else:\n        return str(data)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.smart_decode_punycode","title":"smart_decode_punycode","text":"<pre><code>smart_decode_punycode(text: str) -&gt; str\n</code></pre> <p>xn--eckwd4c7c.xn--zckzah --&gt; \u30c9\u30e1\u30a4\u30f3.\u30c6\u30b9\u30c8</p> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def smart_decode_punycode(text: str) -&gt; str:\n\"\"\"\n    xn--eckwd4c7c.xn--zckzah --&gt; \u30c9\u30e1\u30a4\u30f3.\u30c6\u30b9\u30c8\n    \"\"\"\n    host, before, after = extract_host(text)\n    if host is None:\n        return text\n\n    try:\n        host = idna.decode(host)\n    except UnicodeError:\n        pass  # If decoding fails, leave the host as it is\n\n    return f\"{before}{host}{after}\"\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.smart_encode","title":"smart_encode","text":"<pre><code>smart_encode(data)\n</code></pre> <p>Encodes the input data to bytes using UTF-8 encoding, silently ignoring errors.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>str or bytes</code>)         \u2013          <p>The data to encode.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes</code>        \u2013          <p>The encoded bytes.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; smart_encode(\"asdf\")\nb\"asdf\"\n&gt;&gt;&gt; smart_encode(b\"asdf\")\nb\"asdf\"\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def smart_encode(data):\n\"\"\"\n    Encodes the input data to bytes using UTF-8 encoding, silently ignoring errors.\n\n    Args:\n        data (str or bytes): The data to encode.\n\n    Returns:\n        bytes: The encoded bytes.\n\n    Examples:\n        &gt;&gt;&gt; smart_encode(\"asdf\")\n        b\"asdf\"\n        &gt;&gt;&gt; smart_encode(b\"asdf\")\n        b\"asdf\"\n    \"\"\"\n    if isinstance(data, bytes):\n        return data\n    return str(data).encode(\"utf-8\", errors=\"ignore\")\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.smart_encode_punycode","title":"smart_encode_punycode","text":"<pre><code>smart_encode_punycode(text: str) -&gt; str\n</code></pre> <p>\u30c9\u30e1\u30a4\u30f3.\u30c6\u30b9\u30c8 --&gt; xn--eckwd4c7c.xn--zckzah</p> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def smart_encode_punycode(text: str) -&gt; str:\n\"\"\"\n    \u30c9\u30e1\u30a4\u30f3.\u30c6\u30b9\u30c8 --&gt; xn--eckwd4c7c.xn--zckzah\n    \"\"\"\n    host, before, after = extract_host(text)\n    if host is None:\n        return text\n\n    try:\n        host = idna.encode(host).decode(errors=\"ignore\")\n    except UnicodeError:\n        pass  # If encoding fails, leave the host as it is\n\n    return f\"{before}{host}{after}\"\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.split_domain","title":"split_domain","text":"<pre><code>split_domain(hostname)\n</code></pre> <p>Splits the hostname into its subdomain and registered domain components.</p> <p>Parameters:</p> <ul> <li> <code>hostname</code>             (<code>str</code>)         \u2013          <p>The full hostname to be split.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>        \u2013          <p>A tuple containing the subdomain and registered domain.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; split_domain(\"www.internal.evilcorp.co.uk\")\n(\"www.internal\", \"evilcorp.co.uk\")\n</code></pre> Notes <ul> <li>Utilizes the <code>tldextract</code> function to first break down the hostname.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def split_domain(hostname):\n\"\"\"\n    Splits the hostname into its subdomain and registered domain components.\n\n    Args:\n        hostname (str): The full hostname to be split.\n\n    Returns:\n        tuple: A tuple containing the subdomain and registered domain.\n\n    Examples:\n        &gt;&gt;&gt; split_domain(\"www.internal.evilcorp.co.uk\")\n        (\"www.internal\", \"evilcorp.co.uk\")\n\n    Notes:\n        - Utilizes the `tldextract` function to first break down the hostname.\n    \"\"\"\n    if is_ip(hostname):\n        return (\"\", hostname)\n    parsed = tldextract(hostname)\n    subdomain = parsed.subdomain\n    domain = parsed.registered_domain\n    if not domain:\n        split = hostname.split(\".\")\n        subdomain = \".\".join(split[:-2])\n        domain = \".\".join(split[-2:])\n    return (subdomain, domain)\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.split_host_port","title":"split_host_port","text":"<pre><code>split_host_port(d)\n</code></pre> <p>Parse a string containing a host and port into a tuple.</p> <p>This function takes an input string <code>d</code> and returns a tuple containing the host and port. The host is converted to its appropriate IP address type if possible. The port is inferred based on the scheme if not provided.</p> <p>Parameters:</p> <ul> <li> <code>d</code>             (<code>str</code>)         \u2013          <p>The input string containing the host and possibly the port.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>Tuple[Union[IPv4Address, IPv6Address, str], Optional[int]]: Tuple containing the host and port.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; split_host_port(\"evilcorp.com:443\")\n(\"evilcorp.com\", 443)\n</code></pre> <pre><code>&gt;&gt;&gt; split_host_port(\"192.168.1.1:443\")\n(IPv4Address('192.168.1.1'), 443)\n</code></pre> <pre><code>&gt;&gt;&gt; split_host_port(\"[dead::beef]:443\")\n(IPv6Address('dead::beef'), 443)\n</code></pre> Notes <ul> <li>If port is not provided, it is inferred based on the scheme:<ul> <li>For \"https\" and \"wss\", port 443 is used.</li> <li>For \"http\" and \"ws\", port 80 is used.</li> </ul> </li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def split_host_port(d):\n\"\"\"\n    Parse a string containing a host and port into a tuple.\n\n    This function takes an input string `d` and returns a tuple containing the host and port.\n    The host is converted to its appropriate IP address type if possible. The port is inferred\n    based on the scheme if not provided.\n\n    Args:\n        d (str): The input string containing the host and possibly the port.\n\n    Returns:\n        Tuple[Union[IPv4Address, IPv6Address, str], Optional[int]]: Tuple containing the host and port.\n\n    Examples:\n        &gt;&gt;&gt; split_host_port(\"evilcorp.com:443\")\n        (\"evilcorp.com\", 443)\n\n        &gt;&gt;&gt; split_host_port(\"192.168.1.1:443\")\n        (IPv4Address('192.168.1.1'), 443)\n\n        &gt;&gt;&gt; split_host_port(\"[dead::beef]:443\")\n        (IPv6Address('dead::beef'), 443)\n\n    Notes:\n        - If port is not provided, it is inferred based on the scheme:\n            - For \"https\" and \"wss\", port 443 is used.\n            - For \"http\" and \"ws\", port 80 is used.\n    \"\"\"\n    d = str(d)\n    host = None\n    port = None\n    scheme = None\n    if is_ip(d):\n        return make_ip_type(d), port\n\n    match = bbot_regexes.split_host_port_regex.match(d)\n    if match is None:\n        raise ValueError(f'split_port() failed to parse \"{d}\"')\n    scheme = match.group(\"scheme\")\n    netloc = match.group(\"netloc\")\n    if netloc is None:\n        raise ValueError(f'split_port() failed to parse \"{d}\"')\n\n    match = bbot_regexes.extract_open_port_regex.match(netloc)\n    if match is None:\n        raise ValueError(f'split_port() failed to parse netloc \"{netloc}\"')\n\n    host = match.group(2)\n    if host is None:\n        host = match.group(1)\n    if host is None:\n        raise ValueError(f'split_port() failed to locate host in netloc \"{netloc}\"')\n\n    port = match.group(3)\n    if port is None and scheme is not None:\n        if scheme in (\"https\", \"wss\"):\n            port = 443\n        elif scheme in (\"http\", \"ws\"):\n            port = 80\n    elif port is not None:\n        with suppress(ValueError):\n            port = int(port)\n\n    return make_ip_type(host), port\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.split_list","title":"split_list","text":"<pre><code>split_list(alist, wanted_parts = 2)\n</code></pre> <p>Splits a list into a specified number of approximately equal parts.</p> <p>Parameters:</p> <ul> <li> <code>alist</code>             (<code>list</code>)         \u2013          <p>The list to be split.</p> </li> <li> <code>wanted_parts</code>             (<code>int</code>, default:                 <code>2</code> )         \u2013          <p>The number of parts to split the list into.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>        \u2013          <p>A list of lists, each containing a portion of the original list.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; split_list([1, 2, 3, 4, 5])\n[[1, 2], [3, 4, 5]]\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def split_list(alist, wanted_parts=2):\n\"\"\"\n    Splits a list into a specified number of approximately equal parts.\n\n    Args:\n        alist (list): The list to be split.\n        wanted_parts (int): The number of parts to split the list into.\n\n    Returns:\n        list: A list of lists, each containing a portion of the original list.\n\n    Examples:\n        &gt;&gt;&gt; split_list([1, 2, 3, 4, 5])\n        [[1, 2], [3, 4, 5]]\n    \"\"\"\n    length = len(alist)\n    return [alist[i * length // wanted_parts : (i + 1) * length // wanted_parts] for i in range(wanted_parts)]\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.str_or_file","title":"str_or_file","text":"<pre><code>str_or_file(s)\n</code></pre> <p>Reads a string or file and yields its content line-by-line.</p> <p>This function tries to open the given string <code>s</code> as a file and yields its lines. If it fails to open <code>s</code> as a file, it treats <code>s</code> as a regular string and yields it as is.</p> <p>Parameters:</p> <ul> <li> <code>s</code>             (<code>str</code>)         \u2013          <p>The string or file path to read.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>str</code>        \u2013          <p>Either lines from the file or the original string.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; list(str_or_file(\"file.txt\"))\n['file_line1', 'file_line2', 'file_line3']\n&gt;&gt;&gt; list(str_or_file(\"not_a_file\"))\n['not_a_file']\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def str_or_file(s):\n\"\"\"Reads a string or file and yields its content line-by-line.\n\n    This function tries to open the given string `s` as a file and yields its lines.\n    If it fails to open `s` as a file, it treats `s` as a regular string and yields it as is.\n\n    Args:\n        s (str): The string or file path to read.\n\n    Yields:\n        str: Either lines from the file or the original string.\n\n    Examples:\n        &gt;&gt;&gt; list(str_or_file(\"file.txt\"))\n        ['file_line1', 'file_line2', 'file_line3']\n        &gt;&gt;&gt; list(str_or_file(\"not_a_file\"))\n        ['not_a_file']\n    \"\"\"\n    try:\n        with open(s, errors=\"ignore\") as f:\n            for line in f:\n                yield line.rstrip(\"\\r\\n\")\n    except OSError:\n        yield s\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.swap_status","title":"swap_status","text":"<pre><code>swap_status()\n</code></pre> <p>Return statistics on swap memory consumption.</p> <p>The function returns a <code>psutil</code> named tuple that contains statistics on system swap memory usage, such as total swap, used swap, free swap, and more.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>psutil._common.sswap: A named tuple representing various statistics about system swap memory usage.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; swap = swap_status()\n&gt;&gt;&gt; swap.total\n4294967296\n</code></pre> <pre><code>&gt;&gt;&gt; swap = swap_status()\n&gt;&gt;&gt; swap.used\n2097152\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def swap_status():\n\"\"\"Return statistics on swap memory consumption.\n\n    The function returns a `psutil` named tuple that contains statistics on\n    system swap memory usage, such as total swap, used swap, free swap, and more.\n\n    Returns:\n        psutil._common.sswap: A named tuple representing various statistics\n            about system swap memory usage.\n\n    Examples:\n        &gt;&gt;&gt; swap = swap_status()\n        &gt;&gt;&gt; swap.total\n        4294967296\n\n        &gt;&gt;&gt; swap = swap_status()\n        &gt;&gt;&gt; swap.used\n        2097152\n    \"\"\"\n    return psutil.swap_memory()\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.tagify","title":"tagify","text":"<pre><code>tagify(s, maxlen = None)\n</code></pre> <p>Sanitize a string into a tag-friendly format.</p> <p>Converts a given string to lowercase and replaces all characters not matching [a-z0-9] with hyphens. Optionally truncates the result to 'maxlen' characters.</p> <p>Parameters:</p> <ul> <li> <code>s</code>             (<code>str</code>)         \u2013          <p>The input string to sanitize.</p> </li> <li> <code>maxlen</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>The maximum length for the tag. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>A sanitized, tag-friendly string.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tagify(\"HTTP Web Title\")\n'http-web-title'\n&gt;&gt;&gt; tagify(\"HTTP Web Title\", maxlen=8)\n'http-web'\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def tagify(s, maxlen=None):\n\"\"\"Sanitize a string into a tag-friendly format.\n\n    Converts a given string to lowercase and replaces all characters not matching\n    [a-z0-9] with hyphens. Optionally truncates the result to 'maxlen' characters.\n\n    Args:\n        s (str): The input string to sanitize.\n        maxlen (int, optional): The maximum length for the tag. Defaults to None.\n\n    Returns:\n        str: A sanitized, tag-friendly string.\n\n    Examples:\n        &gt;&gt;&gt; tagify(\"HTTP Web Title\")\n        'http-web-title'\n        &gt;&gt;&gt; tagify(\"HTTP Web Title\", maxlen=8)\n        'http-web'\n    \"\"\"\n    ret = str(s).lower()\n    return tag_filter_regex.sub(\"-\", ret)[:maxlen].strip(\"-\")\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.tldextract","title":"tldextract","text":"<pre><code>tldextract(data)\n</code></pre> <p>Extracts the subdomain, domain, and suffix from a URL string.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>str</code>)         \u2013          <p>The URL string to be processed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ExtractResult</code>        \u2013          <p>A named tuple containing the subdomain, domain, and suffix.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tldextract(\"www.evilcorp.co.uk\")\nExtractResult(subdomain='www', domain='evilcorp', suffix='co.uk')\n</code></pre> Notes <ul> <li>Utilizes <code>smart_decode</code> to preprocess the data.</li> <li>Makes use of the <code>tldextract</code> library for extraction.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def tldextract(data):\n\"\"\"\n    Extracts the subdomain, domain, and suffix from a URL string.\n\n    Args:\n        data (str): The URL string to be processed.\n\n    Returns:\n        ExtractResult: A named tuple containing the subdomain, domain, and suffix.\n\n    Examples:\n        &gt;&gt;&gt; tldextract(\"www.evilcorp.co.uk\")\n        ExtractResult(subdomain='www', domain='evilcorp', suffix='co.uk')\n\n    Notes:\n        - Utilizes `smart_decode` to preprocess the data.\n        - Makes use of the `tldextract` library for extraction.\n    \"\"\"\n    return _tldextract.extract(smart_decode(data))\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.url_parents","title":"url_parents","text":"<pre><code>url_parents(u)\n</code></pre> <p>Generate a list of parent URLs for a given URL string.</p> <p>This function takes an input string <code>u</code> representing a URL and generates a list of its parent URLs in decreasing order of specificity.</p> <p>Parameters:</p> <ul> <li> <code>u</code>             (<code>str</code>)         \u2013          <p>The input string representing a URL.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>List[str]: A list of parent URLs of the input URL in decreasing order of specificity.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; url_parents(\"http://www.evilcorp.co.uk/admin/tools/cmd.php\")\n[\"http://www.evilcorp.co.uk/admin/tools/\", \"http://www.evilcorp.co.uk/admin/\", \"http://www.evilcorp.co.uk/\"]\n</code></pre> Notes <ul> <li>The list is generated by continuously calling <code>parent_url</code> until it returns None.</li> <li>All components of the URL except for the path are preserved.</li> </ul> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def url_parents(u):\n\"\"\"\n    Generate a list of parent URLs for a given URL string.\n\n    This function takes an input string `u` representing a URL and generates a list of its parent URLs in decreasing order of specificity.\n\n    Args:\n        u (str): The input string representing a URL.\n\n    Returns:\n        List[str]: A list of parent URLs of the input URL in decreasing order of specificity.\n\n    Examples:\n        &gt;&gt;&gt; url_parents(\"http://www.evilcorp.co.uk/admin/tools/cmd.php\")\n        [\"http://www.evilcorp.co.uk/admin/tools/\", \"http://www.evilcorp.co.uk/admin/\", \"http://www.evilcorp.co.uk/\"]\n\n    Notes:\n        - The list is generated by continuously calling `parent_url` until it returns None.\n        - All components of the URL except for the path are preserved.\n    \"\"\"\n    parent_list = []\n    while 1:\n        parent = parent_url(u)\n        if parent == None:\n            return parent_list\n        elif parent not in parent_list:\n            parent_list.append(parent)\n            u = parent\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.verify_sudo_password","title":"verify_sudo_password","text":"<pre><code>verify_sudo_password(sudo_pass)\n</code></pre> <p>Verify if the given sudo password is correct.</p> <p>This function checks whether the sudo password provided is valid for the current user. It runs a command with sudo, feeding in the password via stdin, and checks the return code.</p> <p>Parameters:</p> <ul> <li> <code>sudo_pass</code>             (<code>str</code>)         \u2013          <p>The sudo password to verify.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if the sudo password is correct, False otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; verify_sudo_password(\"mysecretpassword\")\nTrue\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def verify_sudo_password(sudo_pass):\n\"\"\"Verify if the given sudo password is correct.\n\n    This function checks whether the sudo password provided is valid for the current user.\n    It runs a command with sudo, feeding in the password via stdin, and checks the return code.\n\n    Args:\n        sudo_pass (str): The sudo password to verify.\n\n    Returns:\n        bool: True if the sudo password is correct, False otherwise.\n\n    Examples:\n        &gt;&gt;&gt; verify_sudo_password(\"mysecretpassword\")\n        True\n    \"\"\"\n    try:\n        sp.run(\n            [\"sudo\", \"-S\", \"-k\", \"true\"],\n            input=smart_encode(sudo_pass),\n            stderr=sp.DEVNULL,\n            stdout=sp.DEVNULL,\n            check=True,\n        )\n    except sp.CalledProcessError:\n        return False\n    return True\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.weighted_shuffle","title":"weighted_shuffle","text":"<pre><code>weighted_shuffle(items, weights)\n</code></pre> <p>Shuffles a list of items based on their corresponding weights.</p> <p>Parameters:</p> <ul> <li> <code>items</code>             (<code>list</code>)         \u2013          <p>The list of items to shuffle.</p> </li> <li> <code>weights</code>             (<code>list</code>)         \u2013          <p>The list of weights corresponding to each item.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>        \u2013          <p>A new list containing the shuffled items.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; items = ['apple', 'banana', 'cherry']\n&gt;&gt;&gt; weights = [0.4, 0.5, 0.1]\n&gt;&gt;&gt; weighted_shuffle(items, weights)\n['banana', 'apple', 'cherry']\n&gt;&gt;&gt; weighted_shuffle(items, weights)\n['apple', 'banana', 'cherry']\n&gt;&gt;&gt; weighted_shuffle(items, weights)\n['apple', 'banana', 'cherry']\n&gt;&gt;&gt; weighted_shuffle(items, weights)\n['banana', 'apple', 'cherry']\n</code></pre> Note <p>The sum of all weights does not have to be 1. They will be normalized internally.</p> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def weighted_shuffle(items, weights):\n\"\"\"\n    Shuffles a list of items based on their corresponding weights.\n\n    Args:\n        items (list): The list of items to shuffle.\n        weights (list): The list of weights corresponding to each item.\n\n    Returns:\n        list: A new list containing the shuffled items.\n\n    Examples:\n        &gt;&gt;&gt; items = ['apple', 'banana', 'cherry']\n        &gt;&gt;&gt; weights = [0.4, 0.5, 0.1]\n        &gt;&gt;&gt; weighted_shuffle(items, weights)\n        ['banana', 'apple', 'cherry']\n        &gt;&gt;&gt; weighted_shuffle(items, weights)\n        ['apple', 'banana', 'cherry']\n        &gt;&gt;&gt; weighted_shuffle(items, weights)\n        ['apple', 'banana', 'cherry']\n        &gt;&gt;&gt; weighted_shuffle(items, weights)\n        ['banana', 'apple', 'cherry']\n\n    Note:\n        The sum of all weights does not have to be 1. They will be normalized internally.\n    \"\"\"\n    # Create a list of tuples where each tuple is (item, weight)\n    pool = list(zip(items, weights))\n\n    shuffled_items = []\n\n    # While there are still items to be chosen...\n    while pool:\n        # Normalize weights\n        total = sum(weight for item, weight in pool)\n        weights = [weight / total for item, weight in pool]\n\n        # Choose an index based on weight\n        chosen_index = random.choices(range(len(pool)), weights=weights, k=1)[0]\n\n        # Add the chosen item to the shuffled list\n        chosen_item, chosen_weight = pool.pop(chosen_index)\n        shuffled_items.append(chosen_item)\n\n    return shuffled_items\n</code></pre>"},{"location":"dev/helpers/misc/#bbot.core.helpers.misc.which","title":"which","text":"<pre><code>which(*executables)\n</code></pre> <p>Finds the full path of the first available executable from a list of executables.</p> <p>Parameters:</p> <ul> <li> <code>*executables</code>             (<code>str</code>, default:                 <code>()</code> )         \u2013          <p>One or more executable names to search for.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>The full path of the first available executable, or None if none are found.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; which(\"python\", \"python3\")\n\"/usr/bin/python\"\n</code></pre> Source code in <code>bbot/core/helpers/misc.py</code> <pre><code>def which(*executables):\n\"\"\"Finds the full path of the first available executable from a list of executables.\n\n    Args:\n        *executables (str): One or more executable names to search for.\n\n    Returns:\n        str: The full path of the first available executable, or None if none are found.\n\n    Examples:\n        &gt;&gt;&gt; which(\"python\", \"python3\")\n        \"/usr/bin/python\"\n    \"\"\"\n    for e in executables:\n        location = shutil.which(e)\n        if location:\n            return location\n</code></pre>"},{"location":"dev/helpers/web/","title":"Web","text":"<p>These are helpers for making various web requests.</p> <p>Note that these helpers can be invoked directly from <code>self.helpers</code>, e.g.:</p> <pre><code>self.helpers.request(\"https://www.evilcorp.com\")\n</code></pre>"},{"location":"dev/helpers/web/#bbot.core.helpers.web.WebHelper","title":"WebHelper","text":"<p>Main utility class for managing HTTP operations in BBOT. It serves as a wrapper around the BBOTAsyncClient, which itself is a subclass of httpx.AsyncClient. The class provides functionalities to make HTTP requests, download files, and handle cached wordlists.</p> <p>Attributes:</p> <ul> <li> <code>parent_helper</code>             (<code>object</code>)         \u2013          <p>The parent helper object containing scan configurations.</p> </li> <li> <code>http_debug</code>             (<code>bool</code>)         \u2013          <p>Flag to indicate whether HTTP debugging is enabled.</p> </li> <li> <code>ssl_verify</code>             (<code>bool</code>)         \u2013          <p>Flag to indicate whether SSL verification is enabled.</p> </li> <li> <code>web_client</code>             (<code>BBOTAsyncClient</code>)         \u2013          <p>An instance of BBOTAsyncClient for making HTTP requests.</p> </li> <li> <code>client_only_options</code>             (<code>tuple</code>)         \u2013          <p>A tuple of options only applicable to the web client.</p> </li> </ul> <p>Examples:</p> <p>Basic web request:</p> <pre><code>&gt;&gt;&gt; response = await self.helpers.request(\"https://www.evilcorp.com\")\n</code></pre> <p>Download file:</p> <pre><code>&gt;&gt;&gt; filename = await self.helpers.download(\"https://www.evilcorp.com/passwords.docx\")\n</code></pre> <p>Download wordlist (cached for 30 days by default):</p> <pre><code>&gt;&gt;&gt; filename = await self.helpers.wordlist(\"https://www.evilcorp.com/wordlist.txt\")\n</code></pre> Source code in <code>bbot/core/helpers/web.py</code> <pre><code>class WebHelper:\n\"\"\"\n    Main utility class for managing HTTP operations in BBOT. It serves as a wrapper around the BBOTAsyncClient,\n    which itself is a subclass of httpx.AsyncClient. The class provides functionalities to make HTTP requests,\n    download files, and handle cached wordlists.\n\n    Attributes:\n        parent_helper (object): The parent helper object containing scan configurations.\n        http_debug (bool): Flag to indicate whether HTTP debugging is enabled.\n        ssl_verify (bool): Flag to indicate whether SSL verification is enabled.\n        web_client (BBOTAsyncClient): An instance of BBOTAsyncClient for making HTTP requests.\n        client_only_options (tuple): A tuple of options only applicable to the web client.\n\n    Examples:\n        Basic web request:\n        &gt;&gt;&gt; response = await self.helpers.request(\"https://www.evilcorp.com\")\n\n        Download file:\n        &gt;&gt;&gt; filename = await self.helpers.download(\"https://www.evilcorp.com/passwords.docx\")\n\n        Download wordlist (cached for 30 days by default):\n        &gt;&gt;&gt; filename = await self.helpers.wordlist(\"https://www.evilcorp.com/wordlist.txt\")\n    \"\"\"\n\n    client_only_options = (\n        \"retries\",\n        \"max_redirects\",\n    )\n\n    def __init__(self, parent_helper):\n        self.parent_helper = parent_helper\n        self.http_debug = self.parent_helper.config.get(\"http_debug\", False)\n        self._ssl_context_noverify = None\n        self.ssl_verify = self.parent_helper.config.get(\"ssl_verify\", False)\n        if self.ssl_verify is False:\n            self.ssl_verify = self.ssl_context_noverify()\n        self.web_client = self.AsyncClient(persist_cookies=False)\n\n    def AsyncClient(self, *args, **kwargs):\n        kwargs[\"_bbot_scan\"] = self.parent_helper.scan\n        retries = kwargs.pop(\"retries\", self.parent_helper.config.get(\"http_retries\", 1))\n        kwargs[\"transport\"] = httpx.AsyncHTTPTransport(retries=retries, verify=self.ssl_verify)\n        kwargs[\"verify\"] = self.ssl_verify\n        return BBOTAsyncClient(*args, **kwargs)\n\n    async def request(self, *args, **kwargs):\n\"\"\"\n        Asynchronous function for making HTTP requests, intended to be the most basic web request function\n        used widely across BBOT and within this helper class. Handles various exceptions and timeouts\n        that might occur during the request.\n\n        This function automatically respects the scan's global timeout, proxy, headers, etc.\n        Headers you specify will be merged with the scan's. Your arguments take ultimate precedence,\n        meaning you can override the scan's values if you want.\n\n        Args:\n            url (str): The URL to send the request to.\n            method (str, optional): The HTTP method to use for the request. Defaults to 'GET'.\n            headers (dict, optional): Dictionary of HTTP headers to send with the request.\n            params (dict, optional): Dictionary, list of tuples, or bytes to send in the query string.\n            cookies (dict, optional): Dictionary or CookieJar object containing cookies.\n            json (Any, optional): A JSON serializable Python object to send in the body.\n            data (dict, optional): Dictionary, list of tuples, or bytes to send in the body.\n            files (dict, optional): Dictionary of 'name': file-like-objects for multipart encoding upload.\n            auth (tuple, optional): Auth tuple to enable Basic/Digest/Custom HTTP auth.\n            timeout (float, optional): The maximum time to wait for the request to complete.\n            proxies (dict, optional): Dictionary mapping protocol schemes to proxy URLs.\n            allow_redirects (bool, optional): Enables or disables redirection. Defaults to None.\n            stream (bool, optional): Enables or disables response streaming.\n            raise_error (bool, optional): Whether to raise exceptions for HTTP connect, timeout errors. Defaults to False.\n            client (httpx.AsyncClient, optional): A specific httpx.AsyncClient to use for the request. Defaults to self.web_client.\n            cache_for (int, optional): Time in seconds to cache the request. Not used currently. Defaults to None.\n\n        Raises:\n            httpx.TimeoutException: If the request times out.\n            httpx.ConnectError: If the connection fails.\n            httpx.RequestError: For other request-related errors.\n\n        Returns:\n            httpx.Response or None: The HTTP response object returned by the httpx library.\n\n        Examples:\n            &gt;&gt;&gt; response = await self.helpers.request(\"https://www.evilcorp.com\")\n\n            &gt;&gt;&gt; response = await self.helpers.request(\"https://api.evilcorp.com/\", method=\"POST\", data=\"stuff\")\n\n        Note:\n            If the web request fails, it will return None unless `raise_error` is `True`.\n        \"\"\"\n\n        raise_error = kwargs.pop(\"raise_error\", False)\n        # TODO: use this\n        cache_for = kwargs.pop(\"cache_for\", None)  # noqa\n\n        client = kwargs.get(\"client\", self.web_client)\n\n        # allow vs follow, httpx why??\n        allow_redirects = kwargs.pop(\"allow_redirects\", None)\n        if allow_redirects is not None and \"follow_redirects\" not in kwargs:\n            kwargs[\"follow_redirects\"] = allow_redirects\n\n        # in case of URL only, assume GET request\n        if len(args) == 1:\n            kwargs[\"url\"] = args[0]\n            args = []\n\n        url = kwargs.get(\"url\", \"\")\n\n        if not args and \"method\" not in kwargs:\n            kwargs[\"method\"] = \"GET\"\n\n        client_kwargs = {}\n        for k in list(kwargs):\n            if k in self.client_only_options:\n                v = kwargs.pop(k)\n                client_kwargs[k] = v\n\n        if client_kwargs:\n            client = self.AsyncClient(**client_kwargs)\n\n        async with self._acatch(url, raise_error):\n            if self.http_debug:\n                logstr = f\"Web request: {str(args)}, {str(kwargs)}\"\n                log.debug(logstr)\n            response = await client.request(*args, **kwargs)\n            if self.http_debug:\n                log.debug(\n                    f\"Web response from {url}: {response} (Length: {len(response.content)}) headers: {response.headers}\"\n                )\n            return response\n\n    async def download(self, url, **kwargs):\n\"\"\"\n        Asynchronous function for downloading files from a given URL. Supports caching with an optional\n        time period in hours via the \"cache_hrs\" keyword argument. In case of successful download,\n        returns the full path of the saved filename. If the download fails, returns None.\n\n        Args:\n            url (str): The URL of the file to download.\n            filename (str, optional): The filename to save the downloaded file as.\n                If not provided, will generate based on URL.\n            max_size (str or int): Maximum filesize as a string (\"5MB\") or integer in bytes.\n            cache_hrs (float, optional): The number of hours to cache the downloaded file.\n                A negative value disables caching. Defaults to -1.\n            method (str, optional): The HTTP method to use for the request, defaults to 'GET'.\n            raise_error (bool, optional): Whether to raise exceptions for HTTP connect, timeout errors. Defaults to False.\n            **kwargs: Additional keyword arguments to pass to the httpx request.\n\n        Returns:\n            Path or None: The full path of the downloaded file as a Path object if successful, otherwise None.\n\n        Examples:\n            &gt;&gt;&gt; filepath = await self.helpers.download(\"https://www.evilcorp.com/passwords.docx\", cache_hrs=24)\n        \"\"\"\n        success = False\n        filename = kwargs.pop(\"filename\", self.parent_helper.cache_filename(url))\n        follow_redirects = kwargs.pop(\"follow_redirects\", True)\n        max_size = kwargs.pop(\"max_size\", None)\n        warn = kwargs.pop(\"warn\", True)\n        raise_error = kwargs.pop(\"raise_error\", False)\n        if max_size is not None:\n            max_size = self.parent_helper.human_to_bytes(max_size)\n        cache_hrs = float(kwargs.pop(\"cache_hrs\", -1))\n        total_size = 0\n        chunk_size = 8192\n        log.debug(f\"Downloading file from {url} with cache_hrs={cache_hrs}\")\n        if cache_hrs &gt; 0 and self.parent_helper.is_cached(url):\n            log.debug(f\"{url} is cached at {self.parent_helper.cache_filename(url)}\")\n            success = True\n        else:\n            # kwargs[\"raise_error\"] = True\n            # kwargs[\"stream\"] = True\n            kwargs[\"follow_redirects\"] = follow_redirects\n            if not \"method\" in kwargs:\n                kwargs[\"method\"] = \"GET\"\n            try:\n                async with self._acatch(url, raise_error), self.AsyncClient().stream(url=url, **kwargs) as response:\n                    status_code = getattr(response, \"status_code\", 0)\n                    log.debug(f\"Download result: HTTP {status_code}\")\n                    if status_code != 0:\n                        response.raise_for_status()\n                        with open(filename, \"wb\") as f:\n                            agen = response.aiter_bytes(chunk_size=chunk_size)\n                            async for chunk in agen:\n                                if max_size is not None and total_size + chunk_size &gt; max_size:\n                                    log.verbose(\n                                        f\"Filesize of {url} exceeds {self.parent_helper.bytes_to_human(max_size)}, file will be truncated\"\n                                    )\n                                    agen.aclose()\n                                    break\n                                total_size += chunk_size\n                                f.write(chunk)\n                        success = True\n            except httpx.HTTPError as e:\n                log_fn = log.verbose\n                if warn:\n                    log_fn = log.warning\n                log_fn(f\"Failed to download {url}: {e}\")\n                return\n\n        if success:\n            return filename.resolve()\n\n    async def wordlist(self, path, lines=None, **kwargs):\n\"\"\"\n        Asynchronous function for retrieving wordlists, either from a local path or a URL.\n        Allows for optional line-based truncation and caching. Returns the full path of the wordlist\n        file or a truncated version of it.\n\n        Args:\n            path (str): The local or remote path of the wordlist.\n            lines (int, optional): Number of lines to read from the wordlist.\n                If specified, will return a truncated wordlist with this many lines.\n            cache_hrs (float, optional): Number of hours to cache the downloaded wordlist.\n                Defaults to 720 hours (30 days) for remote wordlists.\n            **kwargs: Additional keyword arguments to pass to the 'download' function for remote wordlists.\n\n        Returns:\n            Path: The full path of the wordlist (or its truncated version) as a Path object.\n\n        Raises:\n            WordlistError: If the path is invalid or the wordlist could not be retrieved or found.\n\n        Examples:\n            Fetching full wordlist\n            &gt;&gt;&gt; wordlist_path = await self.helpers.wordlist(\"https://www.evilcorp.com/wordlist.txt\")\n\n            Fetching and truncating to the first 100 lines\n            &gt;&gt;&gt; wordlist_path = await self.helpers.wordlist(\"/root/rockyou.txt\", lines=100)\n        \"\"\"\n        if not path:\n            raise WordlistError(f\"Invalid wordlist: {path}\")\n        if not \"cache_hrs\" in kwargs:\n            kwargs[\"cache_hrs\"] = 720\n        if self.parent_helper.is_url(path):\n            filename = await self.download(str(path), **kwargs)\n            if filename is None:\n                raise WordlistError(f\"Unable to retrieve wordlist from {path}\")\n        else:\n            filename = Path(path).resolve()\n            if not filename.is_file():\n                raise WordlistError(f\"Unable to find wordlist at {path}\")\n\n        if lines is None:\n            return filename\n        else:\n            lines = int(lines)\n            with open(filename) as f:\n                read_lines = f.readlines()\n            cache_key = f\"{filename}:{lines}\"\n            truncated_filename = self.parent_helper.cache_filename(cache_key)\n            with open(truncated_filename, \"w\") as f:\n                for line in read_lines[:lines]:\n                    f.write(line)\n            return truncated_filename\n\n    async def api_page_iter(self, url, page_size=100, json=True, next_key=None, **requests_kwargs):\n\"\"\"\n        An asynchronous generator function for iterating through paginated API data.\n\n        This function continuously makes requests to a specified API URL, incrementing the page number\n        or applying a custom pagination function, and yields the received data one page at a time.\n        It is well-suited for APIs that provide paginated results.\n\n        Args:\n            url (str): The initial API URL. Can contain placeholders for 'page', 'page_size', and 'offset'.\n            page_size (int, optional): The number of items per page. Defaults to 100.\n            json (bool, optional): If True, attempts to deserialize the response content to a JSON object. Defaults to True.\n            next_key (callable, optional): A function that takes the last page's data and returns the URL for the next page. Defaults to None.\n            **requests_kwargs: Arbitrary keyword arguments that will be forwarded to the HTTP request function.\n\n        Yields:\n            dict or httpx.Response: If 'json' is True, yields a dictionary containing the parsed JSON data. Otherwise, yields the raw HTTP response.\n\n        Note:\n            The loop will continue indefinitely unless manually stopped. Make sure to break out of the loop once the last page has been received.\n\n        Examples:\n            &gt;&gt;&gt; agen = api_page_iter('https://api.example.com/data?page={page}&amp;page_size={page_size}')\n            &gt;&gt;&gt; try:\n            &gt;&gt;&gt;     async for page in agen:\n            &gt;&gt;&gt;         subdomains = page[\"subdomains\"]\n            &gt;&gt;&gt;         self.hugesuccess(subdomains)\n            &gt;&gt;&gt;         if not subdomains:\n            &gt;&gt;&gt;             break\n            &gt;&gt;&gt; finally:\n            &gt;&gt;&gt;     agen.aclose()\n        \"\"\"\n        page = 1\n        offset = 0\n        result = None\n        while 1:\n            if result and callable(next_key):\n                try:\n                    new_url = next_key(result)\n                except Exception as e:\n                    log.debug(f\"Failed to extract next page of results from {url}: {e}\")\n                    log.debug(traceback.formate_exc())\n            else:\n                new_url = url.format(page=page, page_size=page_size, offset=offset)\n            result = await self.request(new_url, **requests_kwargs)\n            try:\n                if json:\n                    result = result.json()\n                yield result\n            except Exception:\n                log.warning(f'Error in api_page_iter() for url: \"{new_url}\"')\n                log.trace(traceback.format_exc())\n                break\n            finally:\n                offset += page_size\n                page += 1\n\n    async def curl(self, *args, **kwargs):\n\"\"\"\n        An asynchronous function that runs a cURL command with specified arguments and options.\n\n        This function constructs and executes a cURL command based on the provided parameters.\n        It offers support for various cURL options such as headers, post data, and cookies.\n\n        Args:\n            *args: Variable length argument list for positional arguments. Unused in this function.\n            url (str): The URL for the cURL request. Mandatory.\n            raw_path (bool, optional): If True, activates '--path-as-is' in cURL. Defaults to False.\n            headers (dict, optional): A dictionary of HTTP headers to include in the request.\n            ignore_bbot_global_settings (bool, optional): If True, ignores the global settings of BBOT. Defaults to False.\n            post_data (dict, optional): A dictionary containing data to be sent in the request body.\n            method (str, optional): The HTTP method to use for the request (e.g., 'GET', 'POST').\n            cookies (dict, optional): A dictionary of cookies to include in the request.\n            path_override (str, optional): Overrides the request-target to use in the HTTP request line.\n            head_mode (bool, optional): If True, includes '-I' to fetch headers only. Defaults to None.\n            raw_body (str, optional): Raw string to be sent in the body of the request.\n            **kwargs: Arbitrary keyword arguments that will be forwarded to the HTTP request function.\n\n        Returns:\n            str: The output of the cURL command.\n\n        Raises:\n            CurlError: If 'url' is not supplied.\n\n        Examples:\n            &gt;&gt;&gt; output = await curl(url=\"https://example.com\", headers={\"X-Header\": \"Wat\"})\n            &gt;&gt;&gt; print(output)\n        \"\"\"\n        url = kwargs.get(\"url\", \"\")\n\n        if not url:\n            raise CurlError(\"No URL supplied to CURL helper\")\n\n        curl_command = [\"curl\", url, \"-s\"]\n\n        raw_path = kwargs.get(\"raw_path\", False)\n        if raw_path:\n            curl_command.append(\"--path-as-is\")\n\n        # respect global ssl verify settings\n        if self.ssl_verify is not True:\n            curl_command.append(\"-k\")\n\n        headers = kwargs.get(\"headers\", {})\n\n        ignore_bbot_global_settings = kwargs.get(\"ignore_bbot_global_settings\", False)\n\n        if ignore_bbot_global_settings:\n            log.debug(\"ignore_bbot_global_settings enabled. Global settings will not be applied\")\n        else:\n            http_timeout = self.parent_helper.config.get(\"http_timeout\", 20)\n            user_agent = self.parent_helper.config.get(\"user_agent\", \"BBOT\")\n\n            if \"User-Agent\" not in headers:\n                headers[\"User-Agent\"] = user_agent\n\n            # only add custom headers if the URL is in-scope\n            if self.parent_helper.scan.in_scope(url):\n                for hk, hv in self.parent_helper.scan.config.get(\"http_headers\", {}).items():\n                    headers[hk] = hv\n\n            # add the timeout\n            if not \"timeout\" in kwargs:\n                timeout = http_timeout\n\n            curl_command.append(\"-m\")\n            curl_command.append(str(timeout))\n\n        for k, v in headers.items():\n            if isinstance(v, list):\n                for x in v:\n                    curl_command.append(\"-H\")\n                    curl_command.append(f\"{k}: {x}\")\n\n            else:\n                curl_command.append(\"-H\")\n                curl_command.append(f\"{k}: {v}\")\n\n        post_data = kwargs.get(\"post_data\", {})\n        if len(post_data.items()) &gt; 0:\n            curl_command.append(\"-d\")\n            post_data_str = \"\"\n            for k, v in post_data.items():\n                post_data_str += f\"&amp;{k}={v}\"\n            curl_command.append(post_data_str.lstrip(\"&amp;\"))\n\n        method = kwargs.get(\"method\", \"\")\n        if method:\n            curl_command.append(\"-X\")\n            curl_command.append(method)\n\n        cookies = kwargs.get(\"cookies\", \"\")\n        if cookies:\n            curl_command.append(\"-b\")\n            cookies_str = \"\"\n            for k, v in cookies.items():\n                cookies_str += f\"{k}={v}; \"\n            curl_command.append(f'{cookies_str.rstrip(\" \")}')\n\n        path_override = kwargs.get(\"path_override\", None)\n        if path_override:\n            curl_command.append(\"--request-target\")\n            curl_command.append(f\"{path_override}\")\n\n        head_mode = kwargs.get(\"head_mode\", None)\n        if head_mode:\n            curl_command.append(\"-I\")\n\n        raw_body = kwargs.get(\"raw_body\", None)\n        if raw_body:\n            curl_command.append(\"-d\")\n            curl_command.append(raw_body)\n\n        output = (await self.parent_helper.run(curl_command)).stdout\n        return output\n\n    def is_spider_danger(self, source_event, url):\n\"\"\"\n        Determines whether visiting a URL could potentially trigger a web-spider-like happening.\n\n        This function assesses the depth and distance of a URL in relation to the parent helper's\n        configuration settings for web spidering. If the URL exceeds the specified depth or distance,\n        the function returns True, indicating a possible web-spider risk.\n\n        Args:\n            source_event: The source event object that discovered the URL.\n            url (str): The URL to evaluate for web-spider risk.\n\n        Returns:\n            bool: True if visiting the URL might trigger a web-spider-like event, False otherwise.\n\n        Todo:\n            - Write tests for this function\n\n        Examples:\n            &gt;&gt;&gt; is_spider_danger(source_event_obj, \"https://example.com/subpage\")\n            True\n\n            &gt;&gt;&gt; is_spider_danger(source_event_obj, \"https://example.com/\")\n            False\n        \"\"\"\n        url_depth = self.parent_helper.url_depth(url)\n        web_spider_depth = self.parent_helper.scan.config.get(\"web_spider_depth\", 1)\n        spider_distance = getattr(source_event, \"web_spider_distance\", 0) + 1\n        web_spider_distance = self.parent_helper.scan.config.get(\"web_spider_distance\", 0)\n        if (url_depth &gt; web_spider_depth) or (spider_distance &gt; web_spider_distance):\n            return True\n        return False\n\n    def ssl_context_noverify(self):\n        if self._ssl_context_noverify is None:\n            ssl_context = ssl.create_default_context()\n            ssl_context.check_hostname = False\n            ssl_context.verify_mode = ssl.CERT_NONE\n            ssl_context.options &amp;= ~ssl.OP_NO_SSLv2 &amp; ~ssl.OP_NO_SSLv3\n            ssl_context.set_ciphers(\"ALL:@SECLEVEL=0\")\n            ssl_context.options |= 0x4  # Add the OP_LEGACY_SERVER_CONNECT option\n            self._ssl_context_noverify = ssl_context\n        return self._ssl_context_noverify\n\n    @asynccontextmanager\n    async def _acatch(self, url, raise_error):\n\"\"\"\n        Asynchronous context manager to handle various httpx errors during a request.\n\n        Yields:\n            None\n\n        Note:\n            This function is internal and should generally not be used directly.\n            `url`, `args`, `kwargs`, and `raise_error` should be in the same context as this function.\n        \"\"\"\n        try:\n            yield\n        except httpx.TimeoutException:\n            log.verbose(f\"HTTP timeout to URL: {url}\")\n            if raise_error:\n                raise\n        except httpx.ConnectError:\n            log.verbose(f\"HTTP connect failed to URL: {url}\")\n            if raise_error:\n                raise\n        except httpx.RequestError as e:\n            log.trace(f\"Error with request to URL: {url}: {e}\")\n            log.trace(traceback.format_exc())\n            if raise_error:\n                raise\n        except ssl.SSLError as e:\n            msg = f\"SSL error with request to URL: {url}: {e}\"\n            log.trace(msg)\n            log.trace(traceback.format_exc())\n            if raise_error:\n                raise httpx.RequestError(msg)\n        except anyio.EndOfStream as e:\n            msg = f\"AnyIO error with request to URL: {url}: {e}\"\n            log.trace(msg)\n            log.trace(traceback.format_exc())\n            if raise_error:\n                raise httpx.RequestError(msg)\n        except BaseException as e:\n            log.trace(f\"Unhandled exception with request to URL: {url}: {e}\")\n            log.trace(traceback.format_exc())\n            raise\n</code></pre>"},{"location":"dev/helpers/web/#bbot.core.helpers.web.WebHelper.api_page_iter","title":"api_page_iter  <code>async</code>","text":"<pre><code>api_page_iter(url, page_size = 100, json = True, next_key = None, **requests_kwargs)\n</code></pre> <p>An asynchronous generator function for iterating through paginated API data.</p> <p>This function continuously makes requests to a specified API URL, incrementing the page number or applying a custom pagination function, and yields the received data one page at a time. It is well-suited for APIs that provide paginated results.</p> <p>Parameters:</p> <ul> <li> <code>url</code>             (<code>str</code>)         \u2013          <p>The initial API URL. Can contain placeholders for 'page', 'page_size', and 'offset'.</p> </li> <li> <code>page_size</code>             (<code>int</code>, default:                 <code>100</code> )         \u2013          <p>The number of items per page. Defaults to 100.</p> </li> <li> <code>json</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If True, attempts to deserialize the response content to a JSON object. Defaults to True.</p> </li> <li> <code>next_key</code>             (<code>callable</code>, default:                 <code>None</code> )         \u2013          <p>A function that takes the last page's data and returns the URL for the next page. Defaults to None.</p> </li> <li> <code>**requests_kwargs</code>         \u2013          <p>Arbitrary keyword arguments that will be forwarded to the HTTP request function.</p> </li> </ul> <p>Yields:</p> <ul> <li>         \u2013          <p>dict or httpx.Response: If 'json' is True, yields a dictionary containing the parsed JSON data. Otherwise, yields the raw HTTP response.</p> </li> </ul> Note <p>The loop will continue indefinitely unless manually stopped. Make sure to break out of the loop once the last page has been received.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; agen = api_page_iter('https://api.example.com/data?page={page}&amp;page_size={page_size}')\n&gt;&gt;&gt; try:\n&gt;&gt;&gt;     async for page in agen:\n&gt;&gt;&gt;         subdomains = page[\"subdomains\"]\n&gt;&gt;&gt;         self.hugesuccess(subdomains)\n&gt;&gt;&gt;         if not subdomains:\n&gt;&gt;&gt;             break\n&gt;&gt;&gt; finally:\n&gt;&gt;&gt;     agen.aclose()\n</code></pre> Source code in <code>bbot/core/helpers/web.py</code> <pre><code>async def api_page_iter(self, url, page_size=100, json=True, next_key=None, **requests_kwargs):\n\"\"\"\n    An asynchronous generator function for iterating through paginated API data.\n\n    This function continuously makes requests to a specified API URL, incrementing the page number\n    or applying a custom pagination function, and yields the received data one page at a time.\n    It is well-suited for APIs that provide paginated results.\n\n    Args:\n        url (str): The initial API URL. Can contain placeholders for 'page', 'page_size', and 'offset'.\n        page_size (int, optional): The number of items per page. Defaults to 100.\n        json (bool, optional): If True, attempts to deserialize the response content to a JSON object. Defaults to True.\n        next_key (callable, optional): A function that takes the last page's data and returns the URL for the next page. Defaults to None.\n        **requests_kwargs: Arbitrary keyword arguments that will be forwarded to the HTTP request function.\n\n    Yields:\n        dict or httpx.Response: If 'json' is True, yields a dictionary containing the parsed JSON data. Otherwise, yields the raw HTTP response.\n\n    Note:\n        The loop will continue indefinitely unless manually stopped. Make sure to break out of the loop once the last page has been received.\n\n    Examples:\n        &gt;&gt;&gt; agen = api_page_iter('https://api.example.com/data?page={page}&amp;page_size={page_size}')\n        &gt;&gt;&gt; try:\n        &gt;&gt;&gt;     async for page in agen:\n        &gt;&gt;&gt;         subdomains = page[\"subdomains\"]\n        &gt;&gt;&gt;         self.hugesuccess(subdomains)\n        &gt;&gt;&gt;         if not subdomains:\n        &gt;&gt;&gt;             break\n        &gt;&gt;&gt; finally:\n        &gt;&gt;&gt;     agen.aclose()\n    \"\"\"\n    page = 1\n    offset = 0\n    result = None\n    while 1:\n        if result and callable(next_key):\n            try:\n                new_url = next_key(result)\n            except Exception as e:\n                log.debug(f\"Failed to extract next page of results from {url}: {e}\")\n                log.debug(traceback.formate_exc())\n        else:\n            new_url = url.format(page=page, page_size=page_size, offset=offset)\n        result = await self.request(new_url, **requests_kwargs)\n        try:\n            if json:\n                result = result.json()\n            yield result\n        except Exception:\n            log.warning(f'Error in api_page_iter() for url: \"{new_url}\"')\n            log.trace(traceback.format_exc())\n            break\n        finally:\n            offset += page_size\n            page += 1\n</code></pre>"},{"location":"dev/helpers/web/#bbot.core.helpers.web.WebHelper.curl","title":"curl  <code>async</code>","text":"<pre><code>curl(*args, **kwargs)\n</code></pre> <p>An asynchronous function that runs a cURL command with specified arguments and options.</p> <p>This function constructs and executes a cURL command based on the provided parameters. It offers support for various cURL options such as headers, post data, and cookies.</p> <p>Parameters:</p> <ul> <li> <code>*args</code>         \u2013          <p>Variable length argument list for positional arguments. Unused in this function.</p> </li> <li> <code>url</code>             (<code>str</code>)         \u2013          <p>The URL for the cURL request. Mandatory.</p> </li> <li> <code>raw_path</code>             (<code>bool</code>)         \u2013          <p>If True, activates '--path-as-is' in cURL. Defaults to False.</p> </li> <li> <code>headers</code>             (<code>dict</code>)         \u2013          <p>A dictionary of HTTP headers to include in the request.</p> </li> <li> <code>ignore_bbot_global_settings</code>             (<code>bool</code>)         \u2013          <p>If True, ignores the global settings of BBOT. Defaults to False.</p> </li> <li> <code>post_data</code>             (<code>dict</code>)         \u2013          <p>A dictionary containing data to be sent in the request body.</p> </li> <li> <code>method</code>             (<code>str</code>)         \u2013          <p>The HTTP method to use for the request (e.g., 'GET', 'POST').</p> </li> <li> <code>cookies</code>             (<code>dict</code>)         \u2013          <p>A dictionary of cookies to include in the request.</p> </li> <li> <code>path_override</code>             (<code>str</code>)         \u2013          <p>Overrides the request-target to use in the HTTP request line.</p> </li> <li> <code>head_mode</code>             (<code>bool</code>)         \u2013          <p>If True, includes '-I' to fetch headers only. Defaults to None.</p> </li> <li> <code>raw_body</code>             (<code>str</code>)         \u2013          <p>Raw string to be sent in the body of the request.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Arbitrary keyword arguments that will be forwarded to the HTTP request function.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>        \u2013          <p>The output of the cURL command.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>CurlError</code>           \u2013          <p>If 'url' is not supplied.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; output = await curl(url=\"https://example.com\", headers={\"X-Header\": \"Wat\"})\n&gt;&gt;&gt; print(output)\n</code></pre> Source code in <code>bbot/core/helpers/web.py</code> <pre><code>async def curl(self, *args, **kwargs):\n\"\"\"\n    An asynchronous function that runs a cURL command with specified arguments and options.\n\n    This function constructs and executes a cURL command based on the provided parameters.\n    It offers support for various cURL options such as headers, post data, and cookies.\n\n    Args:\n        *args: Variable length argument list for positional arguments. Unused in this function.\n        url (str): The URL for the cURL request. Mandatory.\n        raw_path (bool, optional): If True, activates '--path-as-is' in cURL. Defaults to False.\n        headers (dict, optional): A dictionary of HTTP headers to include in the request.\n        ignore_bbot_global_settings (bool, optional): If True, ignores the global settings of BBOT. Defaults to False.\n        post_data (dict, optional): A dictionary containing data to be sent in the request body.\n        method (str, optional): The HTTP method to use for the request (e.g., 'GET', 'POST').\n        cookies (dict, optional): A dictionary of cookies to include in the request.\n        path_override (str, optional): Overrides the request-target to use in the HTTP request line.\n        head_mode (bool, optional): If True, includes '-I' to fetch headers only. Defaults to None.\n        raw_body (str, optional): Raw string to be sent in the body of the request.\n        **kwargs: Arbitrary keyword arguments that will be forwarded to the HTTP request function.\n\n    Returns:\n        str: The output of the cURL command.\n\n    Raises:\n        CurlError: If 'url' is not supplied.\n\n    Examples:\n        &gt;&gt;&gt; output = await curl(url=\"https://example.com\", headers={\"X-Header\": \"Wat\"})\n        &gt;&gt;&gt; print(output)\n    \"\"\"\n    url = kwargs.get(\"url\", \"\")\n\n    if not url:\n        raise CurlError(\"No URL supplied to CURL helper\")\n\n    curl_command = [\"curl\", url, \"-s\"]\n\n    raw_path = kwargs.get(\"raw_path\", False)\n    if raw_path:\n        curl_command.append(\"--path-as-is\")\n\n    # respect global ssl verify settings\n    if self.ssl_verify is not True:\n        curl_command.append(\"-k\")\n\n    headers = kwargs.get(\"headers\", {})\n\n    ignore_bbot_global_settings = kwargs.get(\"ignore_bbot_global_settings\", False)\n\n    if ignore_bbot_global_settings:\n        log.debug(\"ignore_bbot_global_settings enabled. Global settings will not be applied\")\n    else:\n        http_timeout = self.parent_helper.config.get(\"http_timeout\", 20)\n        user_agent = self.parent_helper.config.get(\"user_agent\", \"BBOT\")\n\n        if \"User-Agent\" not in headers:\n            headers[\"User-Agent\"] = user_agent\n\n        # only add custom headers if the URL is in-scope\n        if self.parent_helper.scan.in_scope(url):\n            for hk, hv in self.parent_helper.scan.config.get(\"http_headers\", {}).items():\n                headers[hk] = hv\n\n        # add the timeout\n        if not \"timeout\" in kwargs:\n            timeout = http_timeout\n\n        curl_command.append(\"-m\")\n        curl_command.append(str(timeout))\n\n    for k, v in headers.items():\n        if isinstance(v, list):\n            for x in v:\n                curl_command.append(\"-H\")\n                curl_command.append(f\"{k}: {x}\")\n\n        else:\n            curl_command.append(\"-H\")\n            curl_command.append(f\"{k}: {v}\")\n\n    post_data = kwargs.get(\"post_data\", {})\n    if len(post_data.items()) &gt; 0:\n        curl_command.append(\"-d\")\n        post_data_str = \"\"\n        for k, v in post_data.items():\n            post_data_str += f\"&amp;{k}={v}\"\n        curl_command.append(post_data_str.lstrip(\"&amp;\"))\n\n    method = kwargs.get(\"method\", \"\")\n    if method:\n        curl_command.append(\"-X\")\n        curl_command.append(method)\n\n    cookies = kwargs.get(\"cookies\", \"\")\n    if cookies:\n        curl_command.append(\"-b\")\n        cookies_str = \"\"\n        for k, v in cookies.items():\n            cookies_str += f\"{k}={v}; \"\n        curl_command.append(f'{cookies_str.rstrip(\" \")}')\n\n    path_override = kwargs.get(\"path_override\", None)\n    if path_override:\n        curl_command.append(\"--request-target\")\n        curl_command.append(f\"{path_override}\")\n\n    head_mode = kwargs.get(\"head_mode\", None)\n    if head_mode:\n        curl_command.append(\"-I\")\n\n    raw_body = kwargs.get(\"raw_body\", None)\n    if raw_body:\n        curl_command.append(\"-d\")\n        curl_command.append(raw_body)\n\n    output = (await self.parent_helper.run(curl_command)).stdout\n    return output\n</code></pre>"},{"location":"dev/helpers/web/#bbot.core.helpers.web.WebHelper.download","title":"download  <code>async</code>","text":"<pre><code>download(url, **kwargs)\n</code></pre> <p>Asynchronous function for downloading files from a given URL. Supports caching with an optional time period in hours via the \"cache_hrs\" keyword argument. In case of successful download, returns the full path of the saved filename. If the download fails, returns None.</p> <p>Parameters:</p> <ul> <li> <code>url</code>             (<code>str</code>)         \u2013          <p>The URL of the file to download.</p> </li> <li> <code>filename</code>             (<code>str</code>)         \u2013          <p>The filename to save the downloaded file as. If not provided, will generate based on URL.</p> </li> <li> <code>max_size</code>             (<code>str or int</code>)         \u2013          <p>Maximum filesize as a string (\"5MB\") or integer in bytes.</p> </li> <li> <code>cache_hrs</code>             (<code>float</code>)         \u2013          <p>The number of hours to cache the downloaded file. A negative value disables caching. Defaults to -1.</p> </li> <li> <code>method</code>             (<code>str</code>)         \u2013          <p>The HTTP method to use for the request, defaults to 'GET'.</p> </li> <li> <code>raise_error</code>             (<code>bool</code>)         \u2013          <p>Whether to raise exceptions for HTTP connect, timeout errors. Defaults to False.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments to pass to the httpx request.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>Path or None: The full path of the downloaded file as a Path object if successful, otherwise None.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; filepath = await self.helpers.download(\"https://www.evilcorp.com/passwords.docx\", cache_hrs=24)\n</code></pre> Source code in <code>bbot/core/helpers/web.py</code> <pre><code>async def download(self, url, **kwargs):\n\"\"\"\n    Asynchronous function for downloading files from a given URL. Supports caching with an optional\n    time period in hours via the \"cache_hrs\" keyword argument. In case of successful download,\n    returns the full path of the saved filename. If the download fails, returns None.\n\n    Args:\n        url (str): The URL of the file to download.\n        filename (str, optional): The filename to save the downloaded file as.\n            If not provided, will generate based on URL.\n        max_size (str or int): Maximum filesize as a string (\"5MB\") or integer in bytes.\n        cache_hrs (float, optional): The number of hours to cache the downloaded file.\n            A negative value disables caching. Defaults to -1.\n        method (str, optional): The HTTP method to use for the request, defaults to 'GET'.\n        raise_error (bool, optional): Whether to raise exceptions for HTTP connect, timeout errors. Defaults to False.\n        **kwargs: Additional keyword arguments to pass to the httpx request.\n\n    Returns:\n        Path or None: The full path of the downloaded file as a Path object if successful, otherwise None.\n\n    Examples:\n        &gt;&gt;&gt; filepath = await self.helpers.download(\"https://www.evilcorp.com/passwords.docx\", cache_hrs=24)\n    \"\"\"\n    success = False\n    filename = kwargs.pop(\"filename\", self.parent_helper.cache_filename(url))\n    follow_redirects = kwargs.pop(\"follow_redirects\", True)\n    max_size = kwargs.pop(\"max_size\", None)\n    warn = kwargs.pop(\"warn\", True)\n    raise_error = kwargs.pop(\"raise_error\", False)\n    if max_size is not None:\n        max_size = self.parent_helper.human_to_bytes(max_size)\n    cache_hrs = float(kwargs.pop(\"cache_hrs\", -1))\n    total_size = 0\n    chunk_size = 8192\n    log.debug(f\"Downloading file from {url} with cache_hrs={cache_hrs}\")\n    if cache_hrs &gt; 0 and self.parent_helper.is_cached(url):\n        log.debug(f\"{url} is cached at {self.parent_helper.cache_filename(url)}\")\n        success = True\n    else:\n        # kwargs[\"raise_error\"] = True\n        # kwargs[\"stream\"] = True\n        kwargs[\"follow_redirects\"] = follow_redirects\n        if not \"method\" in kwargs:\n            kwargs[\"method\"] = \"GET\"\n        try:\n            async with self._acatch(url, raise_error), self.AsyncClient().stream(url=url, **kwargs) as response:\n                status_code = getattr(response, \"status_code\", 0)\n                log.debug(f\"Download result: HTTP {status_code}\")\n                if status_code != 0:\n                    response.raise_for_status()\n                    with open(filename, \"wb\") as f:\n                        agen = response.aiter_bytes(chunk_size=chunk_size)\n                        async for chunk in agen:\n                            if max_size is not None and total_size + chunk_size &gt; max_size:\n                                log.verbose(\n                                    f\"Filesize of {url} exceeds {self.parent_helper.bytes_to_human(max_size)}, file will be truncated\"\n                                )\n                                agen.aclose()\n                                break\n                            total_size += chunk_size\n                            f.write(chunk)\n                    success = True\n        except httpx.HTTPError as e:\n            log_fn = log.verbose\n            if warn:\n                log_fn = log.warning\n            log_fn(f\"Failed to download {url}: {e}\")\n            return\n\n    if success:\n        return filename.resolve()\n</code></pre>"},{"location":"dev/helpers/web/#bbot.core.helpers.web.WebHelper.is_spider_danger","title":"is_spider_danger","text":"<pre><code>is_spider_danger(source_event, url)\n</code></pre> <p>Determines whether visiting a URL could potentially trigger a web-spider-like happening.</p> <p>This function assesses the depth and distance of a URL in relation to the parent helper's configuration settings for web spidering. If the URL exceeds the specified depth or distance, the function returns True, indicating a possible web-spider risk.</p> <p>Parameters:</p> <ul> <li> <code>source_event</code>         \u2013          <p>The source event object that discovered the URL.</p> </li> <li> <code>url</code>             (<code>str</code>)         \u2013          <p>The URL to evaluate for web-spider risk.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>        \u2013          <p>True if visiting the URL might trigger a web-spider-like event, False otherwise.</p> </li> </ul> Todo <ul> <li>Write tests for this function</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_spider_danger(source_event_obj, \"https://example.com/subpage\")\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; is_spider_danger(source_event_obj, \"https://example.com/\")\nFalse\n</code></pre> Source code in <code>bbot/core/helpers/web.py</code> <pre><code>def is_spider_danger(self, source_event, url):\n\"\"\"\n    Determines whether visiting a URL could potentially trigger a web-spider-like happening.\n\n    This function assesses the depth and distance of a URL in relation to the parent helper's\n    configuration settings for web spidering. If the URL exceeds the specified depth or distance,\n    the function returns True, indicating a possible web-spider risk.\n\n    Args:\n        source_event: The source event object that discovered the URL.\n        url (str): The URL to evaluate for web-spider risk.\n\n    Returns:\n        bool: True if visiting the URL might trigger a web-spider-like event, False otherwise.\n\n    Todo:\n        - Write tests for this function\n\n    Examples:\n        &gt;&gt;&gt; is_spider_danger(source_event_obj, \"https://example.com/subpage\")\n        True\n\n        &gt;&gt;&gt; is_spider_danger(source_event_obj, \"https://example.com/\")\n        False\n    \"\"\"\n    url_depth = self.parent_helper.url_depth(url)\n    web_spider_depth = self.parent_helper.scan.config.get(\"web_spider_depth\", 1)\n    spider_distance = getattr(source_event, \"web_spider_distance\", 0) + 1\n    web_spider_distance = self.parent_helper.scan.config.get(\"web_spider_distance\", 0)\n    if (url_depth &gt; web_spider_depth) or (spider_distance &gt; web_spider_distance):\n        return True\n    return False\n</code></pre>"},{"location":"dev/helpers/web/#bbot.core.helpers.web.WebHelper.request","title":"request  <code>async</code>","text":"<pre><code>request(*args, **kwargs)\n</code></pre> <p>Asynchronous function for making HTTP requests, intended to be the most basic web request function used widely across BBOT and within this helper class. Handles various exceptions and timeouts that might occur during the request.</p> <p>This function automatically respects the scan's global timeout, proxy, headers, etc. Headers you specify will be merged with the scan's. Your arguments take ultimate precedence, meaning you can override the scan's values if you want.</p> <p>Parameters:</p> <ul> <li> <code>url</code>             (<code>str</code>)         \u2013          <p>The URL to send the request to.</p> </li> <li> <code>method</code>             (<code>str</code>)         \u2013          <p>The HTTP method to use for the request. Defaults to 'GET'.</p> </li> <li> <code>headers</code>             (<code>dict</code>)         \u2013          <p>Dictionary of HTTP headers to send with the request.</p> </li> <li> <code>params</code>             (<code>dict</code>)         \u2013          <p>Dictionary, list of tuples, or bytes to send in the query string.</p> </li> <li> <code>cookies</code>             (<code>dict</code>)         \u2013          <p>Dictionary or CookieJar object containing cookies.</p> </li> <li> <code>json</code>             (<code>Any</code>)         \u2013          <p>A JSON serializable Python object to send in the body.</p> </li> <li> <code>data</code>             (<code>dict</code>)         \u2013          <p>Dictionary, list of tuples, or bytes to send in the body.</p> </li> <li> <code>files</code>             (<code>dict</code>)         \u2013          <p>Dictionary of 'name': file-like-objects for multipart encoding upload.</p> </li> <li> <code>auth</code>             (<code>tuple</code>)         \u2013          <p>Auth tuple to enable Basic/Digest/Custom HTTP auth.</p> </li> <li> <code>timeout</code>             (<code>float</code>)         \u2013          <p>The maximum time to wait for the request to complete.</p> </li> <li> <code>proxies</code>             (<code>dict</code>)         \u2013          <p>Dictionary mapping protocol schemes to proxy URLs.</p> </li> <li> <code>allow_redirects</code>             (<code>bool</code>)         \u2013          <p>Enables or disables redirection. Defaults to None.</p> </li> <li> <code>stream</code>             (<code>bool</code>)         \u2013          <p>Enables or disables response streaming.</p> </li> <li> <code>raise_error</code>             (<code>bool</code>)         \u2013          <p>Whether to raise exceptions for HTTP connect, timeout errors. Defaults to False.</p> </li> <li> <code>client</code>             (<code>AsyncClient</code>)         \u2013          <p>A specific httpx.AsyncClient to use for the request. Defaults to self.web_client.</p> </li> <li> <code>cache_for</code>             (<code>int</code>)         \u2013          <p>Time in seconds to cache the request. Not used currently. Defaults to None.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TimeoutException</code>           \u2013          <p>If the request times out.</p> </li> <li> <code>ConnectError</code>           \u2013          <p>If the connection fails.</p> </li> <li> <code>RequestError</code>           \u2013          <p>For other request-related errors.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>httpx.Response or None: The HTTP response object returned by the httpx library.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; response = await self.helpers.request(\"https://www.evilcorp.com\")\n</code></pre> <pre><code>&gt;&gt;&gt; response = await self.helpers.request(\"https://api.evilcorp.com/\", method=\"POST\", data=\"stuff\")\n</code></pre> Note <p>If the web request fails, it will return None unless <code>raise_error</code> is <code>True</code>.</p> Source code in <code>bbot/core/helpers/web.py</code> <pre><code>async def request(self, *args, **kwargs):\n\"\"\"\n    Asynchronous function for making HTTP requests, intended to be the most basic web request function\n    used widely across BBOT and within this helper class. Handles various exceptions and timeouts\n    that might occur during the request.\n\n    This function automatically respects the scan's global timeout, proxy, headers, etc.\n    Headers you specify will be merged with the scan's. Your arguments take ultimate precedence,\n    meaning you can override the scan's values if you want.\n\n    Args:\n        url (str): The URL to send the request to.\n        method (str, optional): The HTTP method to use for the request. Defaults to 'GET'.\n        headers (dict, optional): Dictionary of HTTP headers to send with the request.\n        params (dict, optional): Dictionary, list of tuples, or bytes to send in the query string.\n        cookies (dict, optional): Dictionary or CookieJar object containing cookies.\n        json (Any, optional): A JSON serializable Python object to send in the body.\n        data (dict, optional): Dictionary, list of tuples, or bytes to send in the body.\n        files (dict, optional): Dictionary of 'name': file-like-objects for multipart encoding upload.\n        auth (tuple, optional): Auth tuple to enable Basic/Digest/Custom HTTP auth.\n        timeout (float, optional): The maximum time to wait for the request to complete.\n        proxies (dict, optional): Dictionary mapping protocol schemes to proxy URLs.\n        allow_redirects (bool, optional): Enables or disables redirection. Defaults to None.\n        stream (bool, optional): Enables or disables response streaming.\n        raise_error (bool, optional): Whether to raise exceptions for HTTP connect, timeout errors. Defaults to False.\n        client (httpx.AsyncClient, optional): A specific httpx.AsyncClient to use for the request. Defaults to self.web_client.\n        cache_for (int, optional): Time in seconds to cache the request. Not used currently. Defaults to None.\n\n    Raises:\n        httpx.TimeoutException: If the request times out.\n        httpx.ConnectError: If the connection fails.\n        httpx.RequestError: For other request-related errors.\n\n    Returns:\n        httpx.Response or None: The HTTP response object returned by the httpx library.\n\n    Examples:\n        &gt;&gt;&gt; response = await self.helpers.request(\"https://www.evilcorp.com\")\n\n        &gt;&gt;&gt; response = await self.helpers.request(\"https://api.evilcorp.com/\", method=\"POST\", data=\"stuff\")\n\n    Note:\n        If the web request fails, it will return None unless `raise_error` is `True`.\n    \"\"\"\n\n    raise_error = kwargs.pop(\"raise_error\", False)\n    # TODO: use this\n    cache_for = kwargs.pop(\"cache_for\", None)  # noqa\n\n    client = kwargs.get(\"client\", self.web_client)\n\n    # allow vs follow, httpx why??\n    allow_redirects = kwargs.pop(\"allow_redirects\", None)\n    if allow_redirects is not None and \"follow_redirects\" not in kwargs:\n        kwargs[\"follow_redirects\"] = allow_redirects\n\n    # in case of URL only, assume GET request\n    if len(args) == 1:\n        kwargs[\"url\"] = args[0]\n        args = []\n\n    url = kwargs.get(\"url\", \"\")\n\n    if not args and \"method\" not in kwargs:\n        kwargs[\"method\"] = \"GET\"\n\n    client_kwargs = {}\n    for k in list(kwargs):\n        if k in self.client_only_options:\n            v = kwargs.pop(k)\n            client_kwargs[k] = v\n\n    if client_kwargs:\n        client = self.AsyncClient(**client_kwargs)\n\n    async with self._acatch(url, raise_error):\n        if self.http_debug:\n            logstr = f\"Web request: {str(args)}, {str(kwargs)}\"\n            log.debug(logstr)\n        response = await client.request(*args, **kwargs)\n        if self.http_debug:\n            log.debug(\n                f\"Web response from {url}: {response} (Length: {len(response.content)}) headers: {response.headers}\"\n            )\n        return response\n</code></pre>"},{"location":"dev/helpers/web/#bbot.core.helpers.web.WebHelper.wordlist","title":"wordlist  <code>async</code>","text":"<pre><code>wordlist(path, lines = None, **kwargs)\n</code></pre> <p>Asynchronous function for retrieving wordlists, either from a local path or a URL. Allows for optional line-based truncation and caching. Returns the full path of the wordlist file or a truncated version of it.</p> <p>Parameters:</p> <ul> <li> <code>path</code>             (<code>str</code>)         \u2013          <p>The local or remote path of the wordlist.</p> </li> <li> <code>lines</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Number of lines to read from the wordlist. If specified, will return a truncated wordlist with this many lines.</p> </li> <li> <code>cache_hrs</code>             (<code>float</code>)         \u2013          <p>Number of hours to cache the downloaded wordlist. Defaults to 720 hours (30 days) for remote wordlists.</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Additional keyword arguments to pass to the 'download' function for remote wordlists.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Path</code>        \u2013          <p>The full path of the wordlist (or its truncated version) as a Path object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>WordlistError</code>           \u2013          <p>If the path is invalid or the wordlist could not be retrieved or found.</p> </li> </ul> <p>Examples:</p> <p>Fetching full wordlist</p> <pre><code>&gt;&gt;&gt; wordlist_path = await self.helpers.wordlist(\"https://www.evilcorp.com/wordlist.txt\")\n</code></pre> <p>Fetching and truncating to the first 100 lines</p> <pre><code>&gt;&gt;&gt; wordlist_path = await self.helpers.wordlist(\"/root/rockyou.txt\", lines=100)\n</code></pre> Source code in <code>bbot/core/helpers/web.py</code> <pre><code>async def wordlist(self, path, lines=None, **kwargs):\n\"\"\"\n    Asynchronous function for retrieving wordlists, either from a local path or a URL.\n    Allows for optional line-based truncation and caching. Returns the full path of the wordlist\n    file or a truncated version of it.\n\n    Args:\n        path (str): The local or remote path of the wordlist.\n        lines (int, optional): Number of lines to read from the wordlist.\n            If specified, will return a truncated wordlist with this many lines.\n        cache_hrs (float, optional): Number of hours to cache the downloaded wordlist.\n            Defaults to 720 hours (30 days) for remote wordlists.\n        **kwargs: Additional keyword arguments to pass to the 'download' function for remote wordlists.\n\n    Returns:\n        Path: The full path of the wordlist (or its truncated version) as a Path object.\n\n    Raises:\n        WordlistError: If the path is invalid or the wordlist could not be retrieved or found.\n\n    Examples:\n        Fetching full wordlist\n        &gt;&gt;&gt; wordlist_path = await self.helpers.wordlist(\"https://www.evilcorp.com/wordlist.txt\")\n\n        Fetching and truncating to the first 100 lines\n        &gt;&gt;&gt; wordlist_path = await self.helpers.wordlist(\"/root/rockyou.txt\", lines=100)\n    \"\"\"\n    if not path:\n        raise WordlistError(f\"Invalid wordlist: {path}\")\n    if not \"cache_hrs\" in kwargs:\n        kwargs[\"cache_hrs\"] = 720\n    if self.parent_helper.is_url(path):\n        filename = await self.download(str(path), **kwargs)\n        if filename is None:\n            raise WordlistError(f\"Unable to retrieve wordlist from {path}\")\n    else:\n        filename = Path(path).resolve()\n        if not filename.is_file():\n            raise WordlistError(f\"Unable to find wordlist at {path}\")\n\n    if lines is None:\n        return filename\n    else:\n        lines = int(lines)\n        with open(filename) as f:\n            read_lines = f.readlines()\n        cache_key = f\"{filename}:{lines}\"\n        truncated_filename = self.parent_helper.cache_filename(cache_key)\n        with open(truncated_filename, \"w\") as f:\n            for line in read_lines[:lines]:\n                f.write(line)\n        return truncated_filename\n</code></pre>"},{"location":"dev/helpers/wordcloud/","title":"Word Cloud","text":"<p>These are helpers related to BBOT's Word Cloud, a mechanism for storing target-specific keywords that are useful for custom wordlists, etc.</p> <p>Note that these helpers can be invoked directly from <code>self.helpers</code>, e.g.:</p> <pre><code>self.helpers.word_cloud\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.DNSMutator","title":"DNSMutator","text":"<p>             Bases: <code>Mutator</code></p> <p>DNS-specific mutator used by the <code>massdns</code> module to generate target-specific subdomain mutations.</p> <p>This class extends the Mutator base class to add DNS-specific logic for generating subdomain mutations based on input words. It utilizes custom word extraction patterns and a wordninja model trained on DNS-specific data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = Scanner(\"www1.evilcorp.com\", \"www-test.evilcorp.com\")\n&gt;&gt;&gt; s.start_without_generator()\n&gt;&gt;&gt; s.helpers.word_cloud.dns_mutator.mutations(\"word\")\n[\n    \"word\",\n    \"word-test\",\n    \"word1\",\n    \"wordtest\",\n    \"www-word\",\n    \"wwwword\"\n]\n</code></pre> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>class DNSMutator(Mutator):\n\"\"\"\n    DNS-specific mutator used by the `massdns` module to generate target-specific subdomain mutations.\n\n    This class extends the Mutator base class to add DNS-specific logic for generating\n    subdomain mutations based on input words. It utilizes custom word extraction patterns\n    and a wordninja model trained on DNS-specific data.\n\n    Examples:\n        &gt;&gt;&gt; s = Scanner(\"www1.evilcorp.com\", \"www-test.evilcorp.com\")\n        &gt;&gt;&gt; s.start_without_generator()\n        &gt;&gt;&gt; s.helpers.word_cloud.dns_mutator.mutations(\"word\")\n        [\n            \"word\",\n            \"word-test\",\n            \"word1\",\n            \"wordtest\",\n            \"www-word\",\n            \"wwwword\"\n        ]\n    \"\"\"\n\n    extract_word_regexes = [\n        re.compile(r, re.I)\n        for r in [\n            r\"[a-z]+\",\n            r\"[a-z_-]+\",\n            r\"[a-z0-9]+\",\n            r\"[a-z0-9_-]+\",\n        ]\n    ]\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        wordlist_dir = Path(__file__).parent.parent.parent / \"wordlists\"\n        wordninja_dns_wordlist = wordlist_dir / \"wordninja_dns.txt.gz\"\n        self.model = wordninja.LanguageModel(wordninja_dns_wordlist)\n\n    def mutations(self, words, max_mutations=None):\n        if isinstance(words, str):\n            words = [words]\n        new_words = set()\n        for word in words:\n            for e in extract_words(word, acronyms=False, model=self.model, word_regexes=self.extract_word_regexes):\n                new_words.add(e)\n        return super().mutations(new_words, max_mutations=max_mutations)\n\n    def add_word(self, word):\n        spans = set()\n        mutations = set()\n        for r in self.extract_word_regexes:\n            for match in r.finditer(word):\n                span = match.span()\n                if span not in spans:\n                    spans.add(span)\n        for start, end in spans:\n            match_str = word[start:end]\n            # skip digits\n            if match_str.isdigit():\n                continue\n            before = word[:start]\n            after = word[end:]\n            basic_mutation = (before, None, after)\n            mutations.add(basic_mutation)\n            match_str_split = self.model.split(match_str)\n            if len(match_str_split) &gt; 1:\n                for i, s in enumerate(match_str_split):\n                    if s.isdigit():\n                        continue\n                    split_before = \"\".join(match_str_split[:i])\n                    split_after = \"\".join(match_str_split[i + 1 :])\n                    wordninja_mutation = (before + split_before, None, split_after + after)\n                    mutations.add(wordninja_mutation)\n        for m in mutations:\n            self._add_mutation(m)\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.Mutator","title":"Mutator","text":"<p>             Bases: <code>dict</code></p> <p>Base class for generating mutations from a list of words. It accumulates words and produces mutations from them.</p> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>class Mutator(dict):\n\"\"\"\n    Base class for generating mutations from a list of words.\n    It accumulates words and produces mutations from them.\n    \"\"\"\n\n    def mutations(self, words, max_mutations=None):\n        mutations = self.top_mutations(max_mutations)\n        ret = set()\n        if isinstance(words, str):\n            words = [words]\n        for word in words:\n            for m in self.mutate(word, mutations=mutations):\n                ret.add(\"\".join(m))\n        return ret\n\n    def mutate(self, word, max_mutations=None, mutations=None):\n        if mutations is None:\n            mutations = self.top_mutations(max_mutations)\n        for mutation, count in mutations.items():\n            ret = []\n            for s in mutation:\n                if s is not None:\n                    ret.append(s)\n                else:\n                    ret.append(word)\n            yield ret\n\n    def top_mutations(self, n=None):\n        if n is not None:\n            return dict(sorted(self.items(), key=lambda x: x[-1], reverse=True)[:n])\n        else:\n            return dict(self)\n\n    def _add_mutation(self, mutation):\n        if None not in mutation:\n            return\n        mutation = tuple([m for m in mutation if m != \"\"])\n        try:\n            self[mutation] += 1\n        except KeyError:\n            self[mutation] = 1\n\n    def add_word(self, word):\n        pass\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.WordCloud","title":"WordCloud","text":"<p>             Bases: <code>dict</code></p> <p>WordCloud is a specialized dictionary-like class for storing and aggregating words extracted from various data sources such as DNS names and URLs. The class is intended to facilitate the generation of target-specific wordlists and mutations.</p> <p>The WordCloud class can be accessed and manipulated like a standard Python dictionary. It also offers additional methods for generating mutations based on the words it contains.</p> <p>Attributes:</p> <ul> <li> <code>parent_helper</code>         \u2013          <p>The parent helper object that provides necessary utilities.</p> </li> <li> <code>devops_mutations</code>         \u2013          <p>A set containing common devops-related mutations, loaded from a file.</p> </li> <li> <code>dns_mutator</code>         \u2013          <p>An instance of the DNSMutator class for generating DNS-based mutations.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; s = Scanner(\"www1.evilcorp.com\", \"www-test.evilcorp.com\")\n&gt;&gt;&gt; s.start_without_generator()\n&gt;&gt;&gt; print(s.helpers.word_cloud)\n{\n    \"evilcorp\": 2,\n    \"ec\": 2,\n    \"www1\": 1,\n    \"evil\": 2,\n    \"www\": 2,\n    \"w1\": 1,\n    \"corp\": 2,\n    \"1\": 1,\n    \"wt\": 1,\n    \"test\": 1,\n    \"www-test\": 1\n}\n</code></pre> <pre><code>&gt;&gt;&gt; s.helpers.word_cloud.mutations([\"word\"], cloud=True, numbers=0, devops=False, letters=False)\n[\n    [\n        \"1\",\n        \"word\"\n    ],\n    [\n        \"corp\",\n        \"word\"\n    ],\n    [\n        \"ec\",\n        \"word\"\n    ],\n    [\n        \"evil\",\n        \"word\"\n    ],\n    ...\n]\n</code></pre> <pre><code>&gt;&gt;&gt; s.helpers.word_cloud.dns_mutator.mutations(\"word\")\n[\n    \"word\",\n    \"word-test\",\n    \"word1\",\n    \"wordtest\",\n    \"www-word\",\n    \"wwwword\"\n]\n</code></pre> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>class WordCloud(dict):\n\"\"\"\n    WordCloud is a specialized dictionary-like class for storing and aggregating\n    words extracted from various data sources such as DNS names and URLs. The class\n    is intended to facilitate the generation of target-specific wordlists and mutations.\n\n    The WordCloud class can be accessed and manipulated like a standard Python dictionary.\n    It also offers additional methods for generating mutations based on the words it contains.\n\n    Attributes:\n        parent_helper: The parent helper object that provides necessary utilities.\n        devops_mutations: A set containing common devops-related mutations, loaded from a file.\n        dns_mutator: An instance of the DNSMutator class for generating DNS-based mutations.\n\n    Examples:\n        &gt;&gt;&gt; s = Scanner(\"www1.evilcorp.com\", \"www-test.evilcorp.com\")\n        &gt;&gt;&gt; s.start_without_generator()\n        &gt;&gt;&gt; print(s.helpers.word_cloud)\n        {\n            \"evilcorp\": 2,\n            \"ec\": 2,\n            \"www1\": 1,\n            \"evil\": 2,\n            \"www\": 2,\n            \"w1\": 1,\n            \"corp\": 2,\n            \"1\": 1,\n            \"wt\": 1,\n            \"test\": 1,\n            \"www-test\": 1\n        }\n\n        &gt;&gt;&gt; s.helpers.word_cloud.mutations([\"word\"], cloud=True, numbers=0, devops=False, letters=False)\n        [\n            [\n                \"1\",\n                \"word\"\n            ],\n            [\n                \"corp\",\n                \"word\"\n            ],\n            [\n                \"ec\",\n                \"word\"\n            ],\n            [\n                \"evil\",\n                \"word\"\n            ],\n            ...\n        ]\n\n        &gt;&gt;&gt; s.helpers.word_cloud.dns_mutator.mutations(\"word\")\n        [\n            \"word\",\n            \"word-test\",\n            \"word1\",\n            \"wordtest\",\n            \"www-word\",\n            \"wwwword\"\n        ]\n    \"\"\"\n\n    def __init__(self, parent_helper, *args, **kwargs):\n        self.parent_helper = parent_helper\n\n        devops_filename = self.parent_helper.wordlist_dir / \"devops_mutations.txt\"\n        self.devops_mutations = set(self.parent_helper.read_file(devops_filename))\n\n        self.dns_mutator = DNSMutator()\n\n        super().__init__(*args, **kwargs)\n\n    def mutations(\n        self, words, devops=True, cloud=True, letters=True, numbers=5, number_padding=2, substitute_numbers=True\n    ):\n\"\"\"\n        Generate various mutations for the given list of words based on different criteria.\n\n        Yields tuples of strings which can be joined on the desired delimiter, e.g. \"-\" or \"_\".\n\n        Args:\n            words (Union[str, Iterable[str]]): A single word or list of words to mutate.\n            devops (bool): Whether to include devops-related mutations.\n            cloud (bool): Whether to include mutations from the word cloud.\n            letters (bool): Whether to include letter-based mutations.\n            numbers (int): The maximum numeric mutations to include.\n            number_padding (int): Padding for numeric mutations.\n            substitute_numbers (bool): Whether to substitute numbers in mutations.\n\n        Yields:\n            tuple: A tuple containing each of the mutation segments.\n        \"\"\"\n        if isinstance(words, str):\n            words = (words,)\n        results = set()\n        for word in words:\n            h = hash(word)\n            if not h in results:\n                results.add(h)\n                yield (word,)\n        if numbers &gt; 0:\n            if substitute_numbers:\n                for word in words:\n                    for number_mutation in self.get_number_mutations(word, n=numbers, padding=number_padding):\n                        h = hash(number_mutation)\n                        if not h in results:\n                            results.add(h)\n                            yield (number_mutation,)\n        for word in words:\n            for modifier in self.modifiers(\n                devops=devops, cloud=cloud, letters=letters, numbers=numbers, number_padding=number_padding\n            ):\n                a = (word, modifier)\n                b = (modifier, word)\n                for _ in (a, b):\n                    h = hash(_)\n                    if h not in results:\n                        results.add(h)\n                        yield _\n\n    def modifiers(self, devops=True, cloud=True, letters=True, numbers=5, number_padding=2):\n        modifiers = set()\n        if devops:\n            modifiers.update(self.devops_mutations)\n        if cloud:\n            modifiers.update(set(self))\n        if letters:\n            modifiers.update(set(string.ascii_lowercase))\n        if numbers &gt; 0:\n            modifiers.update(self.parent_helper.gen_numbers(numbers, number_padding))\n        return modifiers\n\n    def absorb_event(self, event):\n\"\"\"\n        Absorbs an event from a BBOT scan into the word cloud.\n\n        This method updates the word cloud by extracting words from the given event. It aims to avoid including PTR\n        (Pointer) records, as they tend to produce unhelpful mutations in the word cloud.\n\n        Args:\n            event (Event): The event object containing the words to be absorbed into the word cloud.\n        \"\"\"\n        for word in event.words:\n            self.add_word(word)\n        if event.scope_distance == 0 and event.type.startswith(\"DNS_NAME\"):\n            subdomain = tldextract(event.data).subdomain\n            if subdomain and not self.parent_helper.is_ptr(subdomain):\n                for s in subdomain.split(\".\"):\n                    self.dns_mutator.add_word(s)\n\n    def absorb_word(self, word, ninja=True):\n\"\"\"\n        Absorbs a word into the word cloud after splitting it using a word extraction algorithm.\n\n        This method splits the input word into smaller meaningful words using word extraction, and then adds each\n        of them to the word cloud. The splitting is done using a predefined algorithm in the parent helper.\n\n        Args:\n            word (str): The word to be split and absorbed into the word cloud.\n            ninja (bool, optional): If True, word extraction is enabled. Defaults to True.\n\n        Examples:\n            &gt;&gt;&gt; self.helpers.word_cloud.absorb_word(\"blacklantern\")\n            &gt;&gt;&gt; print(self.helpers.word_cloud)\n            {\n                \"blacklantern\": 1,\n                \"black\": 1,\n                \"bl\": 1,\n                \"lantern\": 1\n            }\n        \"\"\"\n        for w in self.parent_helper.extract_words(word):\n            self.add_word(w)\n\n    def add_word(self, word, lowercase=True):\n\"\"\"\n        Adds a word to the word cloud.\n\n        This method updates the word cloud by adding a given word. If the word already exists in the cloud,\n        its frequency count is incremented by 1. Optionally, the word can be converted to lowercase before adding.\n\n        Args:\n            word (str): The word to be added to the word cloud.\n            lowercase (bool, optional): If True, the word will be converted to lowercase before adding. Defaults to True.\n\n        Examples:\n            &gt;&gt;&gt; self.helpers.word_cloud.add_word(\"Example\")\n            &gt;&gt;&gt; self.helpers.word_cloud.add_word(\"example\")\n            &gt;&gt;&gt; print(self.helpers.word_cloud)\n            {'example': 2}\n        \"\"\"\n        if lowercase:\n            word = word.lower()\n        try:\n            self[word] += 1\n        except KeyError:\n            self[word] = 1\n\n    def get_number_mutations(self, base, n=5, padding=2):\n\"\"\"\n        Generates mutations of a base string by modifying the numerical parts or appending numbers.\n\n        This method detects existing numbers in the base string and tries incrementing and decrementing them within a\n        specified range. It also appends numbers at the end or after each word to generate more mutations.\n\n        Args:\n            base (str): The base string to generate mutations from.\n            n (int, optional): The range of numbers to use for incrementing/decrementing. Defaults to 5.\n            padding (int, optional): Zero-pad numbers up to this length. Defaults to 2.\n\n        Returns:\n            set: A set of mutated strings based on the base input.\n\n        Examples:\n            &gt;&gt;&gt; self.helpers.word_cloud.get_number_mutations(\"www2-test\", n=2)\n            {\n                \"www0-test\",\n                \"www1-test\",\n                \"www2-test\",\n                \"www2-test0\",\n                \"www2-test00\",\n                \"www2-test01\",\n                \"www2-test1\",\n                \"www3-test\",\n                \"www4-test\"\n            }\n        \"\"\"\n        results = set()\n\n        # detects numbers and increments/decrements them\n        # e.g. for \"base2_p013\", we would try:\n        # - \"base0_p013\" through \"base12_p013\"\n        # - \"base2_p003\" through \"base2_p023\"\n        # limited to three iterations for sanity's sake\n        for match in list(self.parent_helper.regexes.num_regex.finditer(base))[-3:]:\n            span = match.span()\n            before = base[: span[0]]\n            after = base[span[-1] :]\n            number = base[span[0] : span[-1]]\n            numlen = len(number)\n            maxnum = min(int(\"9\" * numlen), int(number) + n)\n            minnum = max(0, int(number) - n)\n            for i in range(minnum, maxnum + 1):\n                filled_num = str(i).zfill(numlen)\n                results.add(f\"{before}{filled_num}{after}\")\n                if not number.startswith(\"0\"):\n                    results.add(f\"{before}{i}{after}\")\n\n        # appends numbers after each word\n        # e.g., for \"base_www\", we would try:\n        # - \"base1_www\", \"base2_www\", etc.\n        # - \"base_www1\", \"base_www2\", etc.\n        # limited to three iterations for sanity's sake\n        number_suffixes = self.parent_helper.gen_numbers(n, padding)\n        for match in list(self.parent_helper.regexes.word_regex.finditer(base))[-3:]:\n            span = match.span()\n            for suffix in number_suffixes:\n                before = base[: span[-1]]\n                after = base[span[-1] :]\n                # skip if there's already a number\n                if len(after) &gt; 1 and not after[0].isdigit():\n                    results.add(f\"{before}{suffix}{after}\")\n        # basic cases so we don't miss anything\n        for s in number_suffixes:\n            results.add(f\"{base}{s}\")\n            results.add(base)\n\n        return results\n\n    def truncate(self, limit):\n\"\"\"\n        Truncates the word cloud dictionary to retain only the top `limit` entries based on their occurrence frequencies.\n\n        Args:\n            limit (int): The maximum number of entries to retain in the word cloud.\n\n        Examples:\n            &gt;&gt;&gt; self.helpers.word_cloud.update({\"apple\": 5, \"banana\": 2, \"cherry\": 8})\n            &gt;&gt;&gt; self.helpers.word_cloud.truncate(2)\n            &gt;&gt;&gt; self.helpers.word_cloud\n            {'cherry': 8, 'apple': 5}\n        \"\"\"\n        new_self = dict(self.json(limit=limit))\n        self.clear()\n        self.update(new_self)\n\n    def json(self, limit=None):\n\"\"\"\n        Returns the word cloud as a sorted OrderedDict, optionally truncated to the top `limit` entries.\n\n        Args:\n            limit (int, optional): The maximum number of entries to include in the returned OrderedDict. If None, all entries are included.\n\n        Returns:\n            OrderedDict: A dictionary sorted by word frequencies, potentially truncated to the top `limit` entries.\n\n        Examples:\n            &gt;&gt;&gt; self.helpers.word_cloud.update({\"apple\": 5, \"banana\": 2, \"cherry\": 8})\n            &gt;&gt;&gt; self.helpers.word_cloud.json(limit=2)\n            OrderedDict([('cherry', 8), ('apple', 5)])\n        \"\"\"\n        cloud_sorted = sorted(self.items(), key=lambda x: x[-1], reverse=True)\n        if limit is not None:\n            cloud_sorted = cloud_sorted[:limit]\n        return OrderedDict(cloud_sorted)\n\n    @property\n    def default_filename(self):\n        return self.parent_helper.scan.home / f\"wordcloud.tsv\"\n\n    def save(self, filename=None, limit=None):\n\"\"\"\n        Saves the word cloud to a file. The cloud can optionally be truncated to the top `limit` entries.\n\n        Args:\n            filename (str, optional): The path to the file where the word cloud will be saved. If None, uses a default filename.\n            limit (int, optional): The maximum number of entries to save to the file. If None, all entries are saved.\n\n        Returns:\n            tuple: A tuple containing a boolean indicating success or failure, and the resolved filename.\n\n        Examples:\n            &gt;&gt;&gt; self.helpers.word_cloud.update({\"apple\": 5, \"banana\": 2, \"cherry\": 8})\n            &gt;&gt;&gt; self.helpers.word_cloud.save(filename=\"word_cloud.txt\", limit=2)\n            (True, Path('word_cloud.txt'))\n        \"\"\"\n        if filename is None:\n            filename = self.default_filename\n        else:\n            filename = Path(filename).resolve()\n        try:\n            if not self.parent_helper.mkdir(filename.parent):\n                log.error(f\"Failure creating or error writing to {filename.parent} when saving word cloud\")\n                return\n            if len(self) &gt; 0:\n                log.debug(f\"Saving word cloud to {filename}\")\n                with open(str(filename), mode=\"w\", newline=\"\") as f:\n                    c = csv.writer(f, delimiter=\"\\t\")\n                    for word, count in self.json(limit).items():\n                        c.writerow([count, word])\n                log.debug(f\"Saved word cloud ({len(self):,} words) to {filename}\")\n                return True, filename\n            else:\n                log.debug(f\"No words to save\")\n        except Exception as e:\n            import traceback\n\n            log.warning(f\"Failed to save word cloud to {filename}: {e}\")\n            log.trace(traceback.format_exc())\n        return False, filename\n\n    def load(self, filename=None):\n\"\"\"\n        Loads a word cloud from a file. The file can be either a standard wordlist with one entry per line\n        or a .tsv (tab-separated) file where the first row is the count and the second row is the associated entry.\n\n        Args:\n            filename (str, optional): The path to the file from which to load the word cloud. If None, uses a default filename.\n        \"\"\"\n        if filename is None:\n            wordcloud_path = self.default_filename\n        else:\n            wordcloud_path = Path(filename).resolve()\n        log.verbose(f\"Loading word cloud from {wordcloud_path}\")\n        try:\n            with open(str(wordcloud_path), newline=\"\") as f:\n                c = csv.reader(f, delimiter=\"\\t\")\n                for row in c:\n                    if len(row) == 1:\n                        self.add_word(row[0])\n                    elif len(row) == 2:\n                        with suppress(Exception):\n                            count, word = row\n                            count = int(count)\n                            self[word] = count\n            if len(self) &gt; 0:\n                log.success(f\"Loaded word cloud ({len(self):,} words) from {wordcloud_path}\")\n        except Exception as e:\n            import traceback\n\n            log_fn = log.debug\n            if filename is not None:\n                log_fn = log.warning\n            log_fn(f\"Failed to load word cloud from {wordcloud_path}: {e}\")\n            if filename is not None:\n                log.trace(traceback.format_exc())\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.WordCloud.absorb_event","title":"absorb_event","text":"<pre><code>absorb_event(event)\n</code></pre> <p>Absorbs an event from a BBOT scan into the word cloud.</p> <p>This method updates the word cloud by extracting words from the given event. It aims to avoid including PTR (Pointer) records, as they tend to produce unhelpful mutations in the word cloud.</p> <p>Parameters:</p> <ul> <li> <code>event</code>             (<code>Event</code>)         \u2013          <p>The event object containing the words to be absorbed into the word cloud.</p> </li> </ul> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>def absorb_event(self, event):\n\"\"\"\n    Absorbs an event from a BBOT scan into the word cloud.\n\n    This method updates the word cloud by extracting words from the given event. It aims to avoid including PTR\n    (Pointer) records, as they tend to produce unhelpful mutations in the word cloud.\n\n    Args:\n        event (Event): The event object containing the words to be absorbed into the word cloud.\n    \"\"\"\n    for word in event.words:\n        self.add_word(word)\n    if event.scope_distance == 0 and event.type.startswith(\"DNS_NAME\"):\n        subdomain = tldextract(event.data).subdomain\n        if subdomain and not self.parent_helper.is_ptr(subdomain):\n            for s in subdomain.split(\".\"):\n                self.dns_mutator.add_word(s)\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.WordCloud.absorb_word","title":"absorb_word","text":"<pre><code>absorb_word(word, ninja = True)\n</code></pre> <p>Absorbs a word into the word cloud after splitting it using a word extraction algorithm.</p> <p>This method splits the input word into smaller meaningful words using word extraction, and then adds each of them to the word cloud. The splitting is done using a predefined algorithm in the parent helper.</p> <p>Parameters:</p> <ul> <li> <code>word</code>             (<code>str</code>)         \u2013          <p>The word to be split and absorbed into the word cloud.</p> </li> <li> <code>ninja</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If True, word extraction is enabled. Defaults to True.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.helpers.word_cloud.absorb_word(\"blacklantern\")\n&gt;&gt;&gt; print(self.helpers.word_cloud)\n{\n    \"blacklantern\": 1,\n    \"black\": 1,\n    \"bl\": 1,\n    \"lantern\": 1\n}\n</code></pre> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>def absorb_word(self, word, ninja=True):\n\"\"\"\n    Absorbs a word into the word cloud after splitting it using a word extraction algorithm.\n\n    This method splits the input word into smaller meaningful words using word extraction, and then adds each\n    of them to the word cloud. The splitting is done using a predefined algorithm in the parent helper.\n\n    Args:\n        word (str): The word to be split and absorbed into the word cloud.\n        ninja (bool, optional): If True, word extraction is enabled. Defaults to True.\n\n    Examples:\n        &gt;&gt;&gt; self.helpers.word_cloud.absorb_word(\"blacklantern\")\n        &gt;&gt;&gt; print(self.helpers.word_cloud)\n        {\n            \"blacklantern\": 1,\n            \"black\": 1,\n            \"bl\": 1,\n            \"lantern\": 1\n        }\n    \"\"\"\n    for w in self.parent_helper.extract_words(word):\n        self.add_word(w)\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.WordCloud.add_word","title":"add_word","text":"<pre><code>add_word(word, lowercase = True)\n</code></pre> <p>Adds a word to the word cloud.</p> <p>This method updates the word cloud by adding a given word. If the word already exists in the cloud, its frequency count is incremented by 1. Optionally, the word can be converted to lowercase before adding.</p> <p>Parameters:</p> <ul> <li> <code>word</code>             (<code>str</code>)         \u2013          <p>The word to be added to the word cloud.</p> </li> <li> <code>lowercase</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If True, the word will be converted to lowercase before adding. Defaults to True.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.helpers.word_cloud.add_word(\"Example\")\n&gt;&gt;&gt; self.helpers.word_cloud.add_word(\"example\")\n&gt;&gt;&gt; print(self.helpers.word_cloud)\n{'example': 2}\n</code></pre> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>def add_word(self, word, lowercase=True):\n\"\"\"\n    Adds a word to the word cloud.\n\n    This method updates the word cloud by adding a given word. If the word already exists in the cloud,\n    its frequency count is incremented by 1. Optionally, the word can be converted to lowercase before adding.\n\n    Args:\n        word (str): The word to be added to the word cloud.\n        lowercase (bool, optional): If True, the word will be converted to lowercase before adding. Defaults to True.\n\n    Examples:\n        &gt;&gt;&gt; self.helpers.word_cloud.add_word(\"Example\")\n        &gt;&gt;&gt; self.helpers.word_cloud.add_word(\"example\")\n        &gt;&gt;&gt; print(self.helpers.word_cloud)\n        {'example': 2}\n    \"\"\"\n    if lowercase:\n        word = word.lower()\n    try:\n        self[word] += 1\n    except KeyError:\n        self[word] = 1\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.WordCloud.get_number_mutations","title":"get_number_mutations","text":"<pre><code>get_number_mutations(base, n = 5, padding = 2)\n</code></pre> <p>Generates mutations of a base string by modifying the numerical parts or appending numbers.</p> <p>This method detects existing numbers in the base string and tries incrementing and decrementing them within a specified range. It also appends numbers at the end or after each word to generate more mutations.</p> <p>Parameters:</p> <ul> <li> <code>base</code>             (<code>str</code>)         \u2013          <p>The base string to generate mutations from.</p> </li> <li> <code>n</code>             (<code>int</code>, default:                 <code>5</code> )         \u2013          <p>The range of numbers to use for incrementing/decrementing. Defaults to 5.</p> </li> <li> <code>padding</code>             (<code>int</code>, default:                 <code>2</code> )         \u2013          <p>Zero-pad numbers up to this length. Defaults to 2.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>set</code>        \u2013          <p>A set of mutated strings based on the base input.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.helpers.word_cloud.get_number_mutations(\"www2-test\", n=2)\n{\n    \"www0-test\",\n    \"www1-test\",\n    \"www2-test\",\n    \"www2-test0\",\n    \"www2-test00\",\n    \"www2-test01\",\n    \"www2-test1\",\n    \"www3-test\",\n    \"www4-test\"\n}\n</code></pre> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>def get_number_mutations(self, base, n=5, padding=2):\n\"\"\"\n    Generates mutations of a base string by modifying the numerical parts or appending numbers.\n\n    This method detects existing numbers in the base string and tries incrementing and decrementing them within a\n    specified range. It also appends numbers at the end or after each word to generate more mutations.\n\n    Args:\n        base (str): The base string to generate mutations from.\n        n (int, optional): The range of numbers to use for incrementing/decrementing. Defaults to 5.\n        padding (int, optional): Zero-pad numbers up to this length. Defaults to 2.\n\n    Returns:\n        set: A set of mutated strings based on the base input.\n\n    Examples:\n        &gt;&gt;&gt; self.helpers.word_cloud.get_number_mutations(\"www2-test\", n=2)\n        {\n            \"www0-test\",\n            \"www1-test\",\n            \"www2-test\",\n            \"www2-test0\",\n            \"www2-test00\",\n            \"www2-test01\",\n            \"www2-test1\",\n            \"www3-test\",\n            \"www4-test\"\n        }\n    \"\"\"\n    results = set()\n\n    # detects numbers and increments/decrements them\n    # e.g. for \"base2_p013\", we would try:\n    # - \"base0_p013\" through \"base12_p013\"\n    # - \"base2_p003\" through \"base2_p023\"\n    # limited to three iterations for sanity's sake\n    for match in list(self.parent_helper.regexes.num_regex.finditer(base))[-3:]:\n        span = match.span()\n        before = base[: span[0]]\n        after = base[span[-1] :]\n        number = base[span[0] : span[-1]]\n        numlen = len(number)\n        maxnum = min(int(\"9\" * numlen), int(number) + n)\n        minnum = max(0, int(number) - n)\n        for i in range(minnum, maxnum + 1):\n            filled_num = str(i).zfill(numlen)\n            results.add(f\"{before}{filled_num}{after}\")\n            if not number.startswith(\"0\"):\n                results.add(f\"{before}{i}{after}\")\n\n    # appends numbers after each word\n    # e.g., for \"base_www\", we would try:\n    # - \"base1_www\", \"base2_www\", etc.\n    # - \"base_www1\", \"base_www2\", etc.\n    # limited to three iterations for sanity's sake\n    number_suffixes = self.parent_helper.gen_numbers(n, padding)\n    for match in list(self.parent_helper.regexes.word_regex.finditer(base))[-3:]:\n        span = match.span()\n        for suffix in number_suffixes:\n            before = base[: span[-1]]\n            after = base[span[-1] :]\n            # skip if there's already a number\n            if len(after) &gt; 1 and not after[0].isdigit():\n                results.add(f\"{before}{suffix}{after}\")\n    # basic cases so we don't miss anything\n    for s in number_suffixes:\n        results.add(f\"{base}{s}\")\n        results.add(base)\n\n    return results\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.WordCloud.json","title":"json","text":"<pre><code>json(limit = None)\n</code></pre> <p>Returns the word cloud as a sorted OrderedDict, optionally truncated to the top <code>limit</code> entries.</p> <p>Parameters:</p> <ul> <li> <code>limit</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>The maximum number of entries to include in the returned OrderedDict. If None, all entries are included.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>OrderedDict</code>        \u2013          <p>A dictionary sorted by word frequencies, potentially truncated to the top <code>limit</code> entries.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.helpers.word_cloud.update({\"apple\": 5, \"banana\": 2, \"cherry\": 8})\n&gt;&gt;&gt; self.helpers.word_cloud.json(limit=2)\nOrderedDict([('cherry', 8), ('apple', 5)])\n</code></pre> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>def json(self, limit=None):\n\"\"\"\n    Returns the word cloud as a sorted OrderedDict, optionally truncated to the top `limit` entries.\n\n    Args:\n        limit (int, optional): The maximum number of entries to include in the returned OrderedDict. If None, all entries are included.\n\n    Returns:\n        OrderedDict: A dictionary sorted by word frequencies, potentially truncated to the top `limit` entries.\n\n    Examples:\n        &gt;&gt;&gt; self.helpers.word_cloud.update({\"apple\": 5, \"banana\": 2, \"cherry\": 8})\n        &gt;&gt;&gt; self.helpers.word_cloud.json(limit=2)\n        OrderedDict([('cherry', 8), ('apple', 5)])\n    \"\"\"\n    cloud_sorted = sorted(self.items(), key=lambda x: x[-1], reverse=True)\n    if limit is not None:\n        cloud_sorted = cloud_sorted[:limit]\n    return OrderedDict(cloud_sorted)\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.WordCloud.load","title":"load","text":"<pre><code>load(filename = None)\n</code></pre> <p>Loads a word cloud from a file. The file can be either a standard wordlist with one entry per line or a .tsv (tab-separated) file where the first row is the count and the second row is the associated entry.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>The path to the file from which to load the word cloud. If None, uses a default filename.</p> </li> </ul> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>def load(self, filename=None):\n\"\"\"\n    Loads a word cloud from a file. The file can be either a standard wordlist with one entry per line\n    or a .tsv (tab-separated) file where the first row is the count and the second row is the associated entry.\n\n    Args:\n        filename (str, optional): The path to the file from which to load the word cloud. If None, uses a default filename.\n    \"\"\"\n    if filename is None:\n        wordcloud_path = self.default_filename\n    else:\n        wordcloud_path = Path(filename).resolve()\n    log.verbose(f\"Loading word cloud from {wordcloud_path}\")\n    try:\n        with open(str(wordcloud_path), newline=\"\") as f:\n            c = csv.reader(f, delimiter=\"\\t\")\n            for row in c:\n                if len(row) == 1:\n                    self.add_word(row[0])\n                elif len(row) == 2:\n                    with suppress(Exception):\n                        count, word = row\n                        count = int(count)\n                        self[word] = count\n        if len(self) &gt; 0:\n            log.success(f\"Loaded word cloud ({len(self):,} words) from {wordcloud_path}\")\n    except Exception as e:\n        import traceback\n\n        log_fn = log.debug\n        if filename is not None:\n            log_fn = log.warning\n        log_fn(f\"Failed to load word cloud from {wordcloud_path}: {e}\")\n        if filename is not None:\n            log.trace(traceback.format_exc())\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.WordCloud.mutations","title":"mutations","text":"<pre><code>mutations(words, devops = True, cloud = True, letters = True, numbers = 5, number_padding = 2, substitute_numbers = True)\n</code></pre> <p>Generate various mutations for the given list of words based on different criteria.</p> <p>Yields tuples of strings which can be joined on the desired delimiter, e.g. \"-\" or \"_\".</p> <p>Parameters:</p> <ul> <li> <code>words</code>             (<code>Union[str, Iterable[str]]</code>)         \u2013          <p>A single word or list of words to mutate.</p> </li> <li> <code>devops</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to include devops-related mutations.</p> </li> <li> <code>cloud</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to include mutations from the word cloud.</p> </li> <li> <code>letters</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to include letter-based mutations.</p> </li> <li> <code>numbers</code>             (<code>int</code>, default:                 <code>5</code> )         \u2013          <p>The maximum numeric mutations to include.</p> </li> <li> <code>number_padding</code>             (<code>int</code>, default:                 <code>2</code> )         \u2013          <p>Padding for numeric mutations.</p> </li> <li> <code>substitute_numbers</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to substitute numbers in mutations.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>tuple</code>        \u2013          <p>A tuple containing each of the mutation segments.</p> </li> </ul> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>def mutations(\n    self, words, devops=True, cloud=True, letters=True, numbers=5, number_padding=2, substitute_numbers=True\n):\n\"\"\"\n    Generate various mutations for the given list of words based on different criteria.\n\n    Yields tuples of strings which can be joined on the desired delimiter, e.g. \"-\" or \"_\".\n\n    Args:\n        words (Union[str, Iterable[str]]): A single word or list of words to mutate.\n        devops (bool): Whether to include devops-related mutations.\n        cloud (bool): Whether to include mutations from the word cloud.\n        letters (bool): Whether to include letter-based mutations.\n        numbers (int): The maximum numeric mutations to include.\n        number_padding (int): Padding for numeric mutations.\n        substitute_numbers (bool): Whether to substitute numbers in mutations.\n\n    Yields:\n        tuple: A tuple containing each of the mutation segments.\n    \"\"\"\n    if isinstance(words, str):\n        words = (words,)\n    results = set()\n    for word in words:\n        h = hash(word)\n        if not h in results:\n            results.add(h)\n            yield (word,)\n    if numbers &gt; 0:\n        if substitute_numbers:\n            for word in words:\n                for number_mutation in self.get_number_mutations(word, n=numbers, padding=number_padding):\n                    h = hash(number_mutation)\n                    if not h in results:\n                        results.add(h)\n                        yield (number_mutation,)\n    for word in words:\n        for modifier in self.modifiers(\n            devops=devops, cloud=cloud, letters=letters, numbers=numbers, number_padding=number_padding\n        ):\n            a = (word, modifier)\n            b = (modifier, word)\n            for _ in (a, b):\n                h = hash(_)\n                if h not in results:\n                    results.add(h)\n                    yield _\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.WordCloud.save","title":"save","text":"<pre><code>save(filename = None, limit = None)\n</code></pre> <p>Saves the word cloud to a file. The cloud can optionally be truncated to the top <code>limit</code> entries.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>             (<code>str</code>, default:                 <code>None</code> )         \u2013          <p>The path to the file where the word cloud will be saved. If None, uses a default filename.</p> </li> <li> <code>limit</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>The maximum number of entries to save to the file. If None, all entries are saved.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>        \u2013          <p>A tuple containing a boolean indicating success or failure, and the resolved filename.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.helpers.word_cloud.update({\"apple\": 5, \"banana\": 2, \"cherry\": 8})\n&gt;&gt;&gt; self.helpers.word_cloud.save(filename=\"word_cloud.txt\", limit=2)\n(True, Path('word_cloud.txt'))\n</code></pre> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>def save(self, filename=None, limit=None):\n\"\"\"\n    Saves the word cloud to a file. The cloud can optionally be truncated to the top `limit` entries.\n\n    Args:\n        filename (str, optional): The path to the file where the word cloud will be saved. If None, uses a default filename.\n        limit (int, optional): The maximum number of entries to save to the file. If None, all entries are saved.\n\n    Returns:\n        tuple: A tuple containing a boolean indicating success or failure, and the resolved filename.\n\n    Examples:\n        &gt;&gt;&gt; self.helpers.word_cloud.update({\"apple\": 5, \"banana\": 2, \"cherry\": 8})\n        &gt;&gt;&gt; self.helpers.word_cloud.save(filename=\"word_cloud.txt\", limit=2)\n        (True, Path('word_cloud.txt'))\n    \"\"\"\n    if filename is None:\n        filename = self.default_filename\n    else:\n        filename = Path(filename).resolve()\n    try:\n        if not self.parent_helper.mkdir(filename.parent):\n            log.error(f\"Failure creating or error writing to {filename.parent} when saving word cloud\")\n            return\n        if len(self) &gt; 0:\n            log.debug(f\"Saving word cloud to {filename}\")\n            with open(str(filename), mode=\"w\", newline=\"\") as f:\n                c = csv.writer(f, delimiter=\"\\t\")\n                for word, count in self.json(limit).items():\n                    c.writerow([count, word])\n            log.debug(f\"Saved word cloud ({len(self):,} words) to {filename}\")\n            return True, filename\n        else:\n            log.debug(f\"No words to save\")\n    except Exception as e:\n        import traceback\n\n        log.warning(f\"Failed to save word cloud to {filename}: {e}\")\n        log.trace(traceback.format_exc())\n    return False, filename\n</code></pre>"},{"location":"dev/helpers/wordcloud/#bbot.core.helpers.wordcloud.WordCloud.truncate","title":"truncate","text":"<pre><code>truncate(limit)\n</code></pre> <p>Truncates the word cloud dictionary to retain only the top <code>limit</code> entries based on their occurrence frequencies.</p> <p>Parameters:</p> <ul> <li> <code>limit</code>             (<code>int</code>)         \u2013          <p>The maximum number of entries to retain in the word cloud.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; self.helpers.word_cloud.update({\"apple\": 5, \"banana\": 2, \"cherry\": 8})\n&gt;&gt;&gt; self.helpers.word_cloud.truncate(2)\n&gt;&gt;&gt; self.helpers.word_cloud\n{'cherry': 8, 'apple': 5}\n</code></pre> Source code in <code>bbot/core/helpers/wordcloud.py</code> <pre><code>def truncate(self, limit):\n\"\"\"\n    Truncates the word cloud dictionary to retain only the top `limit` entries based on their occurrence frequencies.\n\n    Args:\n        limit (int): The maximum number of entries to retain in the word cloud.\n\n    Examples:\n        &gt;&gt;&gt; self.helpers.word_cloud.update({\"apple\": 5, \"banana\": 2, \"cherry\": 8})\n        &gt;&gt;&gt; self.helpers.word_cloud.truncate(2)\n        &gt;&gt;&gt; self.helpers.word_cloud\n        {'cherry': 8, 'apple': 5}\n    \"\"\"\n    new_self = dict(self.json(limit=limit))\n    self.clear()\n    self.update(new_self)\n</code></pre>"},{"location":"modules/list_of_modules/","title":"List of Modules","text":"Module Type Needs API Key Description Flags Consumed Events Produced Events badsecrets scan No Library for detecting known or weak secrets across many web frameworks active, safe, web-basic, web-thorough HTTP_RESPONSE FINDING, VULNERABILITY bucket_amazon scan No Check for S3 buckets related to target active, cloud-enum, safe, web-basic, web-thorough DNS_NAME, STORAGE_BUCKET FINDING, STORAGE_BUCKET bucket_azure scan No Check for Azure storage blobs related to target active, cloud-enum, safe, web-basic, web-thorough DNS_NAME, STORAGE_BUCKET FINDING, STORAGE_BUCKET bucket_digitalocean scan No Check for DigitalOcean spaces related to target active, cloud-enum, safe, slow, web-thorough DNS_NAME, STORAGE_BUCKET FINDING, STORAGE_BUCKET bucket_firebase scan No Check for open Firebase databases related to target active, cloud-enum, safe, web-basic, web-thorough DNS_NAME, STORAGE_BUCKET FINDING, STORAGE_BUCKET bucket_google scan No Check for Google object storage related to target active, cloud-enum, safe, web-basic, web-thorough DNS_NAME, STORAGE_BUCKET FINDING, STORAGE_BUCKET bypass403 scan No Check 403 pages for common bypasses active, aggressive, web-thorough URL FINDING dnszonetransfer scan No Attempt DNS zone transfers active, safe, subdomain-enum DNS_NAME DNS_NAME ffuf scan No A fast web fuzzer written in Go active, aggressive, deadly URL URL_UNVERIFIED ffuf_shortnames scan No Use ffuf in combination IIS shortnames active, aggressive, iis-shortnames, web-thorough URL_HINT URL_UNVERIFIED filedownload scan No Download common filetypes such as PDF, DOCX, PPTX, etc. active, safe HTTP_RESPONSE, URL_UNVERIFIED fingerprintx scan No Fingerprint exposed services like RDP, SSH, MySQL, etc. active, safe, service-enum, slow OPEN_TCP_PORT PROTOCOL generic_ssrf scan No Check for generic SSRFs active, aggressive, web-thorough URL VULNERABILITY git scan No Check for exposed .git repositories active, safe, web-basic, web-thorough URL FINDING gowitness scan No Take screenshots of webpages active, safe, web-screenshots URL TECHNOLOGY, URL, URL_UNVERIFIED, WEBSCREENSHOT host_header scan No Try common HTTP Host header spoofing techniques active, aggressive, web-thorough HTTP_RESPONSE FINDING httpx scan No Visit webpages. Many other modules rely on httpx active, cloud-enum, safe, social-enum, subdomain-enum, web-basic, web-thorough OPEN_TCP_PORT, URL, URL_UNVERIFIED HTTP_RESPONSE, URL hunt scan No Watch for commonly-exploitable HTTP parameters active, safe, web-basic, web-thorough HTTP_RESPONSE FINDING iis_shortnames scan No Check for IIS shortname vulnerability active, iis-shortnames, safe, web-basic, web-thorough URL URL_HINT masscan scan No Port scan IP subnets with masscan active, aggressive, portscan SCAN OPEN_TCP_PORT nmap scan No Execute port scans with nmap active, aggressive, portscan, web-thorough DNS_NAME, IP_ADDRESS OPEN_TCP_PORT ntlm scan No Watch for HTTP endpoints that support NTLM authentication active, safe, web-basic, web-thorough HTTP_RESPONSE, URL DNS_NAME, FINDING nuclei scan No Fast and customisable vulnerability scanner active, aggressive, deadly URL FINDING, VULNERABILITY oauth scan No Enumerate OAUTH and OpenID Connect services active, affiliates, cloud-enum, safe, subdomain-enum, web-basic DNS_NAME, URL_UNVERIFIED DNS_NAME paramminer_cookies scan No Smart brute-force to check for common HTTP cookie parameters active, aggressive, slow, web-paramminer HTTP_RESPONSE FINDING paramminer_getparams scan No Use smart brute-force to check for common HTTP GET parameters active, aggressive, slow, web-paramminer HTTP_RESPONSE FINDING paramminer_headers scan No Use smart brute-force to check for common HTTP header parameters active, aggressive, slow, web-paramminer HTTP_RESPONSE FINDING robots scan No Look for and parse robots.txt active, safe, web-basic, web-thorough URL URL_UNVERIFIED secretsdb scan No Detect common secrets with secrets-patterns-db active, safe, web-basic, web-thorough HTTP_RESPONSE FINDING smuggler scan No Check for HTTP smuggling active, aggressive, slow, web-thorough URL FINDING social scan No Look for social media links in webpages active, safe, social-enum URL_UNVERIFIED SOCIAL sslcert scan No Visit open ports and retrieve SSL certificates active, affiliates, email-enum, safe, subdomain-enum, web-basic, web-thorough OPEN_TCP_PORT DNS_NAME, EMAIL_ADDRESS subdomain_hijack scan No Detect hijackable subdomains active, cloud-enum, safe, subdomain-enum, subdomain-hijack, web-basic, web-thorough DNS_NAME, DNS_NAME_UNRESOLVED FINDING telerik scan No Scan for critical Telerik vulnerabilities active, aggressive, slow, web-thorough URL FINDING, VULNERABILITY url_manipulation scan No Attempt to identify URL parsing/routing based vulnerabilities active, aggressive, web-thorough URL FINDING vhost scan No Fuzz for virtual hosts active, aggressive, deadly, slow URL DNS_NAME, VHOST wafw00f scan No Web Application Firewall Fingerprinting Tool active, aggressive URL WAF wappalyzer scan No Extract technologies from web responses active, safe, web-basic, web-thorough HTTP_RESPONSE TECHNOLOGY affiliates scan No Summarize affiliate domains at the end of a scan affiliates, passive, report, safe * anubisdb scan No Query jldc.me's database for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME asn scan No Query ripe and bgpview.io for ASNs passive, report, safe, subdomain-enum IP_ADDRESS ASN azure_realm scan No Retrieves the \"AuthURL\" from login.microsoftonline.com/getuserrealm affiliates, cloud-enum, passive, safe, subdomain-enum, web-basic DNS_NAME URL_UNVERIFIED azure_tenant scan No Query Azure for tenant sister domains affiliates, cloud-enum, passive, safe, subdomain-enum DNS_NAME DNS_NAME bevigil scan Yes Retrieve OSINT data from mobile applications using BeVigil passive, safe, subdomain-enum DNS_NAME DNS_NAME, URL_UNVERIFIED binaryedge scan Yes Query the BinaryEdge API passive, safe, subdomain-enum DNS_NAME DNS_NAME builtwith scan Yes Query Builtwith.com for subdomains affiliates, passive, safe, subdomain-enum DNS_NAME DNS_NAME c99 scan Yes Query the C99 API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME censys scan Yes Query the Censys API passive, safe, subdomain-enum DNS_NAME DNS_NAME certspotter scan No Query Certspotter's API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME chaos scan Yes Query ProjectDiscovery's Chaos API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME columbus scan No Query the Columbus Project API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME credshed scan Yes Send queries to your own credshed server to check for known credentials of your targets passive, safe DNS_NAME EMAIL_ADDRESS, HASHED_PASSWORD, PASSWORD, USERNAME crobat scan No Query Project Crobat for subdomains passive, safe DNS_NAME DNS_NAME crt scan No Query crt.sh (certificate transparency) for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME dehashed scan Yes Execute queries against dehashed.com for exposed credentials passive DNS_NAME HASHED_PASSWORD, PASSWORD, USERNAME digitorus scan No Query certificatedetails.com for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME dnscommonsrv scan No Check for common SRV records passive, safe, subdomain-enum DNS_NAME DNS_NAME dnsdumpster scan No Query dnsdumpster for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME emailformat scan No Query email-format.com for email addresses email-enum, passive, safe DNS_NAME EMAIL_ADDRESS fullhunt scan Yes Query the fullhunt.io API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME github scan Yes Query Github's API for related repositories passive, safe, subdomain-enum DNS_NAME URL_UNVERIFIED hackertarget scan No Query the hackertarget.com API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME hunterio scan Yes Query hunter.io for emails email-enum, passive, safe, subdomain-enum DNS_NAME DNS_NAME, EMAIL_ADDRESS, URL_UNVERIFIED ip2location scan Yes Query IP2location.io's API for geolocation information. passive, safe IP_ADDRESS GEOLOCATION ipneighbor scan No Look beside IPs in their surrounding subnet aggressive, passive, subdomain-enum IP_ADDRESS IP_ADDRESS ipstack scan Yes Query IPStack's GeoIP API passive, safe IP_ADDRESS GEOLOCATION leakix scan No Query leakix.net for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME massdns scan No Brute-force subdomains with massdns (highly effective) aggressive, passive, slow, subdomain-enum DNS_NAME DNS_NAME myssl scan No Query myssl.com's API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME nsec scan No Enumerate subdomains by NSEC-walking passive, safe, subdomain-enum DNS_NAME DNS_NAME otx scan No Query otx.alienvault.com for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME passivetotal scan Yes Query the PassiveTotal API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME pgp scan No Query common PGP servers for email addresses email-enum, passive, safe DNS_NAME EMAIL_ADDRESS rapiddns scan No Query rapiddns.io for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME riddler scan No Query riddler.io for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME securitytrails scan Yes Query the SecurityTrails API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME shodan_dns scan Yes Query Shodan for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME sitedossier scan No Query sitedossier.com for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME skymem scan No Query skymem.info for email addresses email-enum, passive, safe DNS_NAME EMAIL_ADDRESS subdomaincenter scan No Query subdomain.center's API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME sublist3r scan No Query sublist3r's API for subdomains passive, safe DNS_NAME DNS_NAME threatminer scan No Query threatminer's API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME urlscan scan No Query urlscan.io for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME, URL_UNVERIFIED viewdns scan No Query viewdns.info's reverse whois for related domains affiliates, passive, safe DNS_NAME DNS_NAME virustotal scan Yes Query VirusTotal's API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME wayback scan No Query archive.org's API for subdomains passive, safe, subdomain-enum DNS_NAME DNS_NAME, URL_UNVERIFIED zoomeye scan Yes Query ZoomEye's API for subdomains affiliates, passive, safe, subdomain-enum DNS_NAME DNS_NAME asset_inventory output No Output to an asset inventory style flattened CSV file DNS_NAME, FINDING, IP_ADDRESS, OPEN_TCP_PORT, TECHNOLOGY, URL, VULNERABILITY IP_ADDRESS, OPEN_TCP_PORT csv output No Output to CSV * discord output No Message a Discord channel when certain events are encountered * http output No Send every event to a custom URL via a web request * human output No Output to text * json output No Output to Newline-Delimited JSON (NDJSON) * neo4j output No Output to Neo4j * python output No Output via Python API * slack output No Message a Slack channel when certain events are encountered * subdomains output No Output only resolved, in-scope subdomains subdomain-enum DNS_NAME, DNS_NAME_UNRESOLVED teams output No Message a Slack channel when certain events are encountered * web_report output No Create a markdown report with web assets FINDING, TECHNOLOGY, URL, VHOST, VULNERABILITY websocket output No Output to websockets * aggregate internal No Summarize statistics at the end of a scan passive, safe excavate internal No Passively extract juicy tidbits from scan data passive HTTP_RESPONSE URL_UNVERIFIED speculate internal No Derive certain event types from others by common sense passive DNS_NAME, DNS_NAME_UNRESOLVED, HTTP_RESPONSE, IP_ADDRESS, IP_RANGE, STORAGE_BUCKET, URL, URL_UNVERIFIED DNS_NAME, FINDING, IP_ADDRESS, OPEN_TCP_PORT <p>For a list of module config options, see Module Options.</p>"},{"location":"modules/nuclei/","title":"Nuclei","text":""},{"location":"modules/nuclei/#overview","title":"Overview","text":"<p>BBOT's interface with the open-source vulnerability scanner Nuclei by Project Discovery. This is one of the ways BBOT makes it possible to go from a domain name or IP all the way to confirmed vulnerabilities, in one scan. </p> <p></p> <ul> <li>The BBOT Nuclei module ingests [URL] events and emits events of type [VULNERABILITY] or [FINDING]</li> <li>Vulnerabilities will inherit their severity from the Nuclei templates\u200b</li> <li>Nuclei templates of severity INFO will be emitted as [FINDINGS]</li> </ul>"},{"location":"modules/nuclei/#default-behavior","title":"Default Behavior","text":"<ul> <li>By default, it will scan only directory URLs, but it will scan with ALL templates (BE CAREFUL!)</li> <li>Because it's so aggressive, its considered a deadly module. This means you need to use the flag --allow-deadly to turn it on.</li> </ul>"},{"location":"modules/nuclei/#configuration-and-options","title":"Configuration and Options","text":"<p>The Nuclei module has many configuration options:</p> Option Description Default version What version of Nuclei to use 2.9.9 tags Limit Nuclei to templates w/these tags templates Path to template file, or template directory severity Filter based on severity field available in the template ratelimit maximum number of requests to send per second 150 concurrency maximum number of templates to be executed in parallel 25 mode technology | severe | manual | budget manual etags Tags to exclude from the scan directory_only When on, limits scan to only \"directory\" URLs (omit endpoints) True budget Used in budget mode to set the number of requests which will be allotted 1 retries Number of times to retry a failed request 0 batch_size The number of targets BBOT will pass to Nuclei at a time 200 <p>Most of these you probably will NOT want to change. In particular, we strongly advise against changing the version of Nuclei, as it's very likely the latest version won't work right with BBOT.</p> <p>We also do not recommend changing directory_only mode. Because BBOT is recursive, feeding Nuclei every URL can get very out-of-hand very quickly, depending on what other modules are in use.</p>"},{"location":"modules/nuclei/#mode","title":"Mode","text":"<p>The modes with the Nuclei module are generally in place to help you limit the number of templates you are scanning with, to make your scans quicker. </p>"},{"location":"modules/nuclei/#manual","title":"Manual","text":"<p>This is the default setting, and will use all templates. However, if you're looking to do something particular, you might pair this with some of the pass-through options shown in the next setting.</p>"},{"location":"modules/nuclei/#severe","title":"Severe","text":"<p>severe mode uses only high/critical severity templates. It also excludes the intrusive tag. This is intended to be a shortcut for times when you need to rapidly identify high severity vulnerabilities but can't afford the full scan. Because most templates are INFO, LOW, or MEDIUM, your scan will finish much faster.</p>"},{"location":"modules/nuclei/#technology","title":"Technology","text":"<p>This is equivalent to the Nuclei '-as' scan option. It only use templates that match detected technologies, using wappalyzer-based signatures. This can be a nice way to run a light-weight scan that still has a chance to find some good vulnerabilities.</p>"},{"location":"modules/nuclei/#budget","title":"Budget","text":"<p>Budget mode is unique to BBOT. \u200b</p> <p>For larger scans with thousands of targets, doing a FULL Nuclei scan (1000s of Requests) for each is not realistic. \u200b As an alternative to the other modes, you can take advantage of Nuclei's \"collapsible\" template feature. \u200b</p> <p>For only the cost of one (or more) \"extra\" request(s) per host, it can activate several hundred modules. These are modules which happen to look at a BaseUrl, and typically look for a specific string or other attribute. Nuclei is smart about reusing the request data when it can, and we can use this to our advantage. </p> <p>The budget parameter is the # of extra requests per host you are willing to send to \"feed\" Nuclei templates\u200b (defaults to 1). For those times when vulnerability scanning isn't the main focus, but you want to look for easy wins.\u200b</p> <p>Of course, there is a rapidly diminishing return when you set he value to more than a handful. Eventually, this becomes 1 template per 1 budget value increase. However, in the 1-10 range there is a lot of value. This graphic should give you a rough visual idea of this concept.</p> <p></p>"},{"location":"modules/nuclei/#nuclei-pass-through-options","title":"Nuclei pass-through options","text":"<p>Most of the rest of the options are usually passed straight through to Nuclei when its executed. You can do things like set specific tags to include, (or exclude with etags), exactly how you'd do with Nuclei directly. You can also limit the templates with severity.</p> <p>The ratelimit and concurrency settings default to the same defaults that Nuclei does. These are relatively sane settings, but if you are in a sensitive environment it can certainly help to turn them down.</p> <p>templates will allow you to set your own templates directory. This can be very useful if you have your own custom templates that you want to use with BBOT.</p>"},{"location":"modules/nuclei/#example-commands","title":"Example Commands","text":"<ul> <li>Scan a SINGLE target with a basic port scan and web modules</li> </ul> <p><code>COMMAND: bbot -f web-basic -m nmap nuclei --allow-deadly -t app.evilcorp.com\u200b</code></p> <ul> <li>Scanning MULTIPLE targets</li> </ul> <p><code>bbot -f web-basic -m nmap nuclei --allow-deadly -t app1.evilcorp.com app2.evilcorp.com app3.evilcorp.com\u200b</code></p> <ul> <li>Scanning MULTIPLE targets while performing subdomain enumeration</li> </ul> <p><code>bbot -f subdomain-enum web-basic -m nmap nuclei \u2013allow-deadly -t app1.evilcorp.com app2.evilcorp.com app3.evilcorp.com\u200b</code></p> <ul> <li>Scanning MULTIPLE targets on a BUDGET\u200b</li> </ul> <p><code>bbot -f subdomain-enum web-basic -m nmap nuclei \u2013allow-deadly \u2013c modules.nuclei.mode=Budget -t app1.evilcorp.com app2.evilcorp.com app3.evilcorp.com\u200b</code></p>"},{"location":"scanning/","title":"Scanning Overview","text":""},{"location":"scanning/#scan-names","title":"Scan Names","text":"<p>Every BBOT scan gets a random, mildly-entertaining name like <code>demonic_jimmy</code>. Output for that scan, including scan stats and any web screenshots, are saved to a folder by that name in <code>~/.bbot/scans</code>. The most recent 20 scans are kept, and older ones are removed.</p> <p>If you don't want a random name, you can change it with <code>-n</code>. You can also change the location of BBOT's output with <code>-o</code>:</p> <pre><code># save everything to the folder \"my_scan\" in the current directory\nbbot -t evilcorp.com -f subdomain-enum -m gowitness -n my_scan -o .\n</code></pre> <p>If you reuse a scan name, BBOT will automatically append to your previous output files.</p>"},{"location":"scanning/#targets-t","title":"Targets (<code>-t</code>)","text":"<p>Targets declare what's in-scope, and seed a scan with initial data. BBOT accepts an unlimited number of targets. They can be any of the following:</p> <ul> <li><code>DNS_NAME</code> (<code>evilcorp.com</code>)</li> <li><code>IP_ADDRESS</code> (<code>1.2.3.4</code>)</li> <li><code>IP_RANGE</code> (<code>1.2.3.0/24</code>)</li> <li><code>OPEN_TCP_PORT</code> (<code>192.168.0.1:80</code>)</li> <li><code>URL</code> (<code>https://www.evilcorp.com</code>)</li> </ul> <p>Note that BBOT only discriminates down to the host level. This means, for example, if you specify a URL <code>https://www.evilcorp.com</code> as the target, the scan will be seeded with that URL, but the scope of the scan will be the entire host, <code>www.evilcorp.com</code>. Other ports/URLs on that same host may also be scanned.</p> <p>You can specify targets directly on the command line, load them from files, or both! For example:</p> <pre><code>$ cat targets.txt\n4.3.2.1\n10.0.0.2:80\n1.2.3.0/24\nevilcorp.com\nevilcorp.co.uk\nhttps://www.evilcorp.co.uk\n\n# load targets from a file and from the command-line\n$ bbot -t targets.txt fsociety.com 5.6.7.0/24 -m nmap\n</code></pre> <p>On start, BBOT automatically converts Targets into Events.</p>"},{"location":"scanning/#modules-m","title":"Modules (<code>-m</code>)","text":"<p>To see a full list of modules and their descriptions, use <code>bbot -l</code> or see List of Modules.</p> <p>Modules are the part of BBOT that does the work -- port scanning, subdomain brute-forcing, API querying, etc. Modules consume Events (<code>IP_ADDRESS</code>, <code>DNS_NAME</code>, etc.) from each other, process the data in a useful way, then emit the results as new events. You can enable individual modules with <code>-m</code>.</p> <pre><code># Enable modules: nmap, sslcert, and httpx\nbbot -t www.evilcorp.com -m nmap sslcert httpx\n</code></pre>"},{"location":"scanning/#types-of-modules","title":"Types of Modules","text":"<p>Modules fall into three categories:</p> <ul> <li>Scan Modules:<ul> <li>These make up the majority of modules. Examples are <code>nmap</code>, <code>sslcert</code>, <code>httpx</code>, etc. Enable with <code>-m</code>.</li> </ul> </li> <li>Output Modules:<ul> <li>These output scan data to different formats/destinations. <code>human</code>, <code>json</code>, and <code>csv</code> are enabled by default. Enable others with <code>-om</code>. (See: Output)</li> </ul> </li> <li>Internal Modules:<ul> <li>These modules perform essential, common-sense tasks. They are always enabled, unless explicitly disabled via the config (e.g. <code>-c speculate=false</code>).<ul> <li><code>aggregate</code>: Summarizes results at the end of a scan</li> <li><code>excavate</code>: Extracts useful data such as subdomains from webpages, etc.</li> <li><code>speculate</code>: Intelligently infers new events, e.g. <code>OPEN_TCP_PORT</code> from <code>URL</code> or <code>IP_ADDRESS</code> from <code>IP_NETWORK</code>.</li> </ul> </li> </ul> </li> </ul> <p>For details in the inner workings of modules, see Creating a Module.</p>"},{"location":"scanning/#flags-f","title":"Flags (<code>-f</code>)","text":"<p>Flags are how BBOT categorizes its modules. In a way, you can think of them as groups. Flags let you enable a bunch of similar modules at the same time without having to specify them each individually. For example, <code>-f subdomain-enum</code> would enable every module with the <code>subdomain-enum</code> flag.</p> <pre><code># list all subdomain-enum modules\nbbot -f subdomain-enum -l\n</code></pre>"},{"location":"scanning/#filtering-by-flag","title":"Filtering by Flag","text":"<p>Modules can be easily filtered based on their flags:</p> <ul> <li><code>-f</code> Enable modules with this flag</li> <li><code>-rf</code> Require modules to have this flag</li> <li><code>-ef</code> Exclude modules with this flag</li> <li><code>-em</code> Exclude these individual modules</li> <li><code>-lf</code> List all available flags</li> </ul> <p>Every module is either <code>safe</code> or <code>aggressive</code>, and either <code>active</code> or <code>passive</code>. These can be useful for filtering. For example, if you wanted to enable all the <code>safe</code> modules, but exclude active ones, you could do:</p> <pre><code># Enable safe modules but exclude active ones\nbbot -t evilcorp.com -f safe -ef active\n</code></pre> <p>This is equivalent to requiring the passive flag:</p> <pre><code># Enable safe modules but only if they're also passive\nbbot -t evilcorp.com -f safe -rf passive\n</code></pre> <p>A single module can have multiple flags. For example, the <code>securitytrails</code> module is <code>passive</code>, <code>safe</code>, <code>subdomain-enum</code>. Below is a full list of flags and their associated modules.</p>"},{"location":"scanning/#list-of-flags","title":"List of Flags","text":"Flag # Modules Description Modules safe 69 Non-intrusive, safe to run affiliates, aggregate, anubisdb, asn, azure_realm, azure_tenant, badsecrets, bevigil, binaryedge, bucket_amazon, bucket_azure, bucket_digitalocean, bucket_firebase, bucket_google, builtwith, c99, censys, certspotter, chaos, columbus, credshed, crobat, crt, digitorus, dnscommonsrv, dnsdumpster, dnszonetransfer, emailformat, filedownload, fingerprintx, fullhunt, git, github, gowitness, hackertarget, httpx, hunt, hunterio, iis_shortnames, ip2location, ipstack, leakix, myssl, nsec, ntlm, oauth, otx, passivetotal, pgp, rapiddns, riddler, robots, secretsdb, securitytrails, shodan_dns, sitedossier, skymem, social, sslcert, subdomain_hijack, subdomaincenter, sublist3r, threatminer, urlscan, viewdns, virustotal, wappalyzer, wayback, zoomeye passive 52 Never connects to target systems affiliates, aggregate, anubisdb, asn, azure_realm, azure_tenant, bevigil, binaryedge, builtwith, c99, censys, certspotter, chaos, columbus, credshed, crobat, crt, dehashed, digitorus, dnscommonsrv, dnsdumpster, emailformat, excavate, fullhunt, github, hackertarget, hunterio, ip2location, ipneighbor, ipstack, leakix, massdns, myssl, nsec, otx, passivetotal, pgp, rapiddns, riddler, securitytrails, shodan_dns, sitedossier, skymem, speculate, subdomaincenter, sublist3r, threatminer, urlscan, viewdns, virustotal, wayback, zoomeye subdomain-enum 44 Enumerates subdomains anubisdb, asn, azure_realm, azure_tenant, bevigil, binaryedge, builtwith, c99, censys, certspotter, chaos, columbus, crt, digitorus, dnscommonsrv, dnsdumpster, dnszonetransfer, fullhunt, github, hackertarget, httpx, hunterio, ipneighbor, leakix, massdns, myssl, nsec, oauth, otx, passivetotal, rapiddns, riddler, securitytrails, shodan_dns, sitedossier, sslcert, subdomain_hijack, subdomaincenter, subdomains, threatminer, urlscan, virustotal, wayback, zoomeye active 38 Makes active connections to target systems badsecrets, bucket_amazon, bucket_azure, bucket_digitalocean, bucket_firebase, bucket_google, bypass403, dnszonetransfer, ffuf, ffuf_shortnames, filedownload, fingerprintx, generic_ssrf, git, gowitness, host_header, httpx, hunt, iis_shortnames, masscan, nmap, ntlm, nuclei, oauth, paramminer_cookies, paramminer_getparams, paramminer_headers, robots, secretsdb, smuggler, social, sslcert, subdomain_hijack, telerik, url_manipulation, vhost, wafw00f, wappalyzer web-thorough 24 More advanced web scanning functionality badsecrets, bucket_amazon, bucket_azure, bucket_digitalocean, bucket_firebase, bucket_google, bypass403, ffuf_shortnames, generic_ssrf, git, host_header, httpx, hunt, iis_shortnames, nmap, ntlm, robots, secretsdb, smuggler, sslcert, subdomain_hijack, telerik, url_manipulation, wappalyzer aggressive 18 Generates a large amount of network traffic bypass403, ffuf, ffuf_shortnames, generic_ssrf, host_header, ipneighbor, masscan, massdns, nmap, nuclei, paramminer_cookies, paramminer_getparams, paramminer_headers, smuggler, telerik, url_manipulation, vhost, wafw00f web-basic 17 Basic, non-intrusive web scan functionality azure_realm, badsecrets, bucket_amazon, bucket_azure, bucket_firebase, bucket_google, git, httpx, hunt, iis_shortnames, ntlm, oauth, robots, secretsdb, sslcert, subdomain_hijack, wappalyzer cloud-enum 10 Enumerates cloud resources azure_realm, azure_tenant, bucket_amazon, bucket_azure, bucket_digitalocean, bucket_firebase, bucket_google, httpx, oauth, subdomain_hijack slow 9 May take a long time to complete bucket_digitalocean, fingerprintx, massdns, paramminer_cookies, paramminer_getparams, paramminer_headers, smuggler, telerik, vhost affiliates 8 Discovers affiliated hostnames/domains affiliates, azure_realm, azure_tenant, builtwith, oauth, sslcert, viewdns, zoomeye email-enum 5 Enumerates email addresses emailformat, hunterio, pgp, skymem, sslcert deadly 3 Highly aggressive ffuf, nuclei, vhost web-paramminer 3 Discovers HTTP parameters through brute-force paramminer_cookies, paramminer_getparams, paramminer_headers iis-shortnames 2 Scans for IIS Shortname vulnerability ffuf_shortnames, iis_shortnames portscan 2 Discovers open ports masscan, nmap report 2 Generates a report at the end of the scan affiliates, asn social-enum 2 Enumerates social media httpx, social service-enum 1 Identifies protocols running on open ports fingerprintx subdomain-hijack 1 Detects hijackable subdomains subdomain_hijack web-screenshots 1 Takes screenshots of web pages gowitness"},{"location":"scanning/#dependencies","title":"Dependencies","text":"<p>BBOT modules have external dependencies ranging from OS packages (<code>openssl</code>) to binaries (<code>nmap</code>) to Python libraries (<code>wappalyzer</code>). When a module is enabled, installation of its dependencies happens at runtime with Ansible. BBOT provides several command-line flags to control how dependencies are installed.</p> <ul> <li><code>--no-deps</code> - Don't install module dependencies</li> <li><code>--force-deps</code> - Force install all module dependencies</li> <li><code>--retry-deps</code> - Try again to install failed module dependencies</li> <li><code>--ignore-failed-deps</code> - Run modules even if they have failed dependencies</li> <li><code>--install-all-deps</code> - Install dependencies for all modules (useful if you are provisioning a pentest system and want to install everything ahead of time)</li> </ul> <p>For details on how Ansible playbooks are attached to BBOT modules, see How to Write a Module.</p>"},{"location":"scanning/#scope","title":"Scope","text":"<p>For pentesters and bug bounty hunters, staying in scope is extremely important. BBOT takes this seriously, meaning that active modules (e.g. <code>nuclei</code>) will only touch in-scope resources.</p> <p>By default, scope is whatever you specify with <code>-t</code>. This includes child subdomains. For example, if you specify <code>-t evilcorp.com</code>, all its subdomains (<code>www.evilcorp.com</code>, <code>mail.evilcorp.com</code>, etc.) also become in-scope.</p>"},{"location":"scanning/#scope-distance","title":"Scope Distance","text":"<p>Since BBOT is recursive, it would quickly resort to scanning the entire internet without some kind of restraining mechanism. To solve this problem, every event discovered by BBOT is assigned a Scope Distance. Scope distance represents how far out from the main scope that data was discovered.</p> <p>For example, if your target is <code>evilcorp.com</code>, <code>www.evilcorp.com</code> would have a scope distance of <code>0</code> (i.e. in-scope). If BBOT discovers that <code>www.evilcorp.com</code> resolves to <code>1.2.3.4</code>, <code>1.2.3.4</code> is one hop away, which means it would have a scope distance of <code>1</code>. If <code>1.2.3.4</code> has a PTR record that points to <code>ecorp.blob.core.windows.net</code>, <code>ecorp.blob.core.windows.net</code> is two hops away, so its scope distance is <code>2</code>.</p> <p>Scope distance continues to increase the further out you get. Most modules (e.g. <code>nuclei</code> and <code>nmap</code>) only consume in-scope events. Certain other passive modules such as <code>asn</code> accept out to distance <code>1</code>. By default, DNS resolution happens out to a distance of <code>2</code>. Upon its discovery, any event that's determined to be in-scope (e.g. <code>www.evilcorp.com</code>) immediately becomes distance <code>0</code>, and the cycle starts over.</p>"},{"location":"scanning/#displaying-out-of-scope-events","title":"Displaying Out-of-scope Events","text":"<p>By default, BBOT only displays in-scope events (with a few exceptions such as <code>STORAGE_BUCKET</code>s). If you want to see more, you must increase the config value of <code>scope_report_distance</code>:</p> <pre><code># display out-of-scope events up to one hop away from the main scope\nbbot -t evilcorp.com -f subdomain-enum -c scope_report_distance=1\n</code></pre>"},{"location":"scanning/#strict-scope","title":"Strict Scope","text":"<p>If you want to scan only that specific target hostname and none of its children, you can specify <code>--strict-scope</code>.</p> <p>Note that <code>--strict-scope</code> only applies to targets and whitelists, but not blacklists. This means that if you put <code>internal.evilcorp.com</code> in your blacklist, you can be sure none of its subdomains will be scanned, even when using <code>--strict-scope</code>.</p>"},{"location":"scanning/#whitelists-and-blacklists","title":"Whitelists and Blacklists","text":"<p>BBOT allows precise control over scope with whitelists and blacklists. These both use the same syntax as <code>--target</code>, meaning they accept the same event types, and you can specify an unlimited number of them, via a file, the CLI, or both.</p> <p><code>--whitelist</code> enables you to override what's in scope. For example, if you want to run nuclei against <code>evilcorp.com</code>, but stay only inside their corporate IP range of <code>1.2.3.0/24</code>, you can accomplish this like so:</p> <pre><code># Seed scan with evilcorp.com, but restrict scope to 1.2.3.0/24\nbbot -t evilcorp.com --whitelist 1.2.3.0/24 -f subdomain-enum -m nmap nuclei --allow-deadly\n</code></pre> <p><code>--blacklist</code> takes ultimate precedence. Anything in the blacklist is completely excluded from the scan, even if it's in the whitelist.</p> <pre><code># Scan evilcorp.com, but exclude internal.evilcorp.com and its children\nbbot -t evilcorp.com --blacklist internal.evilcorp.com -f subdomain-enum -m nmap nuclei --allow-deadly\n</code></pre>"},{"location":"scanning/#dns-wildcards","title":"DNS Wildcards","text":"<p>BBOT has robust wildcard detection built-in. It can reliably detect wildcard domains, and will tag them accordingly:</p> <pre><code>[DNS_NAME]      github.io   TARGET  (a-record, a-wildcard-domain, aaaa-wildcard-domain, wildcard-domain)\n                                               ^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^\n</code></pre> <p>Wildcard hosts are collapsed into a single host beginning with <code>_wildcard</code>:</p> <pre><code>[DNS_NAME]      _wildcard.github.io     TARGET  (a-record, a-wildcard, a-wildcard-domain, aaaa-record, aaaa-wildcard, aaaa-wildcard-domain, wildcard, wildcard-domain)\n                ^^^^^^^^^\n</code></pre> <p>If you don't want this, you can disable wildcard detection on a domain-to-domain basis in the config:</p> ~/.bbot/config/bbot.yml<pre><code>dns_wildcard_ignore:\n- evilcorp.com\n- evilcorp.co.uk\n</code></pre> <p>There are certain edge cases (such as with dynamic DNS rules) where BBOT's wildcard detection fails. In these cases, you can try increasing the number of wildcard checks in the config:</p> ~/.bbot/config/bbot.yml<pre><code># default == 10\ndns_wildcard_tests: 20\n</code></pre> <p>If that doesn't work you can consider blacklisting the offending domain.</p>"},{"location":"scanning/advanced/","title":"Advanced","text":"<p>Below you can find some advanced uses of BBOT.</p>"},{"location":"scanning/advanced/#bbot-as-a-python-library","title":"BBOT as a Python library","text":"<p>Synchronous</p> <pre><code>from bbot.scanner import Scanner\n\n# any number of targets can be specified\nscan = Scanner(\"example.com\", \"scanme.nmap.org\", modules=[\"nmap\", \"sslcert\"])\nfor event in scan.start():\n    print(event.json())\n</code></pre> <p>Asynchronous</p> <pre><code>from bbot.scanner import Scanner\n\nasync def main():\n    scan = Scanner(\"example.com\", \"scanme.nmap.org\", modules=[\"nmap\", \"sslcert\"])\n    async for event in scan.async_start():\n        print(event.json())\n\nimport asyncio\nasyncio.run(main())\n</code></pre>"},{"location":"scanning/advanced/#command-line-help","title":"Command-Line Help","text":"<pre><code>usage: bbot [-h] [--help-all] [-t TARGET [TARGET ...]]\n               [-w WHITELIST [WHITELIST ...]] [-b BLACKLIST [BLACKLIST ...]]\n               [--strict-scope] [-m MODULE [MODULE ...]] [-l]\n               [-em MODULE [MODULE ...]] [-f FLAG [FLAG ...]] [-lf]\n               [-rf FLAG [FLAG ...]] [-ef FLAG [FLAG ...]]\n               [-om MODULE [MODULE ...]] [--allow-deadly] [-n SCAN_NAME]\n               [-o DIR] [-c [CONFIG ...]] [-v] [-d] [-s] [--force] [-y]\n               [--dry-run] [--current-config]\n               [--no-deps | --force-deps | --retry-deps | --ignore-failed-deps | --install-all-deps]\n               [-a] [--version]\n\nBighuge BLS OSINT Tool\n\noptions:\n  -h, --help            show this help message and exit\n  --help-all            Display full help including module config options\n\nTarget:\n  -t TARGET [TARGET ...], --targets TARGET [TARGET ...]\n                        Targets to seed the scan\n  -w WHITELIST [WHITELIST ...], --whitelist WHITELIST [WHITELIST ...]\n                        What's considered in-scope (by default it's the same as --targets)\n  -b BLACKLIST [BLACKLIST ...], --blacklist BLACKLIST [BLACKLIST ...]\n                        Don't touch these things\n  --strict-scope        Don't consider subdomains of target/whitelist to be in-scope\n\nModules:\n  -m MODULE [MODULE ...], --modules MODULE [MODULE ...]\n                        Modules to enable. Choices: affiliates,anubisdb,asn,azure_realm,azure_tenant,badsecrets,bevigil,binaryedge,bucket_amazon,bucket_azure,bucket_digitalocean,bucket_firebase,bucket_google,builtwith,bypass403,c99,censys,certspotter,chaos,columbus,credshed,crobat,crt,dehashed,digitorus,dnscommonsrv,dnsdumpster,dnszonetransfer,emailformat,ffuf,ffuf_shortnames,filedownload,fingerprintx,fullhunt,generic_ssrf,git,github,gowitness,hackertarget,host_header,httpx,hunt,hunterio,iis_shortnames,ip2location,ipneighbor,ipstack,leakix,masscan,massdns,myssl,nmap,nsec,ntlm,nuclei,oauth,otx,paramminer_cookies,paramminer_getparams,paramminer_headers,passivetotal,pgp,rapiddns,riddler,robots,secretsdb,securitytrails,shodan_dns,sitedossier,skymem,smuggler,social,sslcert,subdomain_hijack,subdomaincenter,sublist3r,telerik,threatminer,url_manipulation,urlscan,vhost,viewdns,virustotal,wafw00f,wappalyzer,wayback,zoomeye\n  -l, --list-modules    List available modules.\n  -em MODULE [MODULE ...], --exclude-modules MODULE [MODULE ...]\n                        Exclude these modules.\n  -f FLAG [FLAG ...], --flags FLAG [FLAG ...]\n                        Enable modules by flag. Choices: active,affiliates,aggressive,cloud-enum,deadly,email-enum,iis-shortnames,passive,portscan,report,safe,service-enum,slow,social-enum,subdomain-enum,subdomain-hijack,web-basic,web-paramminer,web-screenshots,web-thorough\n  -lf, --list-flags     List available flags.\n  -rf FLAG [FLAG ...], --require-flags FLAG [FLAG ...]\n                        Only enable modules with these flags (e.g. -rf passive)\n  -ef FLAG [FLAG ...], --exclude-flags FLAG [FLAG ...]\n                        Disable modules with these flags. (e.g. -ef aggressive)\n  -om MODULE [MODULE ...], --output-modules MODULE [MODULE ...]\n                        Output module(s). Choices: asset_inventory,csv,discord,http,human,json,neo4j,python,slack,subdomains,teams,web_report,websocket\n  --allow-deadly        Enable the use of highly aggressive modules\n\nScan:\n  -n SCAN_NAME, --name SCAN_NAME\n                        Name of scan (default: random)\n  -o DIR, --output-dir DIR\n  -c [CONFIG ...], --config [CONFIG ...]\n                        custom config file, or configuration options in key=value format: 'modules.shodan.api_key=1234'\n  -v, --verbose         Be more verbose\n  -d, --debug           Enable debugging\n  -s, --silent          Be quiet\n  --force               Run scan even if module setups fail\n  -y, --yes             Skip scan confirmation prompt\n  --dry-run             Abort before executing scan\n  --current-config      Show current config in YAML format\n\nModule dependencies:\n  Control how modules install their dependencies\n\n  --no-deps             Don't install module dependencies\n  --force-deps          Force install all module dependencies\n  --retry-deps          Try again to install failed module dependencies\n  --ignore-failed-deps  Run modules even if they have failed dependencies\n  --install-all-deps    Install dependencies for all modules\n\nAgent:\n  Report back to a central server\n\n  -a, --agent-mode      Start in agent mode\n\nMisc:\n  --version             show BBOT version and exit\n\nEXAMPLES\n\n    Subdomains:\n        bbot -t evilcorp.com -f subdomain-enum\n\n    Subdomains (passive only):\n        bbot -t evilcorp.com -f subdomain-enum -rf passive\n\n    Subdomains + port scan + web screenshots:\n        bbot -t evilcorp.com -f subdomain-enum -m nmap gowitness -n my_scan -o .\n\n    Subdomains + basic web scan:\n        bbot -t evilcorp.com -f subdomain-enum web-basic\n\n    Web spider:\n        bbot -t www.evilcorp.com -m httpx robots badsecrets secretsdb -c web_spider_distance=2 web_spider_depth=2\n\n    Everything everywhere all at once:\n        bbot -t evilcorp.com -f subdomain-enum email-enum cloud-enum web-basic -m nmap gowitness nuclei --allow-deadly\n\n    List modules:\n        bbot -l\n\n    List flags:\n        bbot -lf\n</code></pre>"},{"location":"scanning/configuration/","title":"Configuration Overview","text":"<p>BBOT has a YAML config at <code>~/.config/bbot</code>. This config is different from the command-line arguments. This is where you change settings such as BBOT's HTTP proxy, rate limits, or global User-Agent. It's also where you put modules' API keys.</p> <p>For a list of all possible config options, see:</p> <ul> <li>Global Options</li> <li>Module Options</li> </ul> <p>For examples of common config changes, see Tips and Tricks.</p>"},{"location":"scanning/configuration/#configuration-files","title":"Configuration Files","text":"<p>BBOT loads its config from the following files, in this order:</p> <ul> <li><code>~/.config/bbot/bbot.yml</code>     &lt;-- Use this one as your main config</li> <li><code>~/.config/bbot/secrets.yml</code>  &lt;-- Use this one for sensitive stuff like API keys</li> <li>command line (<code>--config</code>)     &lt;-- Use this to specify a custom config file or override individual config options</li> </ul> <p>These config files will be automatically created for you when you first run BBOT.</p>"},{"location":"scanning/configuration/#yaml-config-vs-command-line","title":"YAML Config vs Command Line","text":"<p>You can specify config options either via the command line or the config. For example, if you want to proxy your BBOT scan through a local proxy like Burp Suite, you could either do:</p> <pre><code># send BBOT traffic through an HTTP proxy\nbbot -t evilcorp.com --config http_proxy=http://127.0.0.1:8080\n</code></pre> <p>Or, in <code>~/.config/bbot/config.yml</code>:</p> ~/.bbot/config/bbot.yml<pre><code>http_proxy: http://127.0.0.1:8080\n</code></pre> <p>These two are equivalent.</p> <p>Config options specified via the command-line take precedence over all others. You can give BBOT a custom config file with <code>--config myconf.yml</code>, or individual arguments like this: <code>--config modules.shodan_dns.api_key=deadbeef</code>. To display the full and current BBOT config, including any command-line arguments, use <code>bbot --current-config</code>.</p> <p>Note that placing the following in <code>bbot.yml</code>: ~/.bbot/config/bbot.yml<pre><code>modules:\nshodan_dns:\napi_key: deadbeef\n</code></pre> Is the same as: <pre><code>bbot --config modules.shodan_dns.api_key=deadbeef\n</code></pre></p>"},{"location":"scanning/configuration/#global-config-options","title":"Global Config Options","text":"<p>Below is a full list of the config options supported, along with their defaults.</p> defaults.yml<pre><code>### BASIC OPTIONS ###\n\n# BBOT working directory\nhome: ~/.bbot\n# Don't output events that are further than this from the main scope\n# 1 == 1 hope away from main scope\n# 0 == in scope only\nscope_report_distance: 0\n# Generate new DNS_NAME and IP_ADDRESS events through DNS resolution\ndns_resolution: true\n# Limit the number of BBOT threads\nmax_threads: 25\n# Rate-limit DNS\ndns_queries_per_second: 1000\n# Rate-limit HTTP\nweb_requests_per_second: 100\n# Interval for displaying status messages\nstatus_frequency: 15\n# HTTP proxy\nhttp_proxy: # Web user-agent\nuser_agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\n\n### WEB SPIDER ###\n\n# Set the maximum number of HTTP links that can be followed in a row (0 == no spidering allowed)\nweb_spider_distance: 0\n# Set the maximum directory depth for the web spider\nweb_spider_depth: 1\n# Set the maximum number of links that can be followed per page\nweb_spider_links_per_page: 25\n\n\n### ADVANCED OPTIONS ###\n\n# How far out from the main scope to search\nscope_search_distance: 0\n# How far out from the main scope to resolve DNS names / IPs\nscope_dns_search_distance: 2\n# Limit how many DNS records can be followed in a row (stop malicious/runaway DNS records)\ndns_resolve_distance: 5\n\n# Infer certain events from others, e.g. IPs from IP ranges, DNS_NAMEs from URLs, etc.\nspeculate: True\n# Passively search event data for URLs, hostnames, emails, etc.\nexcavate: True\n# Summarize activity at the end of a scan\naggregate: True\n\n# HTTP timeout (for Python requests; API calls, etc.)\nhttp_timeout: 10\n# HTTP timeout (for httpx)\nhttpx_timeout: 5\n# Custom HTTP headers (e.g. cookies, etc.)\n# in the format { \"Header-Key\": \"header_value\" }\n# These are attached to all in-scope HTTP requests\n# Note that some modules (e.g. github) may end up sending these to out-of-scope resources\nhttp_headers: {}\n# HTTP retries (for Python requests; API calls, etc.)\nhttp_retries: 1\n# HTTP retries (for httpx)\nhttpx_retries: 1\n# Enable/disable debug messages for web requests/responses\nhttp_debug: false\n# Maximum number of HTTP redirects to follow\nhttp_max_redirects: 5\n# DNS query timeout\ndns_timeout: 5\n# How many times to retry DNS queries\ndns_retries: 1\n# Disable BBOT's smart DNS wildcard handling for select domains\ndns_wildcard_ignore: []\n# How many sanity checks to make when verifying wildcard DNS\n# Increase this value if BBOT's wildcard detection isn't working\ndns_wildcard_tests: 10\n# Skip DNS requests for a certain domain and rdtype after encountering this many timeouts or SERVFAILs\n# This helps prevent faulty DNS servers from hanging up the scan\ndns_abort_threshold: 50\n# Don't show PTR records containing IP addresses\ndns_filter_ptrs: true\n# Enable/disable debug messages for dns queries\ndns_debug: false\n# Whether to verify SSL certificates\nssl_verify: false\n# How many scan results to keep before cleaning up the older ones\nkeep_scans: 20\n# Completely ignore URLs with these extensions\nurl_extension_blacklist:\n# images\n- png\n- jpg\n- bmp\n- ico\n- jpeg\n- gif\n- svg\n# web/fonts\n- css\n- woff\n- woff2\n- ttf\n# audio\n- mp3\n- m4a\n- wav\n- flac\n# video\n- mp4\n- mkv\n- avi\n- wmv\n- mov\n- flv\n- webm\n# Distribute URLs with these extensions only to httpx (these are omitted from output)\nurl_extension_httpx_only:\n- js\n# Don't output these types of events (they are still distributed to modules)\nomit_event_types:\n- HTTP_RESPONSE\n- URL_UNVERIFIED\n- DNS_NAME_UNRESOLVED\n# - IP_ADDRESS\n# URL of BBOT server\nagent_url: ''\n# Agent Bearer authentication token\nagent_token: ''\n\n# Custom interactsh server settings\ninteractsh_server: null\ninteractsh_token: null\ninteractsh_disable: false\n\n# For performance reasons, always skip these DNS queries\n# Microsoft's DNS infrastructure is misconfigured so that certain queries to mail.protection.outlook.com always time out\ndns_omit_queries:\n- SRV:mail.protection.outlook.com\n- CNAME:mail.protection.outlook.com\n- TXT:mail.protection.outlook.com\n</code></pre>"},{"location":"scanning/configuration/#module-config-options","title":"Module Config Options","text":"<p>Many modules accept their own configuration options. These options have the ability to change their behavior. For example, the <code>nmap</code> module accepts options for <code>ports</code>, <code>timing</code>, etc. Below is a list of all possible module config options.</p> Config Option Type Description Default modules.bucket_amazon.permutations bool Whether to try permutations False modules.bucket_azure.permutations bool Whether to try permutations False modules.bucket_digitalocean.permutations bool Whether to try permutations False modules.bucket_firebase.permutations bool Whether to try permutations False modules.bucket_google.permutations bool Whether to try permutations False modules.dnszonetransfer.timeout int Max seconds to wait before timing out 10 modules.ffuf.extensions str Optionally include a list of extensions to extend the keyword with (comma separated) modules.ffuf.lines int take only the first N lines from the wordlist when finding directories 5000 modules.ffuf.max_depth int the maximum directory depth to attempt to solve 0 modules.ffuf.version str ffuf version 2.0.0 modules.ffuf.wordlist str Specify wordlist to use when finding directories https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/raft-small-directories.txt modules.ffuf_shortnames.extensions str Optionally include a list of extensions to extend the keyword with (comma separated) modules.ffuf_shortnames.find_common_prefixes bool Attempt to automatically detect common prefixes and make additional ffuf runs against them False modules.ffuf_shortnames.find_delimiters bool Attempt to detect common delimiters and make additional ffuf runs against them True modules.ffuf_shortnames.ignore_redirects bool Explicitly ignore redirects (301,302) True modules.ffuf_shortnames.lines int take only the first N lines from the wordlist when finding directories 1000000 modules.ffuf_shortnames.max_depth int the maximum directory depth to attempt to solve 1 modules.ffuf_shortnames.version str ffuf version 2.0.0 modules.ffuf_shortnames.wordlist str Specify wordlist to use when finding directories modules.ffuf_shortnames.wordlist_extensions str Specify wordlist to use when making extension lists modules.filedownload.extensions list File extensions to download ['bak', 'bash', 'bashrc', 'conf', 'cfg', 'crt', 'csv', 'db', 'sqlite', 'doc', 'docx', 'exe', 'ica', 'indd', 'ini', 'jar', 'key', 'pub', 'log', 'markdown', 'md', 'msi', 'odg', 'odp', 'ods', 'odt', 'pdf', 'pem', 'png', 'pps', 'ppsx', 'ppt', 'pptx', 'ps1', 'raw', 'rdp', 'sh', 'sql', 'swp', 'sxw', 'tar', 'tar.gz', 'zip', 'txt', 'vbs', 'wpd', 'xls', 'xlsx', 'xml', 'yml', 'yaml'] modules.filedownload.max_filesize str Cancel download if filesize is greater than this size 10MB modules.fingerprintx.version str fingerprintx version 1.1.4 modules.gowitness.output_path str where to save screenshots modules.gowitness.resolution_x int screenshot resolution x 1440 modules.gowitness.resolution_y int screenshot resolution y 900 modules.gowitness.threads int threads used to run 4 modules.gowitness.timeout int preflight check timeout 10 modules.gowitness.version str gowitness version 2.4.2 modules.httpx.in_scope_only bool Only visit web resources that are in scope. True modules.httpx.max_response_size int Max response size in bytes 5242880 modules.httpx.threads int Number of httpx threads to use 50 modules.httpx.version str httpx version 1.2.5 modules.iis_shortnames.detect_only bool Only detect the vulnerability and do not run the shortname scanner True modules.iis_shortnames.max_node_count int Limit how many nodes to attempt to resolve on any given recursion branch 30 modules.masscan.ping_first bool Only portscan hosts that reply to pings False modules.masscan.ports str Ports to scan 80,443 modules.masscan.rate int Rate in packets per second 600 modules.masscan.use_cache bool Instead of scanning, use the results from the previous scan False modules.masscan.wait int Seconds to wait for replies after scan is complete 10 modules.nmap.ports str ports to scan modules.nmap.skip_host_discovery bool skip host discovery (-Pn) True modules.nmap.timing str <code>-T&lt;0-5&gt;: Set timing template (higher is faster)</code> T4 modules.nmap.top_ports int top ports to scan 100 modules.ntlm.try_all bool Try every NTLM endpoint False modules.nuclei.batch_size int Number of targets to send to Nuclei per batch (default 200) 200 modules.nuclei.budget int Used in budget mode to set the number of requests which will be allotted to the nuclei scan 1 modules.nuclei.concurrency int maximum number of templates to be executed in parallel (default 25) 25 modules.nuclei.directory_only bool Filter out 'file' URL event (default True) True modules.nuclei.etags str tags to exclude from the scan modules.nuclei.mode str manual technology modules.nuclei.ratelimit int maximum number of requests to send per second (default 150) 150 modules.nuclei.retries int number of times to retry a failed request (default 0) 0 modules.nuclei.severity str Filter based on severity field available in the template. modules.nuclei.tags str execute a subset of templates that contain the provided tags modules.nuclei.templates str template or template directory paths to include in the scan modules.nuclei.version str nuclei version 2.9.15 modules.oauth.try_all bool Check for OAUTH/IODC on every subdomain and URL. False modules.paramminer_cookies.http_extract bool Attempt to find additional wordlist words from the HTTP Response True modules.paramminer_cookies.skip_boring_words bool Remove commonly uninteresting words from the wordlist True modules.paramminer_cookies.wordlist str Define the wordlist to be used to derive cookies modules.paramminer_getparams.http_extract bool Attempt to find additional wordlist words from the HTTP Response True modules.paramminer_getparams.skip_boring_words bool Remove commonly uninteresting words from the wordlist True modules.paramminer_getparams.wordlist str Define the wordlist to be used to derive headers modules.paramminer_headers.http_extract bool Attempt to find additional wordlist words from the HTTP Response True modules.paramminer_headers.skip_boring_words bool Remove commonly uninteresting words from the wordlist True modules.paramminer_headers.wordlist str Define the wordlist to be used to derive headers modules.robots.include_allow bool Include 'Allow' Entries True modules.robots.include_disallow bool Include 'Disallow' Entries True modules.robots.include_sitemap bool Include 'sitemap' entries False modules.secretsdb.min_confidence int Only use signatures with this confidence score or higher 99 modules.secretsdb.signatures str File path or URL to YAML signatures https://raw.githubusercontent.com/blacklanternsecurity/secrets-patterns-db/master/db/rules-stable.yml modules.sslcert.skip_non_ssl bool Don't try common non-SSL ports True modules.sslcert.timeout float Socket connect timeout in seconds 5.0 modules.subdomain_hijack.fingerprints str URL or path to fingerprints.json https://raw.githubusercontent.com/EdOverflow/can-i-take-over-xyz/master/fingerprints.json modules.telerik.exploit_RAU_crypto bool Attempt to confirm any RAU AXD detections are vulnerable False modules.url_manipulation.allow_redirects bool Allowing redirects will sometimes create false positives. Disallowing will sometimes create false negatives. Allowed by default. True modules.vhost.force_basehost str Use a custom base host (e.g. evilcorp.com) instead of the default behavior of using the current URL modules.vhost.lines int take only the first N lines from the wordlist when finding directories 5000 modules.vhost.wordlist str Wordlist containing subdomains https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/DNS/subdomains-top1million-5000.txt modules.wafw00f.generic_detect bool When no specific WAF detections are made, try to perform a generic detect True modules.bevigil.api_key str BeVigil OSINT API Key modules.bevigil.urls bool Emit URLs in addition to DNS_NAMEs False modules.binaryedge.api_key str BinaryEdge API key modules.binaryedge.max_records int Limit results to help prevent exceeding API quota 1000 modules.builtwith.api_key str Builtwith API key modules.builtwith.redirects bool Also look up inbound and outbound redirects True modules.c99.api_key str c99.nl API key modules.censys.api_id str Censys.io API ID modules.censys.api_secret str Censys.io API Secret modules.censys.max_pages int Maximum number of pages to fetch (100 results per page) 5 modules.chaos.api_key str Chaos API key modules.credshed.credshed_url str URL of credshed server modules.credshed.password str Credshed password modules.credshed.username str Credshed username modules.dehashed.api_key str DeHashed API Key modules.dehashed.username str Email Address associated with your API key modules.fullhunt.api_key str FullHunt API Key modules.github.api_key str Github token modules.hunterio.api_key str Hunter.IO API key modules.ip2location.api_key str IP2location.io API Key modules.ip2location.lang str Translation information(ISO639-1). The translation is only applicable for continent, country, region and city name. modules.ipneighbor.num_bits int Netmask size (in CIDR notation) to check. Default is 4 bits (16 hosts) 4 modules.ipstack.api_key str IPStack GeoIP API Key modules.leakix.api_key str LeakIX API Key modules.massdns.max_mutations int Max number of smart mutations per subdomain 500 modules.massdns.max_resolvers int Number of concurrent massdns resolvers 1000 modules.massdns.wordlist str Subdomain wordlist URL https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/DNS/subdomains-top1million-5000.txt modules.passivetotal.api_key str RiskIQ API Key modules.passivetotal.username str RiskIQ Username modules.pgp.search_urls list PGP key servers to search <code>['https://keyserver.ubuntu.com/pks/lookup?fingerprint=on&amp;op=vindex&amp;search=&lt;query&gt;', 'http://the.earth.li:11371/pks/lookup?fingerprint=on&amp;op=vindex&amp;search=&lt;query&gt;']</code> modules.securitytrails.api_key str SecurityTrails API key modules.shodan_dns.api_key str Shodan API key modules.urlscan.urls bool Emit URLs in addition to DNS_NAMEs False modules.virustotal.api_key str VirusTotal API Key modules.wayback.garbage_threshold int Dedupe similar urls if they are in a group of this size or higher (lower values == less garbage data) 10 modules.wayback.urls bool emit URLs in addition to DNS_NAMEs False modules.zoomeye.api_key str ZoomEye API key modules.zoomeye.include_related bool Include domains which may be related to the target False modules.zoomeye.max_pages int How many pages of results to fetch 20 output_modules.asset_inventory.output_file str Set a custom output file output_modules.asset_inventory.summary_netmask int Subnet mask to use when summarizing IP addresses at end of scan 16 output_modules.asset_inventory.use_previous bool <code>Emit previous asset inventory as new events (use in conjunction with -n &lt;old_scan_name&gt;)</code> False output_modules.csv.output_file str Output to CSV file output_modules.discord.event_types list Types of events to send ['VULNERABILITY', 'FINDING'] output_modules.discord.min_severity str Only allow VULNERABILITY events of this severity or higher LOW output_modules.discord.webhook_url str Discord webhook URL output_modules.http.bearer str Authorization Bearer token output_modules.http.method str HTTP method POST output_modules.http.password str Password (basic auth) output_modules.http.timeout int HTTP timeout 10 output_modules.http.url str Web URL output_modules.http.username str Username (basic auth) output_modules.human.console bool Output to console True output_modules.human.output_file str Output to file output_modules.json.console bool Output to console False output_modules.json.output_file str Output to file output_modules.neo4j.password str Neo4j password bbotislife output_modules.neo4j.uri str Neo4j server + port bolt://localhost:7687 output_modules.neo4j.username str Neo4j username neo4j output_modules.slack.event_types list Types of events to send ['VULNERABILITY', 'FINDING'] output_modules.slack.min_severity str Only allow VULNERABILITY events of this severity or higher LOW output_modules.slack.webhook_url str Discord webhook URL output_modules.subdomains.include_unresolved bool Include unresolved subdomains in output False output_modules.subdomains.output_file str Output to file output_modules.teams.event_types list Types of events to send ['VULNERABILITY', 'FINDING'] output_modules.teams.min_severity str Only allow VULNERABILITY events of this severity or higher LOW output_modules.teams.webhook_url str Discord webhook URL output_modules.web_report.css_theme_file str CSS theme URL for HTML output https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.1.0/github-markdown.min.css output_modules.web_report.output_file str Output to file output_modules.websocket.token str Authorization Bearer token output_modules.websocket.url str Web URL internal_modules.speculate.max_hosts int Max number of IP_RANGE hosts to convert into IP_ADDRESS events 65536 internal_modules.speculate.ports str The set of ports to speculate on 80,443"},{"location":"scanning/events/","title":"Events","text":"<p>An Event is a piece of data discovered by BBOT. Examples include <code>IP_ADDRESS</code>, <code>DNS_NAME</code>, <code>EMAIL_ADDRESS</code>, <code>URL</code>, etc. When you run a BBOT scan, events are constantly being exchanged between modules. They are also output to the console:</p> <pre><code>[DNS_NAME]      www.evilcorp.com    sslcert         (distance-0, in-scope, resolved, subdomain, a-record)\n ^^^^^^^^       ^^^^^^^^^^^^^^^^    ^^^^^^^          ^^^^^^^^^^\nevent type      event data          source module    tags\n</code></pre> <p>In addition to the obvious data (e.g. <code>www.evilcorp.com</code>), an event also contains other useful information such as:</p> <ul> <li>a <code>.timestamp</code> of when the data was discovered</li> <li>the <code>.module</code> that discovered it</li> <li>the <code>.source</code> event that led to its discovery</li> <li>its <code>.scope_distance</code> (how many hops it is from the main scope, 0 == in-scope)</li> <li>a list of <code>.tags</code> that describe the data (<code>mx-record</code>, <code>http-title</code>, etc.)</li> </ul> <p>These attributes allow us to construct a visual graph of events (e.g. in Neo4j) and query/filter/grep them more easily. Here is what a typical event looks like in JSON format:</p> <pre><code>{\n\"type\": \"URL\",\n\"id\": \"URL:017ec8e5dc158c0fd46f07169f8577fb4b45e89a\",\n\"data\": \"http://www.blacklanternsecurity.com/\",\n\"web_spider_distance\": 0,\n\"scope_distance\": 0,\n\"scan\": \"SCAN:4d786912dbc97be199da13074699c318e2067a7f\",\n\"timestamp\": 1688526222.723366,\n\"resolved_hosts\": [\"185.199.108.153\"],\n\"source\": \"OPEN_TCP_PORT:cf7e6a937b161217eaed99f0c566eae045d094c7\",\n\"tags\": [\n\"in-scope\",\n\"distance-0\",\n\"dir\",\n\"ip-185-199-108-153\",\n\"status-301\",\n\"http-title-301-moved-permanently\"\n],\n\"module\": \"httpx\",\n\"module_sequence\": \"httpx\"\n}\n</code></pre> <p>For a more detailed description of BBOT events, see Developer Documentation - Event.</p> <p>Below is a full list of event types along with which modules produce/consume them.</p>"},{"location":"scanning/events/#list-of-event-types","title":"List of Event Types","text":"Event Type # Consuming Modules # Producing Modules Consuming Modules Producing Modules * 11 0 affiliates, csv, discord, http, human, json, neo4j, python, slack, teams, websocket ASN 0 1 asn DNS_NAME 56 43 anubisdb, asset_inventory, azure_realm, azure_tenant, bevigil, binaryedge, bucket_amazon, bucket_azure, bucket_digitalocean, bucket_firebase, bucket_google, builtwith, c99, censys, certspotter, chaos, columbus, credshed, crobat, crt, dehashed, digitorus, dnscommonsrv, dnsdumpster, dnszonetransfer, emailformat, fullhunt, github, hackertarget, hunterio, leakix, massdns, myssl, nmap, nsec, oauth, otx, passivetotal, pgp, rapiddns, riddler, securitytrails, shodan_dns, sitedossier, skymem, speculate, subdomain_hijack, subdomaincenter, subdomains, sublist3r, threatminer, urlscan, viewdns, virustotal, wayback, zoomeye anubisdb, azure_tenant, bevigil, binaryedge, builtwith, c99, censys, certspotter, chaos, columbus, crobat, crt, digitorus, dnscommonsrv, dnsdumpster, dnszonetransfer, fullhunt, hackertarget, hunterio, leakix, massdns, myssl, nsec, ntlm, oauth, otx, passivetotal, rapiddns, riddler, securitytrails, shodan_dns, sitedossier, speculate, sslcert, subdomaincenter, sublist3r, threatminer, urlscan, vhost, viewdns, virustotal, wayback, zoomeye DNS_NAME_UNRESOLVED 3 0 speculate, subdomain_hijack, subdomains EMAIL_ADDRESS 0 6 credshed, emailformat, hunterio, pgp, skymem, sslcert FINDING 2 21 asset_inventory, web_report badsecrets, bucket_amazon, bucket_azure, bucket_digitalocean, bucket_firebase, bucket_google, bypass403, git, host_header, hunt, ntlm, nuclei, paramminer_cookies, paramminer_getparams, paramminer_headers, secretsdb, smuggler, speculate, subdomain_hijack, telerik, url_manipulation GEOLOCATION 0 2 ip2location, ipstack HASHED_PASSWORD 0 2 credshed, dehashed HTTP_RESPONSE 12 1 badsecrets, excavate, filedownload, host_header, hunt, ntlm, paramminer_cookies, paramminer_getparams, paramminer_headers, secretsdb, speculate, wappalyzer httpx IP_ADDRESS 7 3 asn, asset_inventory, ip2location, ipneighbor, ipstack, nmap, speculate asset_inventory, ipneighbor, speculate IP_RANGE 1 0 speculate OPEN_TCP_PORT 4 4 asset_inventory, fingerprintx, httpx, sslcert asset_inventory, masscan, nmap, speculate PASSWORD 0 2 credshed, dehashed PROTOCOL 0 1 fingerprintx SCAN 1 0 masscan SOCIAL 0 1 social STORAGE_BUCKET 6 5 bucket_amazon, bucket_azure, bucket_digitalocean, bucket_firebase, bucket_google, speculate bucket_amazon, bucket_azure, bucket_digitalocean, bucket_firebase, bucket_google TECHNOLOGY 2 2 asset_inventory, web_report gowitness, wappalyzer URL 18 2 asset_inventory, bypass403, ffuf, generic_ssrf, git, gowitness, httpx, iis_shortnames, ntlm, nuclei, robots, smuggler, speculate, telerik, url_manipulation, vhost, wafw00f, web_report gowitness, httpx URL_HINT 1 1 ffuf_shortnames iis_shortnames URL_UNVERIFIED 5 11 filedownload, httpx, oauth, social, speculate azure_realm, bevigil, excavate, ffuf, ffuf_shortnames, github, gowitness, hunterio, robots, urlscan, wayback USERNAME 0 2 credshed, dehashed VHOST 1 1 web_report vhost VULNERABILITY 2 4 asset_inventory, web_report badsecrets, generic_ssrf, nuclei, telerik WAF 0 1 wafw00f WEBSCREENSHOT 0 1 gowitness"},{"location":"scanning/events/#findings-vs-vulnerabilities","title":"Findings Vs. Vulnerabilities","text":"<p>BBOT has a sharp distinction between Findings and Vulnerabilities:</p> <p>VULNERABILITY</p> <ul> <li>There's a higher standard for what is allowed to be a vulnerability. They should be considered confirmed and actionable\u200b - no additional confirmation required</li> <li>They are always assigned a severity. The possible severities are: LOW, MEDIUM, HIGH, or CRITICAL\u200b</li> </ul> <p>FINDING\u200b</p> <ul> <li>Findings can range anywhere from \"slightly interesting behavior\" to \"likely, but unconfirmed vulnerability\"\u200b</li> <li>Are often false positives</li> </ul> <p>By making this separation, actionable vulnerabilities can be identified quickly in the midst of a large scan</p>"},{"location":"scanning/output/","title":"Output","text":"<p>By default, BBOT saves its output in TXT, JSON, and CSV formats: </p> <p>Every BBOT scan gets a unique and mildly-entertaining name like <code>demonic_jimmy</code>. Output for that scan, including scan stats and any web screenshots, etc., are saved to a folder by that name in <code>~/.bbot/scans</code>. The most recent 20 scans are kept, and older ones are removed. You can change the location of BBOT's output with <code>--output</code>, and you can also pick a custom scan name with <code>--name</code>.</p> <p>If you reuse a scan name, it will append to its original output files and leverage the previous.</p>"},{"location":"scanning/output/#output-modules","title":"Output Modules","text":"<p>Multiple simultaneous output formats are possible because of output modules. Output modules are similar to normal modules except they are enabled with <code>-om</code>.</p>"},{"location":"scanning/output/#human","title":"Human","text":"<p><code>human</code> output is tab-delimited, so it's easy to grep:</p> <pre><code># grep out only the DNS_NAMEs\ncat ~/.bbot/scans/extreme_johnny/output.txt | grep '[DNS_NAME]' | cut -f2\nevilcorp.com\nwww.evilcorp.com\nmail.evilcorp.com\n</code></pre>"},{"location":"scanning/output/#csv","title":"CSV","text":"<p>The <code>csv</code> output module produces a CSV like this:</p> Event type Event data IP Address Source Module Scope Distance Event Tags DNS_NAME evilcorp.com 1.2.3.4 TARGET 0 a-record,cdn-github,distance-0,domain,in-scope,mx-record,ns-record,resolved,soa-record,target,txt-record DNS_NAME www.evilcorp.com 2.3.4.5 certspotter 0 a-record,aaaa-record,cdn-github,cname-record,distance-0,in-scope,resolved,subdomain URL http://www.evilcorp.com 2.3.4.5 httpx 0 a-record,aaaa-record,cdn-github,cname-record,distance-0,in-scope,resolved,subdomain DNS_NAME admin.evilcorp.com 5.6.7.8 otx 0 a-record,aaaa-record,cloud-azure,cname-record,distance-0,in-scope,resolved,subdomain"},{"location":"scanning/output/#json","title":"JSON","text":"<p>If you manually enable the <code>json</code> output module, it will go to stdout:</p> <pre><code>bbot -t evilcorp.com -om json | jq\n</code></pre> <p>You will then see events like this:</p> <pre><code>{\n\"type\": \"IP_ADDRESS\",\n\"id\": \"IP_ADDRESS:13cd09c2adf0860a582240229cd7ad1dccdb5eb1\",\n\"data\": \"1.2.3.4\",\n\"scope_distance\": 1,\n\"scan\": \"SCAN:64c0e076516ae7aa6502fd99489693d0d5ec26cc\",\n\"timestamp\": 1688518967.740472,\n\"resolved_hosts\": [\"1.2.3.4\"],\n\"source\": \"DNS_NAME:2da045542abbf86723f22383d04eb453e573723c\",\n\"tags\": [\"distance-1\", \"ipv4\", \"internal\"],\n\"module\": \"A\",\n\"module_sequence\": \"A\"\n}\n</code></pre> <p>You can filter on the JSON output with <code>jq</code>:</p> <pre><code># pull out only the .data attribute of every DNS_NAME\n$ jq -r 'select(.type==\"DNS_NAME\") | .data' ~/.bbot/scans/extreme_johnny/output.ndjson\nevilcorp.com\nwww.evilcorp.com\nmail.evilcorp.com\n</code></pre>"},{"location":"scanning/output/#discord-slack-teams","title":"Discord / Slack / Teams","text":"<p>BBOT supports output via webhooks to <code>discord</code>, <code>slack</code>, and <code>teams</code>. To use them, you must specify a webhook URL either in the config:</p> ~/.bbot/config/bbot.yml<pre><code>output_modules:\ndiscord:\nwebhook_url: output_modules.discord.webhook_url=https://discord.com/api/webhooks/1234/deadbeef\n</code></pre> <p>...or on the command line: <pre><code>bbot -t evilcorp.com -om discord -c output_modules.discord.webhook_url=https://discord.com/api/webhooks/1234/deadbeef\n</code></pre></p> <p>By default, only <code>VULNERABILITY</code> and <code>FINDING</code> events are sent, but this can be customized by setting <code>event_types</code> in the config like so:</p> ~/.bbot/config/bbot.yml<pre><code>output_modules:\ndiscord:\nevent_types:\n- VULNERABILITY\n- FINDING\n- STORAGE_BUCKET\n</code></pre> <p>...or on the command line: <pre><code>bbot -t evilcorp.com -om discord -c output_modules.discord.event_types=[\"STORAGE_BUCKET\",\"FINDING\",\"VULNERABILITY\"]\n</code></pre></p> <p>You can also filter on the severity of <code>VULNERABILITY</code> events by setting <code>min_severity</code>:</p> ~/.bbot/config/bbot.yml<pre><code>output_modules:\ndiscord:\nmin_severity: HIGH\n</code></pre>"},{"location":"scanning/output/#http","title":"HTTP","text":"<p>The <code>http</code> output module sends events in JSON format to a desired HTTP endpoint.</p> <pre><code># POST scan results to localhost\nbbot -t evilcorp.com -om http -c output_modules.http.url=http://localhost:8000\n</code></pre> <p>You can customize the HTTP method if needed. Authentication is also supported:</p> ~/.bbot/config/bbot.yml<pre><code>output_modules:\nhttp:\nurl: https://localhost:8000\nmethod: PUT\n# Authorization: Bearer\nbearer: &lt;bearer_token&gt;\n# OR\nusername: bob\npassword: P@ssw0rd\n</code></pre>"},{"location":"scanning/output/#asset-inventory","title":"Asset Inventory","text":"<p>The <code>asset_inventory</code> module produces a CSV like this:</p> Host Provider IP(s) Status Open Ports evilcorp.com cdn-github 1.2.3.4 Active 80,443 www.evilcorp.com cdn-github 2.3.4.5 Active 22,80,443 admin.evilcorp.com cloud-azure 5.6.7.8 N/A"},{"location":"scanning/output/#subdomains","title":"Subdomains","text":"<p>The <code>subdomains</code> output module produces simple text file containing only in-scope and resolved subdomains:</p> subdomains.txt<pre><code>evilcorp.com\nwww.evilcorp.com\nmail.evilcorp.com\nportal.evilcorp.com\n</code></pre>"},{"location":"scanning/output/#neo4j","title":"Neo4j","text":"<p>Neo4j is the funnest (and prettiest) way to view and interact with BBOT data.</p> <p></p> <ul> <li>You can get Neo4j up and running with a single docker command:</li> </ul> <pre><code># start Neo4j in the background with docker\ndocker run -d -p 7687:7687 -p 7474:7474 -v \"$(pwd)/neo4j/:/data/\" -e NEO4J_AUTH=neo4j/bbotislife neo4j\n</code></pre> <ul> <li>After that, run bbot with <code>-om neo4j</code></li> </ul> <pre><code>bbot -f subdomain-enum -t evilcorp.com -om neo4j\n</code></pre> <ul> <li>Browse data at http://localhost:7474</li> </ul>"},{"location":"scanning/tips_and_tricks/","title":"Tips and Tricks","text":"<p>Below are some helpful tricks to help you in your adventures.</p>"},{"location":"scanning/tips_and_tricks/#change-verbosity-during-scan","title":"Change Verbosity During Scan","text":"<p>Press enter during a BBOT scan to change the log level. This will allow you to see debugging messages, etc.</p> <p></p>"},{"location":"scanning/tips_and_tricks/#kill-individual-module-during-scan","title":"Kill Individual Module During Scan","text":"<p>Sometimes a certain module can get stuck or slow down the scan. If this happens and you want to kill it, just type \"<code>kill &lt;module&gt;</code>\" in the terminal and press enter. This will kill and disable the module for the rest of the scan.</p> <p></p>"},{"location":"scanning/tips_and_tricks/#common-config-changes","title":"Common Config Changes","text":""},{"location":"scanning/tips_and_tricks/#boost-massdns-thread-count","title":"Boost Massdns Thread Count","text":"<p>If you have a fast internet connection or are running BBOT from a cloud VM, you can speed up subdomain enumeration by cranking the threads for <code>massdns</code>. The default is <code>1000</code>, which is about 1MB/s of DNS traffic:</p> <pre><code># massdns with 5000 resolvers, about 5MB/s\nbbot -t evilcorp.com -f subdomain-enum -c modules.massdns.max_resolvers=5000\n</code></pre>"},{"location":"scanning/tips_and_tricks/#web-spider","title":"Web Spider","text":"<p>The web spider is great for finding juicy data like subdomains, email addresses, and javascript secrets buried in webpages. However since it can lengthen the duration of a scan, it's disabled by default. To enable the web spider, you must increase the value of <code>web_spider_distance</code>.</p> <p>The web spider is controlled with three config values:</p> <ul> <li><code>web_spider_depth</code> (default: <code>1</code>: the maximum directory depth allowed. This is to prevent the spider from delving too deep into a website.</li> <li><code>web_spider_distance</code> (<code>0</code> == all spidering disabled, default: <code>0</code>): the maximum number of links that can be followed in a row. This is designed to limit the spider in cases where <code>web_spider_depth</code> fails (e.g. for an ecommerce website with thousands of base-level URLs).</li> <li><code>web_spider_links_per_page</code> (default: <code>25</code>): the maximum number of links per page that can be followed. This is designed to save you in cases where a single page has hundreds or thousands of links.</li> </ul> <p>Here is a typical example:</p> spider.yml<pre><code>web_spider_depth: 2\nweb_spider_distance: 2\nweb_spider_links_per_page: 25\n</code></pre> <pre><code># run the web spider against www.evilcorp.com\nbbot -t www.evilcorp.com -m httpx -c spider.yml\n</code></pre> <p>You can also pair the web spider with subdomain enumeration:</p> <pre><code># spider every subdomain of evilcorp.com\nbbot -t evilcorp.com -f subdomain-enum -c spider.yml\n</code></pre>"},{"location":"scanning/tips_and_tricks/#custom-http-proxy","title":"Custom HTTP Proxy","text":"<p>Web pentesters may appreciate BBOT's ability to quickly populate Burp Suite site maps for all subdomains in a target. If your scan includes gowitness, this will capture the traffic as if you manually visited each website in your browser -- including auxiliary web resources and javascript API calls. To accomplish this, set the <code>http_proxy</code> config option like so:</p> <pre><code># enumerate subdomains, take web screenshots, proxy through Burp\nbbot -t evilcorp.com -f subdomain-enum -m gowitness -c http_proxy=http://127.0.0.1:8080\n</code></pre>"},{"location":"scanning/tips_and_tricks/#display-http_response-events","title":"Display <code>HTTP_RESPONSE</code> Events","text":"<p>BBOT's <code>httpx</code> module emits <code>HTTP_RESPONSE</code> events, but by default they're hidden from output. These events contain the full raw HTTP body along with headers, etc. If you want to see them, you can modify <code>omit_event_types</code> in the config:</p> ~/.bbot/config/bbot.yml<pre><code>omit_event_types:\n- URL_UNVERIFIED\n# - HTTP_RESPONSE\n</code></pre>"},{"location":"scanning/tips_and_tricks/#display-out-of-scope-events","title":"Display Out-of-scope Events","text":"<p>By default, BBOT only shows in-scope events (with a few exceptions for things like storage buckets). If you want to see events that BBOT is emitting internally (such as for DNS resolution, etc.), you can increase <code>scope_report_distance</code> in the config or on the command line like so: <pre><code># display events up to scope distance 2 (default == 0)\nbbot -f subdomain-enum -t evilcorp.com -c scope_report_distance=2\n</code></pre></p>"},{"location":"scanning/tips_and_tricks/#speed-up-scans-by-disabling-dns-resolution","title":"Speed Up Scans By Disabling DNS Resolution","text":"<p>If you already have a list of discovered targets (e.g. URLs), you can speed up the scan by skipping BBOT's DNS resolution. You can do this by setting <code>dns_resolution</code> to <code>false</code>. <pre><code># disable the creation of new events from DNS resoluion\nbbot -m httpx gowitness wappalyzer -t urls.txt -c dns_resolution=false\n</code></pre></p>"},{"location":"scanning/tips_and_tricks/#faq","title":"FAQ","text":""},{"location":"scanning/tips_and_tricks/#what-is-url_unverified","title":"What is <code>URL_UNVERIFIED</code>?","text":"<p><code>URL_UNVERIFIED</code> events are URLs that haven't yet been visited by <code>httpx</code>. Once <code>httpx</code> visits them, it reraises them as <code>URL</code>s, tagged with their resulting status code.</p> <p>For example, when <code>excavate</code> gets an <code>HTTP_RESPONSE</code> event, it extracts links from the raw HTTP response as <code>URL_UNVERIFIED</code>s and then passes them back to <code>httpx</code> to be visited.</p> <p>By default, <code>URL_UNVERIFIED</code>s are hidden from output. If you want to see all of them including the out-of-scope ones, you can do it by changing <code>omit_event_types</code> and <code>scope_report_distance</code> in the config like so:</p> <pre><code># visit www.evilcorp.com and extract all the links\nbbot -t www.evilcorp.com -m httpx -c omit_event_types=[] scope_report_distance=2\n</code></pre>"}]}